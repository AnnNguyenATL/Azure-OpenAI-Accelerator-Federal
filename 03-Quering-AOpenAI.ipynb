{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
      "metadata": {},
      "source": [
        "# Queries with and without Azure OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
      "metadata": {},
      "source": [
        "So far, you have your Search Engine loaded **from two different data sources in two diferent text-based indexes**, on this notebook we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results.\n",
        "\n",
        "The idea is that a user can ask a question about Computer Science (first datasource/index) or about Covid (second datasource/index), and the engine will respond accordingly.\n",
        "This **Multi-Index** demo, mimics the scenario where a company loads multiple type of documents of different types and about completly different topics and the search engine must respond with the most relevant results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95d792b8",
      "metadata": {},
      "source": [
        "## Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ec4e0dce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain==0.0.347 in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 1)) (0.0.347)Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: langchain-experimental==0.0.44 in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 2)) (0.0.44)\n",
            "Requirement already satisfied: openai==1.3.7 in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 4)) (1.3.7)\n",
            "Requirement already satisfied: botbuilder-integration-aiohttp>=4.14.4 in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 5)) (4.14.6)\n",
            "Requirement already satisfied: faiss-cpu in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 6)) (1.7.4)\n",
            "Requirement already satisfied: tiktoken in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: docx2txt in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 8)) (0.8)\n",
            "Requirement already satisfied: pillow in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 9)) (10.0.1)\n",
            "Requirement already satisfied: pypdf in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 10)) (3.17.0)\n",
            "Requirement already satisfied: tenacity in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 11)) (8.2.3)\n",
            "Requirement already satisfied: sqlalchemy<2.0.0 in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 12)) (1.4.50)\n",
            "Requirement already satisfied: pyodbc in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 13)) (5.0.1)\n",
            "Requirement already satisfied: tabulate in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 14)) (0.9.0)\n",
            "Requirement already satisfied: azure-cosmos in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 15)) (4.5.1)\n",
            "Requirement already satisfied: streamlit in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 16)) (1.28.1)\n",
            "Requirement already satisfied: python-dotenv in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 17)) (1.0.0)\n",
            "Requirement already satisfied: azure-ai-formrecognizer in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 18)) (3.3.2)\n",
            "Requirement already satisfied: azure-storage-blob in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 19)) (12.19.0)\n",
            "Requirement already satisfied: rarfile in c:\\python311\\lib\\site-packages (from -r common/requirements.txt (line 20)) (4.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\python311\\lib\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python311\\lib\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python311\\lib\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.11 in c:\\python311\\lib\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (0.0.13)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\python311\\lib\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (0.0.72)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\python311\\lib\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (1.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (2.4.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\python311\\lib\\site-packages (from langchain==0.0.347->-r common/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python311\\lib\\site-packages (from openai==1.3.7->-r common/requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python311\\lib\\site-packages (from openai==1.3.7->-r common/requirements.txt (line 4)) (0.24.1)\n",
            "Requirement already satisfied: sniffio in c:\\python311\\lib\\site-packages (from openai==1.3.7->-r common/requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\python311\\lib\\site-packages (from openai==1.3.7->-r common/requirements.txt (line 4)) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\python311\\lib\\site-packages (from openai==1.3.7->-r common/requirements.txt (line 4)) (4.7.1)\n",
            "Requirement already satisfied: botbuilder-schema==4.14.6 in c:\\python311\\lib\\site-packages (from botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (4.14.6)\n",
            "Requirement already satisfied: botframework-connector==4.14.6 in c:\\python311\\lib\\site-packages (from botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (4.14.6)\n",
            "Requirement already satisfied: botbuilder-core==4.14.6 in c:\\python311\\lib\\site-packages (from botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (4.14.6)\n",
            "Requirement already satisfied: yarl>=1.8.1 in c:\\python311\\lib\\site-packages (from botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (1.9.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.347->-r common/requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.347->-r common/requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.347->-r common/requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.347->-r common/requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.347->-r common/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.347->-r common/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: botframework-streaming==4.14.6 in c:\\python311\\lib\\site-packages (from botbuilder-core==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (4.14.6)\n",
            "Requirement already satisfied: jsonpickle<1.5,>=1.2 in c:\\python311\\lib\\site-packages (from botbuilder-core==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: msrest==0.6.* in c:\\python311\\lib\\site-packages (from botbuilder-schema==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (0.6.21)\n",
            "Requirement already satisfied: urllib3<2.0.0 in c:\\python311\\lib\\site-packages (from botbuilder-schema==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (1.26.16)\n",
            "Requirement already satisfied: PyJWT>=2.4.0 in c:\\python311\\lib\\site-packages (from botframework-connector==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (2.8.0)\n",
            "Requirement already satisfied: msal==1.* in c:\\python311\\lib\\site-packages (from botframework-connector==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (1.25.0)\n",
            "Requirement already satisfied: cryptography<44,>=0.6 in c:\\python311\\lib\\site-packages (from msal==1.*->botframework-connector==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (41.0.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\python311\\lib\\site-packages (from msrest==0.6.*->botbuilder-schema==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: isodate>=0.6.0 in c:\\python311\\lib\\site-packages (from msrest==0.6.*->botbuilder-schema==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from msrest==0.6.*->botbuilder-schema==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (2023.7.22)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\python311\\lib\\site-packages (from tiktoken->-r common/requirements.txt (line 7)) (2023.10.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\python311\\lib\\site-packages (from sqlalchemy<2.0.0->-r common/requirements.txt (line 12)) (2.0.2)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\python311\\lib\\site-packages (from azure-cosmos->-r common/requirements.txt (line 15)) (1.29.5)\n",
            "Requirement already satisfied: altair<6,>=4.0 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (5.1.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (1.7.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (6.8.0)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (2.1.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (4.24.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (13.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (2.8.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (13.6.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in c:\\python311\\lib\\site-packages (from streamlit->-r common/requirements.txt (line 16)) (3.0.0)\n",
            "Requirement already satisfied: azure-common~=1.1 in c:\\python311\\lib\\site-packages (from azure-ai-formrecognizer->-r common/requirements.txt (line 18)) (1.1.28)\n",
            "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r common/requirements.txt (line 16)) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r common/requirements.txt (line 16)) (4.19.2)\n",
            "Requirement already satisfied: toolz in c:\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r common/requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\python311\\lib\\site-packages (from anyio<4.0->langchain==0.0.347->-r common/requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: six>=1.11.0 in c:\\python311\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos->-r common/requirements.txt (line 15)) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit->-r common/requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\python311\\lib\\site-packages (from cryptography<44,>=0.6->msal==1.*->botframework-connector==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.347->-r common/requirements.txt (line 1)) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.347->-r common/requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r common/requirements.txt (line 16)) (4.0.11)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.3.7->-r common/requirements.txt (line 4)) (0.17.3)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\python311\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit->-r common/requirements.txt (line 16)) (3.16.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.347->-r common/requirements.txt (line 1)) (2.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit->-r common/requirements.txt (line 16)) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit->-r common/requirements.txt (line 16)) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain==0.0.347->-r common/requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.347->-r common/requirements.txt (line 1)) (2.10.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->-r common/requirements.txt (line 16)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\davyu\\appdata\\roaming\\python\\python311\\site-packages (from rich<14,>=10.14.0->streamlit->-r common/requirements.txt (line 16)) (2.16.1)\n",
            "Requirement already satisfied: pycparser in c:\\python311\\lib\\site-packages (from cffi>=1.12->cryptography<44,>=0.6->msal==1.*->botframework-connector==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (2.21)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r common/requirements.txt (line 16)) (5.0.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python311\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai==1.3.7->-r common/requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit->-r common/requirements.txt (line 16)) (2.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r common/requirements.txt (line 16)) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r common/requirements.txt (line 16)) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r common/requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r common/requirements.txt (line 16)) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.347->-r common/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python311\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest==0.6.*->botbuilder-schema==4.14.6->botbuilder-integration-aiohttp>=4.14.4->-r common/requirements.txt (line 5)) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install -r common/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
      "metadata": {},
      "source": [
        "## Set up variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML, Markdown\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.embeddings import AzureOpenAIEmbeddings\n",
        "\n",
        "from common.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT, COMBINE_PROMPT_TEMPLATE\n",
        "from common.utils import (\n",
        "    get_search_results,\n",
        "    model_tokens_limit,\n",
        "    num_tokens_from_docs,\n",
        "    num_tokens_from_string\n",
        ")\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\", override=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
        "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
      "metadata": {},
      "source": [
        "## Multi-Index Search queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
      "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Text-based Indexes that we are going to query (from Notebook 01 and 02)\n",
        "index1_name = \"cogsrch-index-files\"\n",
        "index2_name = \"cogsrch-index-csv\"\n",
        "indexes = [index1_name, index2_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c62ebb2-d7be-4bfb-b1ba-4db86c11839a",
      "metadata": {},
      "source": [
        "Try questions that you think might be answered or addressed in computer science papers in 2020-2021 or that can be addressed by medical publications about COVID in 2020-2021. Try comparing the results with the open version of ChatGPT.<br>\n",
        "The idea is that the answers using Azure OpenAI only looks at the information contained on these publications.\n",
        "\n",
        "**Example Questions you can ask**:\n",
        "- What is CLP?\n",
        "- How Markov chains work?\n",
        "- What are some examples of reinforcement learning?\n",
        "- What are the main risk factors for Covid-19?\n",
        "- What medicine reduces inflamation in the lungs?\n",
        "- Why Covid doesn't affect kids that much compared to adults?\n",
        "- Does chloroquine really works against covid?\n",
        "- Who won the 1994 soccer world cup? # This question should yield no answer if the system is correctly grounded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
      "metadata": {},
      "outputs": [],
      "source": [
        "QUESTION = \"What is CLP?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf",
      "metadata": {},
      "source": [
        "### Search on both indexes individually and aggragate results\n",
        "\n",
        "#### **Note**: \n",
        "In order to standarize the indexes, **there must be 8 mandatory fields present on each text-based index**: `id, title, content, chunks, language, name, location, vectorized`. This is so that each document can be treated the same along the code. Also, **all indexes must have a semantic configuration**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "faf2e30f-e71f-4533-ab52-27d048b80a89",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "Index: cogsrch-index-files Results Found: 9789, Results Returned: 10\n",
            "200\n",
            "Index: cogsrch-index-csv Results Found: 48638, Results Returned: 10\n"
          ]
        }
      ],
      "source": [
        "agg_search_results = dict()\n",
        "\n",
        "for index in indexes:\n",
        "    search_payload = {\n",
        "        \"search\": QUESTION,\n",
        "        \"select\": \"id, title, chunks, name, location\",\n",
        "        \"queryType\": \"semantic\",\n",
        "        \"semanticConfiguration\": \"my-semantic-config\",\n",
        "        \"count\": \"true\",\n",
        "        \"speller\": \"lexicon\",\n",
        "        \"queryLanguage\": \"en-us\",\n",
        "        \"captions\": \"extractive\",\n",
        "        \"answers\": \"extractive\",\n",
        "        \"top\": \"10\"\n",
        "    }\n",
        "\n",
        "    r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index + \"/docs/search\",\n",
        "                     data=json.dumps(search_payload), headers=headers, params=params)\n",
        "    print(r.status_code)\n",
        "\n",
        "    search_results = r.json()\n",
        "    agg_search_results[index]=search_results\n",
        "    print(\"Index:\", index, \"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d6da7ea0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"@odata.context\":\"https://gptkb-3hhfqf2n5qzbc.search.windows.net/indexes(\\'cogsrch-index-csv\\')/$metadata#docs(*)\",\"@odata.count\":48638,\"@search.answers\":[{\"key\":\"u2g30x1j\",\"text\":\"Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP).\",\"highlights\":\"Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of <em>recombinant SA11 rotavirus core-like particles</em> (CLP) or virus-like particles (VLP).\",\"score\":0.9345703125}],\"value\":[{\"@search.score\":12.707714,\"@search.rerankerScore\":2.791743278503418,\"@search.captions\":[{\"text\":\"Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody.\",\"highlights\":\"\"}],\"id\":\"5ed5k9tq\",\"title\":\"Quantification of recombinant core-like particles of bluetongue virus using immunosorbent electron microscopy.\",\"chunks\":[\"Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody. The CLP concentration in purified preparations was determined to be 6.6 x 10(15) particles/l. CLP concentration in lysates of recombinant baculovirus-infected cells was determined at various times post-infection and shown to reach a value of 3 x 10(15) particles/l of culture medium at 96 h post-infection. The results indicated that immunosorbent electron microscopy, aided by an improved particle counting method, is a simple, rapid and accurate technique for the quantification of virus and virus-like particles produced in large scale in vitro systems.\"],\"name\":\"metadata.csv\",\"location\":\"https://www.ncbi.nlm.nih.gov/pubmed/10403670/\"},{\"@search.score\":11.988263,\"@search.rerankerScore\":2.548943042755127,\"@search.captions\":[{\"text\":\"The chemokine monocyte chemoattractant protein 1/CC chemokine ligand 2 (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases.\",\"highlights\":\"The<em> chemokine monocyte chemoattractant protein 1/CC</em><em> chemokine ligand 2</em> (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases.\"}],\"id\":\"m3ibpnfw\",\"title\":\"Increased susceptibility to septic and endotoxic shock in monocyte chemoattractant protein 1/cc chemokine ligand 2-deficient mice correlates with reduced interleukin 10 and enhanced macrophage migration inhibitory factor production.\",\"chunks\":[\"The chemokine monocyte chemoattractant protein 1/CC chemokine ligand 2 (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases. In the present study, we demonstrate that mcp-1/ccl2-deficient mice are more susceptible to systemic inflammatory response syndrome induced by lipopolysaccharide and to polymicrobial sepsis induced by cecum ligation and puncture (CLP) when compared with wild-type mice. Interestingly, in the CLP model, mcp-1/ccl2-deficient mice efficiently cleared the bacteria despite an impaired recruitment of leukocytes, especially mononuclear cells. The increased lethality rate in these models correlates with an impaired production of interleukin (IL) 10 in vivo. Furthermore, macrophages from mcp-1/ccl2-deficient mice activated with lipopolysaccharide also produced lower amounts of IL-10 and similar tumor necrosis factor compared with wild-type mice. We observed a drastic increase in the amounts of macrophage migration inhibitory factor at 6 and 24 h after CLP in mcp-1/ccl2-deficient mice. These results indicate that endogenous MCP-1/CCL2 positively regulates IL-10 but negatively controls macrophage migration inhibitory factor during peritoneal sepsis, thus suggesting an important immunomodulatory role for MCP-1/CCL2 in controlling the balance between proinflammatory and anti-inflammatory factors in sepsis.\"],\"name\":\"metadata.csv\",\"location\":\"https://www.ncbi.nlm.nih.gov/pubmed/17047515/\"},{\"@search.score\":12.749268,\"@search.rerankerScore\":2.5401346683502197,\"@search.captions\":[{\"text\":\"In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs.\",\"highlights\":\"\"}],\"id\":\"vnmg0zid\",\"title\":\"Length of encapsidated cargo impacts stability and structure of in vitro assembled alphavirus core-like particles\",\"chunks\":[\"In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs. We hypothesized that cargo neutralizes the basic region of the alphavirus capsid protein and if the cargo is long enough, it will also act to scaffold the CP monomers together. Experimentally we found that CLPs encapsidating short 27mer oligonucleotides were less stable than CLPs encapsidating 48mer or 90mer oligonucleotides under different chemical and thermal conditions. Furthermore, cryo-EM studies showed there were structural differences between CLPs assembled with 27mer and 48mer cargo. To mimic the role of the cargo in CLP assembly we made a mutant (4D) where we substituted a cluster of four Lys residues in the CP with four Asp residues. We found that these few amino acid substitutions were enough to initiate CLP assembly in the absence of cargo. The cargo-free 4D CLPs show higher resistance to ionic strength and increased temperature compared to wild-type cargo containing CLPs suggesting their CLP assembly mechanism might also be different.\"],\"name\":\"metadata.csv\",\"location\":\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7103146/\"},{\"@search.score\":10.760419,\"@search.rerankerScore\":2.5137102603912354,\"@search.captions\":[{\"text\":\"We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional laparoscopic pyeloplasty (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria.\",\"highlights\":\"We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional<em> laparoscopic pyeloplasty</em> (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria.\"}],\"id\":\"7xw8tlg3\",\"title\":\"Laparoendoscopic single site surgery versus conventional laparoscopy for transperitoneal pyeloplasty: A systematic review and meta-analysis.\",\"chunks\":[\"We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional laparoscopic pyeloplasty (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria. The methodological quality of the studies was rated according validated scales. The level of evidence (LE) was reported as described by the Oxford criteria. Preoperative demographic parameters and perioperative outcomes between the two surgical techniques were assessed. A meta-analysis of the included studies was performed. A total of 5 studies were elected for the analysis, including 164 cases, 70 (42.6%) of them being LESS and 94 (57.4%) being CLP. Four studies were observational retrospective comparative studies (LE: 3a-4); one was a prospective randomized controlled trial (LE: 2b). There was no significant difference in age, body mass index, gender, side and presence of the crossing vessel, between the groups. There was no significant difference regarding the operative time (weight mean difference [WMD]: -7.02; 95% confidence interval [CI]: -71.82-57.79; P = 0.83) and length of hospital stay (WMD: 0.04; 95% CI: -0.11-0.20; P = 0.58), whereas the estimated blood loss was statistically lower for LESS (WMD: -16.83; 95% CI: -31.79--1.87; P = 0.03). The postoperative use of analgesic favored the LESS group but without reaching statistical significance (WMD: -7.52; 95% CI: -17.56-2.53; P = 0.14). In conclusion, LESS pyeloplasty offers comparable surgical and functional outcomes to CLP while providing the potential advantages of less blood loss and lower analgesic requirement. Thus, despite being more technically challenging, LESS pyeloplasty can be regarded as a minimally invasive approach for patients seeking fewer incisional scars.\"],\"name\":\"metadata.csv\",\"location\":\"https://doi.org/10.4103/0974-7796.156145; https://www.ncbi.nlm.nih.gov/pubmed/26229312/\"},{\"@search.score\":16.59707,\"@search.rerankerScore\":2.457797050476074,\"@search.captions\":[{\"text\":\"The Academy of Consultation-Liaison Psychiatry (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient consultation-liaison psychiatry (CLP) training and providing a framework for CLP educators who are interested in developing outpatient CLP rotations within their programs.\",\"highlights\":\"The Academy of<em> Consultation-Liaison Psychiatry</em> (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient<em> consultation-liaison psychiatry</em> (CLP) training and providing a framework for<em> CLP</em> educators who are interested in developing outpatient<em> CLP</em> rotations within their programs.\"}],\"id\":\"da6d32x7\",\"title\":\"The educational value of outpatient CL rotations- a white paper from the ACLP residency education subcommittee\",\"chunks\":[\"Abstract Background and aims As mental health services in outpatient medical clinics expand, psychiatrists must be trained to practice in these settings. The Academy of Consultation-Liaison Psychiatry (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient consultation-liaison psychiatry (CLP) training and providing a framework for CLP educators who are interested in developing outpatient CLP rotations within their programs. Method MEDLINE (via PubMed), Embase and PsycINFO (via OVID), were reviewed each from inception to December 2019, for psychiatric CLP services in ambulatory settings that involved residents or fellows. The CLP education guidelines were reviewed for recommendations relevant to outpatient CLP. We also searched MedEd portal for published curriculums relevant to CLP. The group held 2 conferences to reach consensus about recommendations in setting up outpatient CLP rotations. Results Seventeen articles, three ACLP supported guidelines, and eight online didactic resources were identified as directly reporting on the organization and/or impact of an outpatient CLP rotation. These manuscripts indicated that residents found outpatient CLP rotations effective and relevant to their future careers. However, the literature provided few recommendations for establishing formal outpatient CLP training experiences. Discussion Outpatient CLP rotations offer multiple benefits for trainees, including exposure to specific clinical scenarios and therapeutic interventions applicable only in the outpatient setting, increased continuity of care and the unique experience of providing liaison and education to non-mental health providers. The article outlines recommendations and examples for developing outpatient CLP rotations which CLP educators can incorporate in their programs.\"],\"name\":\"metadata.csv\",\"location\":\"https://api.elsevier.com/content/article/pii/S0033318220301420; https://www.sciencedirect.com/science/article/pii/S0033318220301420?v=s5\"},{\"@search.score\":12.193438,\"@search.rerankerScore\":2.2948453426361084,\"@search.captions\":[{\"text\":\"Chronic obstructive pulmonary disease (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling.\",\"highlights\":\"<em>Chronic obstructive pulmonary disease</em> (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling.\"}],\"id\":\"i7ecw3xb\",\"title\":\"What is the contribution of respiratory viruses and lung proteases to airway remodelling in asthma and chronic obstructive pulmonary disease?\",\"chunks\":[\"It is well known that the lungs of asthmatics show airway wall remodelling and that asthma exacerbations are linked to respiratory infections. There is some evidence that respiratory infections in early childhood may increase the risk of developing asthma later in life. Chronic obstructive pulmonary disease (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling. This review considers the role of matrix metalloproteases and neutrophil elastase in remodelling, and whether the induction of proteases and other mediators during respiratory virus infections may contribute to the development of airway remodelling.\"],\"name\":\"metadata.csv\",\"location\":\"https://www.ncbi.nlm.nih.gov/pubmed/16286234/\"},{\"@search.score\":18.031353,\"@search.rerankerScore\":2.262484550476074,\"@search.captions\":[{\"text\":\"Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP).\",\"highlights\":\"Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11<em> rotavirus core-like particles</em> (CLP) or virus-like particles (VLP).\"}],\"id\":\"u2g30x1j\",\"title\":\"Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)\",\"chunks\":[\"The isotype antibody responses to bovine IND P(5), G6 and simian SA11 P(2), G3 rotavirus and SA11 rotavirus proteins (VP4, VP6 and VP7) in serum, colostrum and milk were analysed by ELISA in three groups of vaccinated cows and nonvaccinated controls. Pregnant cows were vaccinated intramuscularly and intramammarily with recombinant baculovirus-expressed SA11 rotavirus VLP (triple-layered virus-like particles containing rotavirus VP2, VP4, VP6 and VP7); CLP (double-layered core-like particles containing rotavirus VP2 and VP6); or inactivated SA11 rotavirus, respectively. Rotavirus antigen titers were highest (30\\\\u2013200-fold) in ELISA in the VLP vaccine compared to the inactivated SA11 vaccine. The IgG1, IgG2 and IgM geometric mean antibody titers (GMT) to rotavirus (titers to bovine rotavirus vs SA11 rotavirus did not differ significantly for any isotype or group) and the IgG2 GMT to VP6 in serum at calving in the vaccinated groups were significantly (P <0.05) higher than in the control group. In colostrum, IgG1 and IgA rotavirus antibody titers were significantly elevated for VLP (IgG1 GMT 832225; IgA GMT 16384), CLP (IgG1 GMT 660561; IgA GMT 10321) and SA11 (IgG1 GMT 131072; IgA GMT 1448) vaccinated cows compared to control cows (IgG1 GMT 11585; IgA GMT 45). The IgG1 and IgA GMT to rotavirus were significantly elevated (6\\\\u2013100-fold) in milk of VLP and CLP vaccinated cows compared to SA11 vaccinated or control cows. The isotype antibody responses to VP6 in serum, colostrum and milk paralleled the responses to rotavirus, but titers were \\\\u223c2\\\\u201310-fold lower. Only cows vaccinated with VLP had significantly enhanced serum, colostral and milk antibody titers to rotavirus VP4 and VP7. These results demonstrate that rotavirus antibody titers in serum, colostrum and milk are significantly enhanced by use of non-infectious VLP, CLP and inactivated SA11 rotavirus vaccines, but the VLP or CLP vaccines induced the highest antibody responses, corresponding to their higher rotavirus antigen titers measured by ELISA.\"],\"name\":\"metadata.csv\",\"location\":\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7131174/\"},{\"@search.score\":12.174453,\"@search.rerankerScore\":2.1104471683502197,\"@search.captions\":[{\"text\":\"Cold-inducible RNA-binding protein (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys.\",\"highlights\":\"Cold-inducible<em> RNA-binding protein</em> (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys.\"}],\"id\":\"ofsjs3nn\",\"title\":\"A cold-inducible RNA-binding protein (CIRP)-derived peptide attenuates inflammation and organ injury in septic mice\",\"chunks\":[\"Cold-inducible RNA-binding protein (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys. First, we confirmed that C23 dose-dependently inhibited TNF-\\\\u03b1 release, I\\\\u03baB\\\\u03b1 degradation, and NF-\\\\u03baB nuclear translocation in macrophages stimulated with CIRP. Next, we observed that male C57BL/6 mice treated with C23 (8 mg/kg BW) at 2 h after cecal ligation and puncture (CLP) had lower serum levels of LDH, ALT, IL-6, TNF-\\\\u03b1, and IL-1\\\\u03b2 (reduced by \\\\u226539%) at 20 h after CLP compared with mice treated with vehicle. C23-treated mice also had improved lung histology, less TUNEL-positive cells, lower serum levels of creatinine (34%) and BUN (26%), and lower kidney expression of NGAL (50%) and KIM-1 (86%). C23-treated mice also had reduced lung and kidney levels of IL-6, TNF-\\\\u03b1, and IL-1\\\\u03b2. E-selectin and ICAM-1 mRNA was significantly lower in C23-treated mice. The 10-day survival after CLP of vehicle-treated mice was 55%, while that of C23-treated mice was 85%. In summary, C23 decreased systemic, lung, and kidney injury and inflammation, and improved the survival rate after CLP, suggesting that it may be developed as a new treatment for sepsis.\"],\"name\":\"metadata.csv\",\"location\":\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5809586/\"},{\"@search.score\":13.193248,\"@search.rerankerScore\":1.8762637376785278,\"@search.captions\":[{\"text\":\"The mainstay of community-acquired pneumonia prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease..\\\\u0000\",\"highlights\":\"The mainstay of<em> community-acquired pneumonia</em> prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease..\\\\u0000\"}],\"id\":\"rd3bed48\",\"title\":\"Community-acquired pneumonia: what is relevant and what is not?\",\"chunks\":[\"PURPOSE OF REVIEW Community-acquired pneumonia is associated with significant morbidity and mortality and is the most common cause of death from infectious diseases in North America. The purpose of this review is to highlight recent advances in epidemiology, risk factors, severity criteria and antibiotic therapeutic regimens used for community-acquired pneumonia management. RECENT FINDINGS All guidelines recommend early and appropriate empiric therapy directed against common typical organisms, such as Streptococcus pneumoniae, and other atypical organisms, but clinicians should be aware of newer emerging pathogens such as community-acquired methicillin-resistant Staphylococcus aureus and Gram-negative pathogens. SUMMARY The optimum outcome in community-acquired pneumonia can be achieved by careful risk stratification using prediction rules together with appropriate antibiotic regimens. The mainstay of community-acquired pneumonia prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease.\"],\"name\":\"metadata.csv\",\"location\":\"https://www.ncbi.nlm.nih.gov/pubmed/17414124/\"},{\"@search.score\":10.3500395,\"@search.rerankerScore\":1.8561580181121826,\"@search.captions\":[{\"text\":\"The direct costs associated with RSV hospitalization were on average CLP $ 413,529 (US$ 632.1) for Group 1, and CLP $ 744,260 (US$ 1,137.6) for Group 2 (p < 0.05). There was also statistically significant higher cost for Group 2 due to tests and drugs (p < 0.05) and costs per day of hospital stay (p < 0.05).\",\"highlights\":\"\"}],\"id\":\"eyvywyob\",\"title\":\"Direct costs of low respiratory infection due to RSV in children under one year.\",\"chunks\":[\"INTRODUCTION Considering the high prevalence of respiratory infections in hospitalized infants with Respiratory Syncytial Virus (RSV), the objective of this study is to determine the direct costs of this infection. PATIENTS AND METHOD Prospective longitudinal study in infants under one year of age hospitalized due to RSV during 2015. The patients were divided into 2 groups, Group 1 pa tients without risk factors and Group 2 patients with risk factors (prematurity, oxygen dependence, bronchopulmonary dysplasia, heart disease, immunocompromised patients), comparing each other variables such as nutritional status, gender, breastfeeding, discharge diagnosis, radiological diagno sis, length of hospital stay, among others. Direct costs for hospitalization were estimated according to the fees of the National Health Fund (FONASA) and the Modality of Institutional Care (MAI). RESULTS The total patients admitted in the period were 260: 234 (90%) in Group 1 and 26 (10%) in Group 2. The average hospital stay for Group 1 was 7.3 days (SD+5.1) with a median of 6 days, and 13.6 days (SD+16.3) for Group 2 with a median of 7 days (p < 0.05). The direct costs associated with RSV hospitalization were on average CLP $ 413,529 (US$ 632.1) for Group 1, and CLP $ 744,260 (US$ 1,137.6) for Group 2 (p < 0.05). There was also statistically significant higher cost for Group 2 due to tests and drugs (p < 0.05) and costs per day of hospital stay (p < 0.05). CONCLUSION These values, known for the first time in the national reality, confirm the high cost of these infections and particularly in risk groups.\"],\"name\":\"metadata.csv\",\"location\":\"https://doi.org/10.4067/s0370-41062018005000401; https://www.ncbi.nlm.nih.gov/pubmed/30571819/\"}]}'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389",
      "metadata": {
        "tags": []
      },
      "source": [
        "### Display the top results (from both searches) based on the score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9e938337-602d-4b61-8141-b8c92a5d91da",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h4>Top Answers</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5>Answer - score: 0.97</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The key notions of CLP are those of an algebra and an associated constraint solver over a class of constraints, namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5>Answer - score: 0.93</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<h4>Top Results</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0508/0508108v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">0508108v1.pdf</a> - score: 3.55</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "CLP(FD) is an extension of logic programming. In CLP(FD) pro- grams, logical variables are assigned a domain and relations between vari- ables are described with constraints. A solution to a CLP(FD) program is a valuation of every variable in its own domain such that no constraint is falsified."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0701/0701082v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">0701082v1.pdf</a> - score: 3.46</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The key notions of CLP are those of an algebra and an associated constraint solver over a class of constraints, namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0508/0508106v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">arXiv:cs/0508106v1  [cs.PL]  24 Aug 2005</a> - score: 3.13</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "A CLP(C) program is a finite set of rules. A rule has the form H ← c⋄B where H and B are atoms and c is a finite conjunction of primitive constraints such that DC |= ∃c. A query has the form 〈A | d〉 where A is an atom and d is a finite conjunction of primitive constraints. Given an atom A := p(t̃), we write rel(A) to denote the predicate symbol p."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0011/0011030v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000</a> - score: 3.12</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1 Constraint Logic Programming  Constraint logic programming (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers)."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0506/0506005v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">0506005v1.pdf</a> - score: 3.1</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "A CLP(FD) system provides primitives for  accessing and updating attribute values. A CLP(FD) system provides equality (=), disequality (6=), and inequality con-  straints. In addition, a CLP(FD) system also provides some other constraints such  as global constraints."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0408/0408056v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">0408056v1.pdf</a> - score: 3.07</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "CLP(FD) languages have been suc-  cessfully used for solving a variety of industrial and academic problems. However,  in some constraint problems, where domain elements need to be acquired, it may  not be wise to perform the acquisition of the whole domains of variables before the  beginning of the constraint propagation process."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0310/0310042v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">()</a> - score: 3.02</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "A CLP(FD) program searches a solution for a set of variables which take values over finite domains and which must verify a set of constraints. The evolution of the domains can be viewed as a sequence of applications of reduction operators attached to the constraints."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0003/0003026v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">arXiv:cs/0003026v1  [cs.LO]  8 Mar 2000</a> - score: 2.97</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "A proof procedure for CLP is defined as an extension of standard resolution. A state is defined as a pair 〈← a, A || C〉 of a goal and a set of constraints. At each step of the computation, some literal a is selected from the current goal according to some selection function."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0402/0402019v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">0402019v1.pdf</a> - score: 2.89</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "CLP combines the advantages of two declarative  paradigms: logic programming (Prolog) and constraint solving. In logic program-  ming, problems are stated in a declarative way using rules to define relations (predi-  cates). Problems are solved using chronological backtrack search to explore choices."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pubmed/10403670/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">Quantification of recombinant core-like particles of bluetongue virus using immunosorbent electron microscopy.</a> - score: 2.79</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0404/0404053v1.pdf?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">0404053v1.pdf</a> - score: 2.77</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "We will define an amalgamated proof system that combines  inference rules from intuitionistic sequent calculus with constraint entailment, in  such a way that the key property of an abstract logic programming language is  preserved."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pubmed/17047515/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">Increased susceptibility to septic and endotoxic shock in monocyte chemoattractant protein 1/cc chemokine ligand 2-deficient mice correlates with reduced interleukin 10 and enhanced macrophage migration inhibitory factor production.</a> - score: 2.55</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The chemokine monocyte chemoattractant protein 1/CC chemokine ligand 2 (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7103146/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">Length of encapsidated cargo impacts stability and structure of in vitro assembled alphavirus core-like particles</a> - score: 2.54</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://doi.org/10.4103/0974-7796.156145; https://www.ncbi.nlm.nih.gov/pubmed/26229312/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">Laparoendoscopic single site surgery versus conventional laparoscopy for transperitoneal pyeloplasty: A systematic review and meta-analysis.</a> - score: 2.51</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional laparoscopic pyeloplasty (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://api.elsevier.com/content/article/pii/S0033318220301420; https://www.sciencedirect.com/science/article/pii/S0033318220301420?v=s5?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">The educational value of outpatient CL rotations- a white paper from the ACLP residency education subcommittee</a> - score: 2.46</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The Academy of Consultation-Liaison Psychiatry (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient consultation-liaison psychiatry (CLP) training and providing a framework for CLP educators who are interested in developing outpatient CLP rotations within their programs."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pubmed/16286234/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">What is the contribution of respiratory viruses and lung proteases to airway remodelling in asthma and chronic obstructive pulmonary disease?</a> - score: 2.29</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Chronic obstructive pulmonary disease (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7131174/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)</a> - score: 2.26</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5809586/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">A cold-inducible RNA-binding protein (CIRP)-derived peptide attenuates inflammation and organ injury in septic mice</a> - score: 2.11</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Cold-inducible RNA-binding protein (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://www.ncbi.nlm.nih.gov/pubmed/17414124/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">Community-acquired pneumonia: what is relevant and what is not?</a> - score: 1.88</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The mainstay of community-acquired pneumonia prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease..\u0000"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h5><a href=\"https://doi.org/10.4067/s0370-41062018005000401; https://www.ncbi.nlm.nih.gov/pubmed/30571819/?sv=2022-11-02&ss=b&srt=sco&sp=rl&se=2026-01-03T02:11:44Z&st=2024-01-02T18:11:44Z&spr=https&sig=ngrEqvqBVaxyuSYqgPVeF%2B9c0fXLs94v3ASgwg7LDBs%3D\">Direct costs of low respiratory infection due to RSV in children under one year.</a> - score: 1.86</h5>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The direct costs associated with RSV hospitalization were on average CLP $ 413,529 (US$ 632.1) for Group 1, and CLP $ 744,260 (US$ 1,137.6) for Group 2 (p < 0.05). There was also statistically significant higher cost for Group 2 due to tests and drugs (p < 0.05) and costs per day of hospital stay (p < 0.05)."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(HTML('<h4>Top Answers</h4>'))\n",
        "\n",
        "for index,search_results in agg_search_results.items():\n",
        "    for result in search_results['@search.answers']:\n",
        "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
        "            display(HTML('<h5>' + 'Answer - score: ' + str(round(result['score'],2)) + '</h5>'))\n",
        "            display(HTML(result['text']))\n",
        "            \n",
        "print(\"\\n\\n\")\n",
        "display(HTML('<h4>Top Results</h4>'))\n",
        "\n",
        "content = dict()\n",
        "ordered_content = OrderedDict()\n",
        "\n",
        "\n",
        "for index,search_results in agg_search_results.items():\n",
        "    for result in search_results['value']:\n",
        "        if result['@search.rerankerScore'] > 1:# Show answers that are at least 25% of the max possible score=4\n",
        "            content[result['id']]={\n",
        "                                    \"title\": result['title'],\n",
        "                                    \"chunks\": result['chunks'], \n",
        "                                    \"chunks_vectors\": [],\n",
        "                                    \"name\": result['name'], \n",
        "                                    \"location\": result['location'] ,\n",
        "                                    \"caption\": result['@search.captions'][0]['text'],\n",
        "                                    \"score\": result['@search.rerankerScore'],\n",
        "                                    \"index\": index\n",
        "                                    }\n",
        "    \n",
        "#After results have been filtered we will Sort and add them as an Ordered list\\n\",\n",
        "for id in sorted(content, key= lambda x: content[x][\"score\"], reverse=True):\n",
        "    ordered_content[id] = content[id]\n",
        "    url = str(ordered_content[id]['location']) + os.environ['BLOB_SAS_TOKEN']\n",
        "    title = str(ordered_content[id]['title']) if (ordered_content[id]['title']) else ordered_content[id]['name']\n",
        "    score = str(round(ordered_content[id]['score'],2))\n",
        "    display(HTML('<h5><a href=\"'+ url + '\">' + title + '</a> - score: '+ score + '</h5>'))\n",
        "    display(HTML(ordered_content[id]['caption']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5",
      "metadata": {},
      "source": [
        "## Comments on Query results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4",
      "metadata": {},
      "source": [
        "As seen above the semantic search feature of Azure Cognitive Search service is good. It gives answers (sometimes) and also the top results with the corresponding file and the paragraph where the answers is possible located.\n",
        "\n",
        "Let's see if we can make this better with Azure OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
      "metadata": {},
      "source": [
        "# Using Azure OpenAI\n",
        "\n",
        "To use OpenAI to get a better answer to our question, the thought process is simple: let's **give the answer and the content of the documents from the search result to the GPT model as context and let it provide a better response**.\n",
        "\n",
        "Now, before we do this, we need to understand a few things first:\n",
        "\n",
        "1) Chainning and Prompt Engineering\n",
        "2) Embeddings\n",
        "\n",
        "We will use a library call **LangChain** that wraps a lot of boiler plate code.\n",
        "Langchain is one library that does a lot of the prompt engineering for us under the hood, for more information see [here](https://python.langchain.com/en/latest/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "325d9138-2250-4f6b-bc88-50d7957f8d33",
      "metadata": {},
      "source": [
        "**Important Note**: Starting now, we will utilize OpenAI models. Please ensure that you have deployed the following models within the Azure OpenAI portal using these precise deployment names:\n",
        "\n",
        "- text-embedding-ada-002\n",
        "- gpt-35-turbo\n",
        "- gpt-35-turbo-16k\n",
        "- gpt-4\n",
        "- gpt-4-32k\n",
        "\n",
        "Should you have deployed the models under different names, the code provided below will not function as expected. To resolve this, you would need to modify the variable names throughout all the notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb",
      "metadata": {},
      "source": [
        "## A gentle intro to chaining LLMs and prompt engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69",
      "metadata": {},
      "source": [
        "Chains are what you get by connecting one or more large language models (LLMs) in a logical way. (Chains can be built of entities other than LLMs but for now, let’s stick with this definition for simplicity).\n",
        "\n",
        "Azure OpenAI is a type of LLM (provider) that you can use but there are others like Cohere, Huggingface, etc.\n",
        "\n",
        "Chains can be simple (i.e. Generic) or specialized (i.e. Utility).\n",
        "\n",
        "* Generic — A single LLM is the simplest chain. It takes an input prompt and the name of the LLM and then uses the LLM for text generation (i.e. output for the prompt).\n",
        "\n",
        "Here’s an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "13df9247-e784-4e04-9475-55e672efea47",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL = \"gpt-4-32k\" # options: gpt-35-turbo, gpt-35-turbo-16k, gpt-4, gpt-4-32k\n",
        "COMPLETION_TOKENS = 1000\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0, max_tokens=COMPLETION_TOKENS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7b0520b9-83b2-49fd-ad84-624cb0f15ce1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer the following question: \"What is CLP?\". Give your response in French\n"
          ]
        }
      ],
      "source": [
        "# Now we create a simple prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"language\"],\n",
        "    template='Answer the following question: \"{question}\". Give your response in {language}',\n",
        ")\n",
        "\n",
        "print(prompt.format(question=QUESTION, language=\"French\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dcc7dae3-6b88-4ea6-be43-b178ebc559dc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is CLP?',\n",
              " 'language': 'French',\n",
              " 'text': 'CLP est l\\'acronyme de \"Classification, Labelling and Packaging\", qui se traduit en français par \"Classification, Étiquetage et Emballage\". Il s\\'agit d\\'un règlement de l\\'Union Européenne concernant la classification, l\\'étiquetage et l\\'emballage de substances et de mélanges chimiques.'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# And finnaly we create our first generic chain\n",
        "chain_chat = LLMChain(llm=llm, prompt=prompt)\n",
        "chain_chat({\"question\": QUESTION, \"language\": \"French\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd8539d0-a538-4368-82c3-5f91d8370f1e",
      "metadata": {},
      "source": [
        "**Note**: this is the first time you use OpenAI in this Accelerator, so if you get a Resource not found error, is most likely because the name of your OpenAI model deployment is different than the variable MODEL set above"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5",
      "metadata": {},
      "source": [
        "Great!!, now you know how to create a simple prompt and use a chain in order to answer a general question using ChatGPT knowledge!. \n",
        "\n",
        "It is important to note that we rarely use generic chains as standalone chains. More often they are used as building blocks for Utility chains (as we will see next). Also important to notice is that we are NOT using our documents or the result of the Azure Search yet, just the knowledge of ChatGPT on the data it was trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12c48038-b1af-4228-8ffb-720e554fd3b2",
      "metadata": {
        "tags": []
      },
      "source": [
        "**The second type of Chains are Utility:**\n",
        "\n",
        "* Utility — These are specialized chains, comprised of many LLMs to help solve a specific task. For example, LangChain supports some end-to-end chains (such as QA_WITH_SOURCES for QnA Doc retrieval, Summarization, etc) and some specific ones (such as GraphQnAChain for creating, querying, and saving graphs). \n",
        "\n",
        "We will look at one specific chain called **qa_with_sources** in this workshop for digging deeper and solve our use case of enhancing the results of Azure Cognitive Search."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0454ddb-44d8-4fa9-929a-5e5563dd28f8",
      "metadata": {},
      "source": [
        "\n",
        "But before dealing with the utility chain needed, we need to deal first with this problem: **the content of the search result files is or can be very lengthy, more than the allowed tokens allowed by the GPT Azure OpenAI models**. \n",
        "\n",
        "This is where the concept of embeddings/vectors come into place.\n",
        "\n",
        "## Embeddings and Vector Search\n",
        "\n",
        "From the Azure OpenAI documentation ([HERE](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings?tabs=python)), An embedding is a special format of data representation that can be easily utilized by machine learning models and algorithms. The embedding is an information dense representation of the semantic meaning of a piece of text. Each embedding is a vector of floating point numbers, such that the distance between two embeddings in the vector space is correlated with semantic similarity between two inputs in the original format. For example, if two texts are similar, then their vector representations should also be similar. \n",
        "\n",
        "To address the challenge of accommodating context within the token limit of a Language Model (LLM), the solution involves the following steps:\n",
        "\n",
        "1. **Segmenting Documents**: Divide the documents into smaller segments or chunks.\n",
        "2. **Vectorization of Chunks**: Transform these chunks into vectors using appropriate techniques.\n",
        "3. **Vector Semantic Search**: Execute a semantic search using vectors to identify the top chunks similar to the given question.\n",
        "4. **Optimal Context Provision**: Provide the LLM with the most relevant and concise context, thereby achieving an optimal balance between comprehensiveness and lengthiness.\n",
        "\n",
        "\n",
        "Notice that **the documents chunks are already done in Azure Search**. *ordered_content* dictionary (created a few cells above) contains the chunks of each document. So we don't really need to chunk them again, but we still need to make sure that we can be as fast as possible and that we are below the max allowed input token limits of our selected OpenAI model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80e79235-3d8b-4713-9336-5004cc4a1556",
      "metadata": {},
      "source": [
        "Our ultimate goal is to rely solely on vector indexes. While it is possible to manually code parsers with OCR for various file types and develop a scheduler to synchronize data with the index, there is a more efficient alternative: **Azure Cognitive Search is soon going to release automated chunking strategies and vectorization within the next months**, so we have three options: \n",
        "1. Wait for this functionality while in the meantime manually push chunks and its vectors to the vector-based indexes \n",
        "2. Fill up the vector-based indexes on-demand, as documents are discovered by users\n",
        "3. Use custom skills (for chunking and vectorization) and use knowledge stores in order to create a vector-base index from a text-based-ai-enriched index at ingestion time. See [HERE](https://github.com/Azure/cognitive-search-vector-pr/blob/main/demo-python/code/azure-search-vector-ingestion-python-sample.ipynb) for instructions on how to do this.\n",
        "\n",
        "In this notebook we are going to implement Option 2: **Create vector-based indexes per each text-based indexes and fill them up on-demand as documents are discovered**. Why? because is simpler and quick to implement, while we wait for Option 1 to become a feature of Azure Search Engine (which is the automation of Option 3 inside the search engine).\n",
        "\n",
        "As observed in Notebooks 1 and 2, each text-based index contains a field named `vectorized` that we have not utilized yet. We will now harness this field. The objective is to avoid vectorizing all documents at the time of ingestion (Option 3). Instead, we can vectorize the chunks as users search for or discover documents. This approach ensures that we allocate funds and resources only when the documents are actually required. Typically, in an organization with a vast repository of documents in a data lake, only 20% of the documents are frequently accessed, while the rest remain untouched. This phenomenon mirrors the [Pareto Principle](https://en.wikipedia.org/wiki/Pareto_principle) found in nature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "12682a1b-df92-49ce-a638-7277103f6cb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = \"cogsrch-index-files\"\n",
        "index2_name = \"cogsrch-index-csv\"\n",
        "indexes = [index_name, index2_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78a6d6a7-18ef-45b2-a216-3c1f50006593",
      "metadata": {},
      "source": [
        "In order to not duplicate code, we have put many of the code used above into functions. These functions are in the `common/utils.py` and `common/prompts.py` files. This way we can use these functios in the app that we will build later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3bccca45-d1dd-476f-b109-a528b857b6b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'@odata.context': \"https://gptkb-3hhfqf2n5qzbc.search.windows.net/indexes('cogsrch-index-files')/$metadata#docs(*)\", '@odata.count': 9789, '@search.answers': [{'key': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNzAxLzA3MDEwODJ2MS5wZGY1', 'text': 'The key notions of CLP are those of an algebra and an associated constraint solver over a class of constraints, namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification.', 'highlights': 'The key notions of CLP are<em> those of an algebra and an associated constraint solver over a class of constraints,</em> namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification.', 'score': 0.96875}], 'value': [{'@search.score': 9.284887, '@search.rerankerScore': 3.548100471496582, '@search.captions': [{'text': 'CLP(FD) is an extension of logic programming. In CLP(FD) pro- grams, logical variables are assigned a domain and relations between vari- ables are described with constraints. A solution to a CLP(FD) program is a valuation of every variable in its own domain such that no constraint is falsified.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNTA4LzA1MDgxMDh2MS5wZGY1', 'title': None, 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n05\\n\\n08\\n10\\n\\n8v\\n1 \\n\\n [\\ncs\\n\\n.S\\nE\\n\\n] \\n 2\\n\\n4 \\nA\\n\\nug\\n 2\\n\\n00\\n5\\n\\nProving or Disproving Likely Invariants\\n\\nwith Constraint Reasoning ⋆\\n\\nTristan Denmat1, Arnaud Gotlieb2, and Mireille Ducassé1\\n\\n1 IRISA/INSA\\n2 IRISA/INRIA\\n\\nCampus universitaire de Beaulieu 35042 Rennes Cedex, France\\n{denmat,gotlieb,ducasse}@irisa.fr\\n\\nAbstract A program invariant is a property that holds for every execu-\\ntion of the program. Recent work suggest to infer likely-only invariants,\\nvia dynamic analysis. A likely invariant is a property that holds for some\\nexecutions but is not guaranteed to hold for all executions. In this pa-\\nper, we present work in progress addressing the challenging problem of\\nautomatically verifying that likely invariants are actual invariants. We\\npropose a constraint-based reasoning approach that is able, unlike other\\napproaches, to both prove or disprove likely invariants. In the latter case,\\nour approach provides counter-examples. We illustrate the approach on a\\nmotivating example where automatically generated likely invariants are\\nverified.\\n\\n1 Introduction\\n\\nA program invariant is a property that holds over every execution of the\\nprogram. Examples of program invariants include loop invariants pre-\\nsented by Hoare in the weakest precondition calculus [12] or pre-post con-\\nditions of the design by contracts approach [14]. Invariants have proved\\nto be crucial in various fields of software engineering such as specifica-\\ntion refinement, software evolution or software verification. Unfortunately,\\nwriting invariants is a tedious task and few programmers write program\\ninvariants by themselves.\\n\\nIn order to palliate this problem, a trend of research aims at inferring\\ninvariants a posteriori. In this case, invariants correspond to the actual\\nbehaviors of programs, not to their intended behaviors.\\n\\nA common approach is to use static analysis, which infers invariants\\nfrom the source code. For example, abstract interpretation-based analyses\\n\\n⋆ In A. Serebrenik and S. Muñoz-Hernández (editors), Proceedings of the 15th Work-\\nshop on Logic-based methods in Programming Environments, October 2005, Spain.\\nCOmputer Research Repository (http://www.acm.org/corr/), cs.SE/0508108; whole\\nproceedings: cs.PL/0508078.\\n\\nhttp://arXiv.org/abs/cs/0508108v1\\nhttp://www.acm.org/corr/\\nhttp://arXiv.org/abs/cs/0508108\\nhttp://arXiv.org/abs/cs/0508078\\n\\n\\n2\\n\\ngenerate different kinds of invariants, depending on the abstract domain\\nused : intervals [3], polyhedra [4] or octagons [15], to name a few. These\\nmethods generate sound invariants but the abstractions used to address\\nproblems of termination and complexity may lead to a weak accuracy.\\n\\nErnst et al. introduced Daikon, a tool performing dynamic inference\\nof properties using actual values computed during program executions\\n[6]. The advantage is that the generated properties are in general more\\nprecise than those generated with a static inference. The drawback of\\nthis method is that the properties may not hold for particular executions.\\nThey are therefore likely only invariants. Proving likely invariants to be\\ncorrect would make them sound, while being in general more precise than\\nstatically inferred invariants.\\n\\nIn this paper, we present work in progress regarding a constraint-based\\napproach to verify likely invariants by refutation. We have restrained the\\npresentation to the validation of likely invariants generated by Daikon.\\nNevertheless, others likely invariants can be checked with this approach.\\nFor example, a user could test his program against properties that he\\nknows it is supposed to have. The idea of the approach is, firstly, to gener-\\nate a constraint system, CS, modeling an imperative program. To do this,\\nwe use the translation of an imperative program into CLP(FD) presented\\nby Gotlieb et al. [8], which has already proved to be useful in structural\\ntesting [9]. This transformation can deal with a large subset of C/C++\\nlanguage, including floating point numbers [1] and a restricted class of\\npointers [10]. Then, we transform a likely invariant into a constraint I.\\nFinally, we try to find a solution of the constraint system CS∧¬I : if the\\nconstraint solver finds a solution, then the likely invariant is spurious. If\\nthe solver finds that there is no solution, then the likely invariant is an in-\\nvariant. Unfortunately, the resolution might not terminate or might take\\ntoo long. In these cases, nothing can be concluded. From a declarative\\npoint of view, this approach is very similar to the verification of program\\nbased on Horn Logic Denotations [11]. The difference is the use of con-\\nstraint logic to express the semantics of an imperative language instead\\nof pure Horn logic. When running the verification, Horn logic leads to a\\ngenerate-and-test method, whereas constraint logic leads to a propagate-\\ngenerate-and-test method. We expect our approach to be more efficient\\nbecause the propagation should reduce the number of test cases.\\n\\n', 'The different steps of our approach are detailed on a motivating ex-\\nample. Three likely invariants are generated by a dynamic inference. By\\napplying the method presented here, two of them are disproved and the\\nother is proved.\\n\\n\\n\\n3\\n\\nThe contribution of the approach, as illustrated on our example, is to\\nbe able to both prove or disprove some likely invariants. In the literature,\\nsimilar techniques are dedicated to either one or the other. Jackson and\\nVaziri use a constraint solving-based approach that only allows them to\\ndisprove likely invariants [13]. Nimmer and Ernst present an experiment\\nto prove the correctness of likely invariants using the static checker ESC-\\nJava [2,16]. When ESC-Java fails to prove a likely invariant, it might be\\ndue to the lack of an assertion or precondition rather than to an actual\\nerror. Because of this point, ESC-Java cannot disprove spurious likely\\ninvariants.\\n\\nSection 2 briefly describes the work of Ernst et al. on dynamic in-\\nference of likely invariants. Section 3 presents our motivating example.\\nThe dynamic analysis of Ernst et al. is used to infer invariants on this\\nprogram. Section 4 summarizes the translation of an imperative program\\ninto a constraint system. Section 5 illustrates how we suggest to refute\\nor prove a likely invariant using constraint solving. Section 6 discusses\\ndifficulties encountered with our approach. Finally, section 7 concludes\\nthe paper.\\n\\n2 Dynamic inference of invariants\\n\\nThis section briefly describes the seminal work of Ernst et al. on dynamic\\ninference of likely invariants [6].\\n\\nPrevious work about the inference of program invariants used static\\nanalyses. Results of such analyses are sound, which is very important\\nfor program invariants. The counterpart is that the approximations and\\ncomplex algorithms required to achieve soundness may lead to a weak\\naccuracy.\\n\\nErnst et al. propose a compromise where the soundness of the results\\nis not guaranteed in order to gain accuracy. They use dynamic analyses\\nthat compute likely invariants from data collected during executions. The\\nunderlying idea is that, if a property holds over many executions, then it\\nhas good chances to be an invariant.\\n\\nDaikon is a tool that implements the dynamic inference of likely invari-\\nants in four steps. Firstly, the program is instrumented to automatically\\ntrace values of variables of interest during execution. Secondly, a test\\nsuite is executed on this new program. The data collected during these\\nexecutions are stored in a database. Thirdly, the set of potential likely in-\\nvariants is generated. Daikon uses a pool of relationships to automatically\\ngenerate all potential invariants between variables that can be compared.\\n\\n\\n\\n4\\n\\nint foo (int n, int r){\\nint s = 0;\\nwhile (n > 0) {\\n\\nn −−;\\nif (s == 0){\\n\\ns = 1;\\nr + +;\\n\\n}\\nelse {\\n\\ns = 0;\\nr −−;\\n\\n}\\n}\\n\\nreturn r;\\n}\\n\\nFigure1. A toy example : the foo program\\n\\nComparability between variables is discussed in [7]. Examples of possible\\ninvariants are equalities with a constant (e.g. x = a), non-linear rela-\\ntionships among variables (e.g. z = gcd(x, y)) or ordering relationships\\nbetween variables (e.g. x > y). Additional relationships involving at most\\nthree variables are trivial to add. Finally, the set of possible invariants\\nso-generated is checked against the execution data stored in the database.\\nPossible invariants that are not falsified during this checking are reported\\nto be likely invariants.\\n\\nIn practice, the complexity of the Daikon algorithm tends to be pro-\\nportional to the number of detected invariants. A lot of research is done\\naround Daikon to improve the efficiency and accuracy of the inference.\\n\\n3 Running example\\n\\nThis section presents an example of dynamic inference of likely invariants\\nas presented in section 2. Figure 1 shows the foo C program. This program\\ntakes two input values : n and r. It returns r if n is negative. Else, it\\nreturns r if n is even and r + 1 if n is odd.\\n\\nWe have used Daikon, the tool presented in section 2, to infer likely\\nprogram invariants of the foo program. We used an all-branch covering\\ntest suite of 25 test cases. In these test cases, the loop is unfolded from 0\\nto 454 times. With this test suite, the inference configured in the default\\nmode resulted in three likely invariants at the exit point of the program :\\n\\n1. orig(r) = 0 =⇒ return = 0\\n\\n\\n\\n5\\n\\n2. return = 0 =⇒ orig(r) = 0\\n\\n3. return ≥ orig(r)\\n\\nIn these likely invariants, orig(r) corresponds to the value of variable r\\n\\nat the entry point of the program and return is the value returned by the\\nprogram. These likely invariants are not trivial, as they represent a partial\\nspecification of a loop. In particular, likely invariant 3 is complicated to\\ninfer statically. Indeed, it requires to detect that the executed branch of\\nthe conditional alternates at each loop unfolding in such a way that the\\nvalue of r cannot become lower than orig(r). Likely invariants 1 and 2 are\\n', 'also difficult to infer as they can be seen as a disjunction of two properties.\\nFor example, likely invariant 1 is actually orig(r) 6= 0 ∨ return = 0.\\n\\n4 Translation of an imperative program into a constraint\\n\\nsystem\\n\\nThis section describes the first step of our approach to validate likely in-\\nvariants, namely translating an imperative program into constraint logic\\nprogramming on finite domains (CLP(FD)). More details about the trans-\\nformation can be found in [8].\\n\\nCLP(FD) is an extension of logic programming. In CLP(FD) pro-\\ngrams, logical variables are assigned a domain and relations between vari-\\nables are described with constraints. A solution to a CLP(FD) program\\nis a valuation of every variable in its own domain such that no constraint\\nis falsified. Solutions are find using two mechanisms : propagation and\\nenumeration. Propagation uses domain information of each variable to\\nreduce domains of other variables. When no more propagation can be\\ndone, enumeration, also called labeling, assigns values to variables to find\\na solution. Note that each time a variable is assigned a value, a new\\npropagation phase takes this new information into account.\\n\\nThe goal of the transformation described in the following is to gener-\\nate a CLP(FD) constraint between the input and output variables of an\\nimperative program. Values for which this constraint is satisfied are those\\nwho correspond to an existing execution of the program. More formally, if\\nIn is the list of input variables of the program and Out the list of output\\nvariables, a constraint clp prog(In,Out) is generated. If the pair (I,O)\\nis a solution of clp prog then the execution of the original program on\\ninputs I returns values O.\\n\\nThe translation uses the SSA-form as an intermediary form of the\\nprogram. The instructions of the intermediary program are transformed\\n\\n\\n\\n6\\n\\ninto constraints. In particular, specific operators are designed to deal with\\ncontrol structures.\\n\\n4.1 The SSA-form\\n\\nThe SSA-form is an intermediate representation of imperative programs\\nwhich prepares the translation into CLP(FD). It has originally been pre-\\nsented by Cytron et al. to optimize compilers [5]. The SSA form is a\\nsemantically equivalent version of a program where each variable has a\\nunique definition and every use of this variable is reached by the defini-\\ntion.\\n\\nThe SSA-form is relevant here because logical variables in CLP(FD)\\nprograms can be assigned only once whereas, in imperative programs not\\nin SSA-form, variables can be assigned many times.\\n\\nEvery program can be transformed into SSA by renaming the uses and\\ndefinitions of the variables. For example i = i+ 1; j = j ∗ i is transformed\\ninto i2 = i1+1; j2 = j1∗i2. At the junction nodes of the control structures,\\nSSA introduces special assignments ,called φ-functions, to merge several\\ndefinitions of the same variable : −→v2 = φ(−→v0 ,−→v1) assigns the values of −→v0 in\\n−→v2 if the flow comes from the first branch of the decision, −→v1 otherwise. In\\nthe case of conditional structures, −→v0 and −→v1 are respectively the vectors\\nof defined variables in the then and else branches. −→v2 is the vector of these\\nvariables out of the conditional structure. Depending on the validity of\\nthe condition, −→v2 = −→v0 or −→v2 = −→v1 .\\n\\n4.2 Instructions as CLP(FD) constraints\\n\\nThe instructions of the original program are transformed into constraints\\nbetween logical variables. Type declarations are translated into domain\\nconstraints. For example, the declaration of a signed integer x is translated\\ninto : X ∈ −231..231 − 1 where X is a logical FD variable.\\n\\nAssignments and decisions are translated into arithmetical con-\\nstraints. For example, assignment x = x + 1 is converted into the SSA\\nform x2 = x1 + 1 and further translated into X2 = X1 + 1 where X1,X2\\n\\nare logical FD variables.\\n\\nThe main difficulty is to transform control structures into constraints.\\nAs described in the following, two specific operators are used.\\n\\nConditional statements The conditional statement is treated with a\\nspecific combinator ite/6. Arguments of ite/6 are the variables that\\n\\n\\n\\n7\\n\\nappear in the φ-functions and the constraints generated from the different\\nparts of the original conditional statement. Note that other combinators\\nmay be nested into the arguments of ite/6. The SSA if else statement :\\n\\nif(exp) {stmt} else {stmt} −→v2 = φ(−→v0 ,\\n−→v1)\\n\\nis translated into ite(CCond,\\n−→v0 ,\\n\\n−→v1 ,\\n−→v2 , CThen, CElse) where CCond is a\\n\\nconstraint generated by the analysis of exp and CThen (resp. CElse) is a\\nset of constraints generated by the analysis of the then branch (resp. else\\nbranch).\\n\\nThe combinator ite/6 is defined as :\\n\\nDefinition 1 ite/6\\n\\nite(CCond,\\n−→v0 ,\\n\\n−→v1 ,\\n−→v2 , CThen, CElse) : −\\n\\nCCond −→ CThen ∧ −→v2 = −→v0 ,\\n¬CCond −→ CElse ∧\\n\\n−→v2 = −→v1,\\n¬(CCond ∧ CThen ∧ −→v2 = −→v0) −→ ¬CCond ∧ CElse ∧\\n\\n−→v2 = −→v1,\\n¬(¬CCond ∧ CElse ∧\\n\\n−→v2 = −→v1) −→ CCond ∧ CThen ∧ −→v2 = −→v0,\\n(CCond ∧ CThen ∧ −→v2 = −→v0) ⊻ (¬CCond ∧ CElse ∧\\n\\n−→v2 = −→v1).\\n\\n', 'This definition uses guarded-constraints. A guarded-constraint\\nhead −→ tail rewrites into tail if the constraint head is entailed by\\nthe constraint store. The first two guarded-constraints straightforwardly\\nresult from the operational semantics of the if else statement whereas\\nthe third and the fourth correspond to a backward reasoning. In this\\ncase, values of −→v2 are used to deduce information concerning the flow.\\nThe last constraint contains the constructive disjunction operator ⊻. This\\noperator removes from the domains of the variables the values that are\\nremoved whatever the executed part of the disjunction is. For example,\\nif the constraint ite(...,\\n\\n[\\n\\nX0\\n\\n]\\n\\n,\\n[\\n\\nX1\\n\\n]\\n\\n,\\n[\\n\\nX2\\n\\n]\\n\\n,X0 = 1,X1 = 3) stands, the\\nconstructive disjunction operator deduces that X2 ∈ {1, 3}.\\n\\nIterative statements The SSA while statement\\n\\n−→v2 = φ(−→v0 ,−→v1) while(exp) {stmt}\\n\\nis treated with the recursive specific combinator\\nw(CCond,\\n\\n−→v0 ,\\n−→v1 ,\\n\\n−→v2 , CBody) where CCond is a constraint generated by\\nthe analysis of exp and CBody is a set of constraints generated by the\\nanalysis of stmt.\\n\\n\\n\\n8\\n\\nDefinition 2 w/5\\n\\nw(CCond,\\n−→v0 ,\\n\\n−→v1 ,\\n−→v2 , CBody) : −\\n\\nCCond −→ (CBody ∧ w(C ′\\n\\nCond,\\n−→v1 ,\\n\\n−→v3 ,−→v2 , C\\n′\\n\\nBody)),\\n\\n¬CCond −→ −→v2 = −→v0,\\n¬(CCond ∧ CBody) −→ (¬CCond ∧\\n\\n−→v2 = −→v0),\\n¬(¬CCond ∧\\n\\n−→v0 = −→v2) −→ (CCond ∧ CBody∧\\nw(C ′\\n\\nCond,\\n−→v1 ,\\n\\n−→v3 ,\\n−→v2 , C\\n\\n′\\n\\nBody)).\\n\\nNote that combinator w/5 is dynamic : new variables and new con-\\nstraints are generated during its evaluation. In particular, the vector −→v3 is\\na vector of fresh variables. The first and the last guarded constraints both\\nmake a recursive call to w. The parameters of this new w are not CCond\\n\\nand CBody but new constraints C ′\\n\\nCond and C ′\\n\\nBody where some variables\\n\\nhave been substituted by variables of −→v1 and −→v3 to model the fact that\\nthe loop has already been entered once.\\n\\nThe first two guarded–constraints are deduced from the operational\\nsemantics of the while statement. The third constraint tells that, if the\\nconstraints extracted from the body are proved to be contradictory with\\nthe current constraint system then the loop cannot be entered. The last\\nconstraint models the fact that, if any variable possesses distinct values\\nbefore and after the execution of the while statement, then the loop must\\nbe entered at least once.\\n\\n4.3 Translation of the foo program into constraints\\n\\nThis section presents the translation of the foo program of Figure 1 into\\na constraint system. By applying the translation described above, the\\nconstraint system presented in Figure 2 is generated.\\n\\nFor the sake of clarity, we omit the translation into SSA-form. That is\\nwhy the constraint system presented on Figure 2 does not explicitly show\\nall the SSA-names. In fact, the variable names that are in the parameters\\nof the w and ite operators must be considered only as syntactical names.\\nDepending on the cases, these names are replaced by logical variables\\n\\nthat are in the vectors\\n−−→\\nVold,\\n\\n−−→\\nVnew,\\n\\n−−−→\\nVfinal,\\n\\n−−−→\\nVthen,\\n\\n−−→\\nVelse or\\n\\n−−−→\\nVf ite. Constraints\\n\\nthat correspond to the type declarations of variables are also omitted.\\nAs the transformation faithfully models the operational semantics of\\n\\nC programs, the constraint system can be executed just like the original\\nC program. For example, if we instantiate N0 to 5 and R0 to 3, constraint\\npropagation leads to the instantiation of RET to 4, which is the result of\\nthe original program on the same entries.\\n\\n\\n\\n9\\n\\nint foo (int n, int r){\\nint s = 0;\\nwhile (n > 0) {\\n\\nn −−;\\nif (s == 0){\\n\\ns = 1;\\nr + +;\\n\\n}\\nelse {\\n\\ns = 0;\\nr −−;\\n\\n}\\n}\\n\\nreturn r;\\n}\\n\\nfoo([N0 , R0],[RET ]):-\\nS0 = 0,\\n\\nw(n > 0,\\n−−→\\nVold,\\n\\n−−−→\\nVnew ,\\n\\n−−−→\\nVfinal,\\n\\n[n = n − 1,\\n\\nite(s = 0,\\n−−−→\\nVthen,\\n\\n−−→\\nVelse,\\n\\n−−−→\\nVf ite,\\n\\n[s = 1, r = r + 1],\\n[s = 0, r = r − 1])]),\\n\\nRET = Rfinal.\\n\\nFigure2. Translation of the foo program into a constraint system\\n\\n5 Validation of likely invariants\\n\\nIn this section, we informally introduce a method to prove or disprove\\nlikely invariants. Section 5.1 explains how we transform the problem of\\ninvariant validation into a constraint satisfaction problem and Section 5.2\\nillustrates the behavior of constraint solvers for the running example.\\n\\n5.1 A constraint solving problem\\n\\nSection 4 presented a model of an imperative program as a constraint\\nsystem. This constraint system, denoted by CS, is a relation between\\nthe input variables and the output variables. If (X,Y ) is a solution of\\nCS, X and Y being respectively input and output values, then there\\nexists a finite execution of the original program starting with input X\\n\\nand returning Y .\\n\\nA likely invariant, denoted by I, can be seen as one more constraint.\\nThis new constraint should be implied by CS if I really is an invariant.\\nWe want to prove\\n\\nCS � I\\n\\nSuch a proof can be established by refutation using constraint solving :\\n\\nCS � I ⇔ Sol(CS ∧ ¬I) = ∅\\n\\n\\n\\n10\\n\\nIn this equation, Sol(CS ∧ ¬I) denotes the set of solutions of the\\nconstraint system CS ∧ ¬I.\\n\\n', 'When solving the refutation request CS ∧ ¬I, there are three cases :\\n\\n1. there exists a solution (X,Y ), which means that the execution starting\\nfrom X and terminating in Y does not verify the likely invariant I.\\nThus, I is spurious and (X,Y ) is a counter-example.\\n\\n2. there is no solution to this problem. It means that I really is an\\ninvariant.\\n\\n3. the user runs out of patience. It can be due either to a too long compu-\\ntation or a non-terminating computation. Nothing can be concluded.\\n\\nAs already mentioned in the introduction, the method presented by\\nNimmer and Ernst [16] can prove that a program verifies a likely invariant.\\nHowever, if no proof can be established, it might be due to the fact that\\nthere is not enough axioms. For example, loop invariants must be provided\\nby users in order to soundly prove properties [2]. On the contrary, in the\\nwork of Jackson and Vaziri [13], it is possible to find a counter-example\\nthat does not verify the property. However, if none can be found, it can\\nbe due either to the fact that the likely invariant is indeed an invariant\\nor to the inaccuracy of the under-approximation. For example, as the\\nnumber of loop unfoldings is bounded by a value k, there might exists a\\ncounter-example that unfolds k + 1 times a loop.\\n\\nIn other words, at the question does the program verify the property ?,\\nNimmer and Ernst answer “yes” or “maybe”, Jackson and Vaziri answer\\n“no” or “maybe” and our method answers “yes”, “no” or “maybe”.\\n\\n5.2 Validation of the invariants of the running example\\n\\nIn this section, we illustrate our approach on the running example. The\\nfirst likely invariant inferred by Daikon for the foo program is\\n\\norig(r) = 0 =⇒ return = 0.\\n\\nAs explained in the previous paragraph, the first step of the validation\\nconsists in adding the negation of the likely invariant to the program. The\\nrequest sent to the solver is therefore\\n\\n: −foo([N0, R0], RET ), R0 = 0, RET \\\\ = 0. (1)\\n\\nAfter propagation the solver answers :\\n\\nN0 ∈ [inf, sup], RET ∈ [inf,−1] ∪ [1, sup], R0 = 0 (2)\\n\\n\\n\\n11\\n\\nThe propagation alone did not allow the solver to find inconsistencies in\\nthe constraint system. Nothing can be deduced concerning the invariant\\nunless concrete values for N0 and RET are found. An enumeration step on\\nvariables N0 and RET must be done. Note that variables need to have\\na domain for labeling. As the logical variables correspond to integers\\nin the original imperative program, their bounds are MIN INT and\\nMAX INT . The request is now :\\n\\n: −domain([N0, RET ],MIN INT,MAX INT ), foo([N0, R0], RET ),\\n\\nR0 = 0, RET \\\\ = 0, labeling([N0, RET ]). (3)\\n\\nAfter propagation and enumeration, the solver finds a solution\\n\\nN0 = 1, R0 = 0, RET = 1. (4)\\n\\nIt means that the execution of the original program with input\\nn = 1, r = 0 returns ret = 1. This execution is a counter-example of\\nthe likely invariant orig(r) = 0 =⇒ return = 0. It is therefore disproved.\\n\\nThe second likely invariant inferred by Daikon for the foo program is\\n\\nreturn = 0 =⇒ orig(r) = 0.\\n\\nIn the same way as above, a counter-example is found :\\n\\nn = 1, r = −1, return = 0.\\n\\nThe second likely invariant is therefore also disproved.\\n\\nThe third likely invariant inferred by Daikon for the foo program is\\n\\nreturn ≥ orig(r).\\n\\nRepeating the operations previously detailed, the following request is sent\\nto the constraint solver :\\n\\n: −foo([N0, R0], RET ),\\n\\nR0 > RET. (5)\\n\\nThis time, without any enumeration, the constraint solver answers “no”,\\nmeaning that there is no solution to this problem. The third likely invari-\\nant is therefore proved to be an invariant.\\n\\n\\n\\n12\\n\\nThe behavior of the w operator on the latter refutation is as follows.\\nInitially, the w operator is instantiated to\\n\\nw(N0 > 0, [R0, N0, S0], [R1, N1, S1], [RET,N2, S2], CBody)\\n\\nWe have not expanded the constraint system of the body for readability\\nreasons. The fourth guarded constraint of the w operator instantiated for\\nthe foo program is logically equivalent to what follows.\\n\\nN0 > 0 ∨ (R0 6= RET ) −→ (N0 > 0 ∧ CBody∧\\n\\nw(N1 > 0, [R1, N1, S1], [R3, N3, S3], [RET,N2, S2], C\\n′\\n\\nBody))).\\n\\nAs R0 > RET (constraint 5), it is impossible for R0 to be equal to\\nRET . The guard of the previous constraint is entailed. The loop must\\ntherefore be entered and constraints of CBody are set up\\n\\nN1 = N0 − 1. (6)\\n\\nAs S0 = 0 (first constraint of the foo program), the ite operator set up\\nconstraints corresponding to the then branch\\n\\nS1 = 1 (7)\\n\\nR1 = R0 + 1 (8)\\n\\nDue to constraints 5 and 8 the following property is true\\n\\nR1 > R0 > RET, (9)\\n\\ntherefore, it is impossible to have R1 = RET . Consequently, the loop\\nis unfold again. Values [R3, N3, S3] are constrained by clones of con-\\nstraints 6 and 8. The same reasoning applies until propagation deduces\\nthat n cannot be greater than 0. At the beginning, n is in the interval\\n[MIN INT,MAX INT ] so after MAX INT iterations n is in the in-\\nterval [MIN INT, 0] because of constraint 6 and all its clones. Thus,\\n\\nNMAX INT ≤ 0 (10)\\n\\nAt this point, RMAX INT > RET . ', 'The second guarded-constraint of the\\nw operator instantiated for the foo program is :\\n\\n¬Nk > 0 −→ [Rk, Nk, Sk] = [RET,N2, S2]\\n\\n\\n\\n13\\n\\nWhen k = MAX INT , the guard is entailed because of constraint 10.\\nConsequently, the constraint\\n\\nRET = RMAX INT (11)\\n\\nis set up. It makes the constraint store unsatisfiable, and this is detected\\nby the constraint solver. As a consequence, the third invariant is proved\\nto be true.\\n\\n6 Discussion\\n\\nThe previous section presented three examples of validation of likely in-\\nvariants by constraint solving. Two likely invariants were disproved by\\nthe exhibition of a counter-example. The last one was proved to be an\\ninvariant.\\n\\nA point that we have not developed yet is the case where the resolution\\ndoes not terminate or is too long. There are two main reasons why these\\ncases can happen. The first reason is due to the loops. Indeed, as the model\\nwe use describes the operational semantics of a program, if the original\\nprogram does not terminate, then the resolution will not terminate.\\n\\nThe second reason is a problem of propagation in the constraint sys-\\ntem. As presented in section 4, the operators ite and w are defined via\\nguarded-constraints. Consequently, if the entailment of none of the guards\\ncan be deduced from the current store of constraints, then the resolution\\nof the constraint system suspends. The problem is that our system is very\\nspecific and usual methods of entailment-checking are inefficient in this\\ncontext : domains of variables are very large, constraint store is dynamic\\nand constraints used can be non-linear.\\n\\nThe consequence of this lack of propagation is that, in bad cases,\\nalmost all the possible values of input variables will have to be enumer-\\nated to prove or disprove likely invariants. In such a case, our approach\\nbecomes a generate-and-test method, which is intractable when the do-\\nmains of input variables are large. Future work will consist in improving\\nthe propagation inside our specific constraint system.\\n\\n7 Conclusion\\n\\nIn this paper, we have presented an approach to verify the correctness of\\nlikely invariants using constraint solving. We have illustrated its principles\\non a toy example.\\n\\n\\n\\n14\\n\\nThe originality of this method is that some likely invariants are dis-\\nproved and others are proved. This differs from other methods that\\nare dedicated to only one of these capabilities. Methods using under-\\napproximations can only disprove likely invariants whereas methods us-\\ning over-approximation can only prove likely invariants. We are not using\\nany approximation, it allows us to prove and disprove but prevents us\\nto guarantee termination and good performances. Consequently, the key\\npoint of our approach is to have a good propagation inside the constraint\\nsystem in order to reduce as much as possible the number of cases where\\nwe cannot conclude.\\n\\nAcknowledgments We thank the anonymous referees for their helpful com-\\nments.\\n\\nReferences\\n\\n1. B. Botella, A. Gotlieb, and C. Michel. Symbolic execution of floating-point com-\\nputations. Software Testing, Verification and Reliability Journal, 2005.\\n\\n2. L. Burdy, Y. Cheon, D. R. Cok, M. D. Ernst, J. R. Kiniry, G. T. Leavens, K. R.\\nLeino, and E. Poll. An overview of JML tools and applications. International\\n\\nJournal on Software Tools for Technology Transfer, 7(3):212–232, 2005.\\n3. P. Cousot and R. Cousot. Abstract interpretation : A unified lattice model for static\\n\\nanalysis of programs by construction or approximation of fixpoints. In Proceedings\\n\\nof Symposium on Principles of Programming Languages, pages 238–252. ACM,\\n1977.\\n\\n4. P. Cousot and N. Halbwachs. Automatic discovery of linear restraints among\\nvariables of a program. In Proceedings of Symposium on Principles of Programming\\n\\nLanguages, pages 84–96. ACM, 1978.\\n5. R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. Efficiently\\n\\ncomputing static single assignment form and the control dependence graph. ACM\\n\\nTransactions on Programming Languages and Systems, 13(4):451–490, 1991.\\n6. M. D. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin. Dynamically discovering\\n\\nlikely program invariants to support program evolution. IEEE Transactions on\\n\\nSoftware Engineering, 27(2):99–123, 2001.\\n7. M. D. Ernst, A. Czeisler, W. G. Griswold, and D. Notkin. Quickly detecting\\n\\nrelevant program invariants. In Proceedings of the International Conference on\\n\\nSoftware Engineering, pages 449–458. IEEE, 2000.\\n8. A. Gotlieb, B. Botella, and M. Rueher. Automatic test data generation using\\n\\nconstraint solving techniques. In Proceedings of the International Symposium on\\n\\nSoftware Testing and Analysis, pages 53–62. ACM, 1998.\\n9. A. Gotlieb, B. Botella, and M. Rueher. A CLP framework for computing structural\\n\\ntest data. In First International Conference on Computational Logic, pages 399–\\n413. Springer, 2000.\\n\\n10. A. Gotlieb, T. Denmat, and B. Botella. Goal-oriented test data generation for\\nprograms with pointer variables. In Proceedings of the International Computer\\n\\n', 'Software and Applications Conference. IEEE, 2005.\\n\\n\\n\\n15\\n\\n11. G. Gupta. Horn logic denotations and their applications. In K. R. Apt, V. W.\\nMarek, M. Truszczynski, and D. S. Warren, editors, The Logic Programming\\n\\nParadigm : A 25-Year Perspective, pages 127–159. Springer, 1999.\\n12. C. A. R. Hoare. An axiomatic basis for computer programming. Communications\\n\\nof the ACM, 12(10):576–580, 1969.\\n13. D. Jackson and M. Vaziri. Finding bugs with a constraint solver. In Proceedings\\n\\nof the International Symposium on Software Testing and Analysis, pages 14–25.\\nACM, 2000.\\n\\n14. B. Meyer. Object-Oriented Software Construction. Prentice Hall, second edition,\\n1997.\\n\\n15. A. Miné. Relational abstract domains for the detection of floating-point run-time\\nerrors. In Proceedings of the European Symposium on Programming, volume 2986\\nof LNCS, pages 3–17. Springer, 2004.\\n\\n16. J. W. Nimmer and M. D. Ernst. Automatic generation of program specifications.\\nIn Proceedings of the International Symposium on Software Testing and Analysis,\\npages 229–239. ACM, 2002.\\n\\n\\n\\tProving or Disproving Likely Invariants  with Constraint Reasoning \\n\\n'], 'name': '0508108v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0508/0508108v1.pdf', 'vectorized': None}, {'@search.score': 18.498878, '@search.rerankerScore': 3.4623162746429443, '@search.captions': [{'text': 'The key notions of CLP are those of an algebra and an associated constraint solver over a class of constraints, namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNzAxLzA3MDEwODJ2MS5wZGY1', 'title': None, 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n07\\n\\n01\\n08\\n\\n2v\\n1 \\n\\n [\\ncs\\n\\n.P\\nL\\n\\n] \\n 1\\n\\n2 \\nJa\\n\\nn \\n20\\n\\n07\\n\\nUnder consideration for publication in Theory and Practice of Logic Programming 1\\n\\nRecurrence with affine level mappings is P-time\\ndecidable for CLP(R)\\n\\nTechnical note\\n\\nFRED MESNARD\\nIREMIA, Université de la Réunion, France\\n\\n(e-mail: Frederic.Mesnard@univ-reunion.fr)\\n\\nALEXANDER SEREBRENIK\\nLaboratory for Quality Software (LaQuSo), T.U. Eindhoven, The Netherlands\\n\\n(e-mail: A.Serebrenik@tue.nl)\\n\\nsubmitted 2 May 2006; revised 13 October 2006; accepted 4 January 2007\\n\\nAbstract\\n\\nIn this paper we introduce a class of constraint logic programs such that their termination can be\\nproved by using affine level mappings. We show that membership to this class is decidable in poly-\\nnomial time.\\n\\nKEYWORDS: constraint logic programming – termination – decidability\\n\\n1 Introduction\\n\\nTermination is well-known to be one of the crucial properties of software verification.\\nLogic programming, and more generally constraint logic programming (CLP), with their\\nstrong theoretical basis lend themselves easily to termination analysis as witnessed by a\\nvery intensive research in the area.\\n\\nIn this paper, which is a revised version of (Serebrenik and Mesnard 2004), we study\\ndecidability of termination for CLP(C) programs for a given constraint domain C. In\\ngeneral, decidability depends on the constraint domain C. On the one hand, Devienne\\net al. (1993) have established undecidability of termination for one-rule binary CLP(H)\\nprograms, where H is the domain of Herbrand terms. On the other hand, Datalog, i.e.,\\nlogic programming with no function symbols, provides an example of a constraint pro-\\ngramming language such that termination is decidable. We note that the decidability of\\nthe related problem of boundedness for Datalog queries has been studied, for instance,\\nin (Afrati et al. 2005; Marcinkowski 1996). For constraint domains with the undecidable\\ntermination property, we are interested in subclasses of programs such that termination is\\ndecidable for these subclasses. A trivial example is the subclass of non-recursive programs.\\n\\nWe organise the paper as follows. After the preliminary remarks of Section 2, in Sec-\\ntion 3 we present our main result. Section 4 reviews related results before our conclusion.\\n\\nhttp://arXiv.org/abs/cs/0701082v1\\n\\n\\n2 Fred Mesnard and Alexander Serebrenik\\n\\n2 Preliminaries\\n\\nFor CLP-related definitions, we follow (Jaffar et al. 1998). Extensive introductions to CLP\\ncan be found in (Jaffar and Maher 1994; Marriott and Stuckey 1998). The key notions of\\nCLP are those of an algebra and an associated constraint solver over a class of constraints,\\nnamely a set of first order formulas including the always satisfiable constraint true, the un-\\nsatisfiable constraint false, and closed under variable renaming, conjunction and existential\\nquantification. If c is a constraint, we write ∃c for its existential closure. We consider ideal\\nCLP(C), i.e., we require the existence of a constraint solver solvC mapping in finite time\\neach constraint to true or false such that if solvC(c) = false then the constraint ∃c is\\nfalse with respect to C and if solvC(c) = true then the constraint ∃c is true with respect to\\nC. The associated domain is denoted DC. Given a constraint c, a solution of c is a mapping\\nθ from the set of variables to DC such that cθ is true with respect to C. The set of predicate\\nsymbols associated with C is denoted ΠC. We are interested in the following domains and\\nlanguages:\\n\\n• N. The predicate symbols are = and ≥, the function symbols are 0, 1, and +.\\n• Q and R. The predicate and function symbols are as above. Q+ and R+ restrict Q\\n\\nand R to non-negative numbers.\\n\\nGiven a CLP(C)-program P, we define ΠP as the set of user-defined predicate symbols\\nappearing in P. We restrict our attention to flat programs, i.e., finite sets of rules in a flat\\nform. So each rule is of form: either q0(ỹ0)← c or q0(ỹ0)← c,q1(ỹ1), . . . ,qn(ỹn) where c\\nis a constraint, q0, . . . ,qn ∈ ΠP, ỹ0, . . . , ỹn denote tuples of distinct variables,\\n\\nTn\\ni=0 ỹi = ∅,\\n\\nand the set of free variables of the constraint c is included in\\nSn\\n\\ni=0 ỹi. Flat queries are de-\\nfined accordingly. A binary program is a flat program such that all rules have no more\\nthan one user-defined body subgoal. The C-base BC\\n\\nP is defined as {p(d1, . . . ,dn) | p ∈\\nΠP,(d1, . . . ,dn) ∈ (DC)n}. For a flat query Q of the form c,A1, . . . ,An, the set of ground\\ninstances of Q, denoted groundC(Q), is the set of conjunctions of the form A1θ, . . . ,Anθ\\nwhere θ is a solution of c. The notion of groundedness is extended to flat rules and pro-\\ngrams.\\n\\nExample 1\\nConsider the following CLP(Q) program P:\\n\\nr1 p(x) ← x = 2.\\n\\nr2 p(x) ← 0 = 1.\\n\\nr3 p(x) ← 72≥ x,y = x + 1, p(y).\\n\\nThis program is a binary program, groundQ(r1) is {p(2)}, groundQ(r2) is ∅, groundQ(r3)\\n\\nis an infinite set that contains, among others, p(72)← p(73) and p(1/2)← p(3/2), and\\ngroundQ(P) = groundQ(r1)∪ groundQ(r2)∪ groundQ(r3). ', 'Note that ground instances do\\nnot contain any constraint.\\n\\nWe now discuss the operational semantics of CLP-programs we consider in this paper.\\nA state of computation is a pair 〈A1, . . . ,An‖c〉. We further assume that one of the atoms in\\nA1, . . . ,An, say Ai, is selected for resolution by a selection rule. The operational semantics\\ncan be expressed by means of the following rewriting rules:\\n\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 3\\n\\n• 〈A1, . . . ,An‖c〉 rewrites to 〈�‖false〉 if there exists a fresh rule A′i← c′,B1, . . . ,Bm in\\nP such that c∧ (Ai = A′i)∧ c′ is unsatisfiable;\\n• 〈A1, . . . ,An‖c〉 rewrites to 〈A1, . . . ,Ai−1,B1, . . . ,Bm,Ai+1, . . . ,An||c∧Ai = A′i ∧ c′〉 if\\n\\nthere exists a fresh rule A′i← c′,B1, . . . ,Bm in P such that c∧ (Ai = A′i)∧c′ is satisfi-\\nable.\\n\\nA derivation from a state S0 is a finite or infinite sequence of states S0,S1, . . . ,Sn, . . . such\\nthat each Si can be rewritten as Si+1. A ground state is a state 〈A1, . . . ,An‖true〉 where each\\nAi belongs to BC\\n\\nP . We say that a CLP(C) program P is terminating if every derivation start-\\ning from any ground state via any selection rule is finite, under the operational semantics\\ndefined above.\\n\\nTo characterize this notion of termination, we use the notion of level mapping. A level\\nmapping for a constraint domain C is a function | · | : BC\\n\\nP → R. We adapt the idea of recur-\\nrence, originally introduced in (Bezem 1993), to CLP:\\n\\nDefinition 1\\nLet P be a flat CLP(C) program, and | · | : C-base→ R be a level mapping. P is called\\nrecurrent with respect to | · | if there exists a real number ε > 0 such that, for every A←\\nB1, . . . ,Bn ∈ groundC(P), |A| ∈ R+, and |Bi| ∈ R+, |A| ≥ |Bi|+ ε for all i, 1 ≤ i ≤ n. We\\nsay that P is recurrent if there exists a level-mapping such that P is recurrent with respect\\nto it.\\n\\nObserve that rules of the form p(x̃)← c are not taken into account by the definition\\nabove. Moreover, without loss of generality, we may fix ε to 1: if P is recurrent in this\\nnarrow sense, P is trivially recurrent with respect to Definition 1. Conversely, since ε > 0,\\nwe can safely multiply the values of the level mapping by 1/ε.\\n\\nTheorem 1\\n(Bezem 1993) P is recurrent if and only if P is terminating.\\n\\n3 Alm-recurrent programs\\n\\nLet us consider programs that can be analyzed by means of affine level mappings.\\n\\nDefinition 2\\nA level mapping | · | is called affine if for any n-ary predicate symbol p ∈ ΠP, there exist\\nreal numbers µp,i, 0≤ i≤ n, such that for any atom p(e1, . . . ,en) ∈ BC\\n\\nP :\\n\\n|p(e1, . . . ,en)|= µp,0 +\\nn\\n\\n∑\\ni=1\\n\\nµp,iei\\n\\nSo for a given atom p(ẽ), its affine level mapping is a linear combination of ẽ shifted by\\na constant. We can define the class of programs we are interested in:\\n\\nDefinition 3\\nLet P be a flat CLP(C) program. We say that P is alm-recurrent if there exists an affine\\nlevel mapping | · | such that P is recurrent with respect to it.\\n\\n\\n\\n4 Fred Mesnard and Alexander Serebrenik\\n\\nExample 2\\nThe CLP(Q) program P from Example 1 is alm-recurrent with respect to |p(x)|= 73− x.\\n\\nClearly, if P is alm-recurrent, then P is recurrent thus terminating. Let us show that alm-\\nrecurrence can be efficiently decided. We start with proving this result for binary programs.\\n\\nTheorem 2\\nAlm-recurrence of a binary constraint logic program P over Q,Q+,R and R+ is decidable\\nin polynomial time with respect to the size of P.\\n\\nProof\\nThe proof is constructive: we provide a decision procedure for alm-recurrence of binary\\nconstraint logic programs over Q,Q+,R and R+. The decision procedure extends the al-\\ngorithm proposed in (Sohn and Van Gelder 1991) for termination of Prolog programs (ab-\\nstracted as CLP(N) programs) to binary CLP(C) where C is Q,Q+,R or R+. The algo-\\nrithm tries to find an affine level mapping showing that P is alm-recurrent by examining\\neach user-defined predicate symbol p of a binary CLP program P in turn (the precise order\\ndoes not matter). For every rule r, say p(x̃p)← c,q(x̃q), we test the satisfiability of c. For\\nthe domains we consider, it can be done in polynomial time (Khachiyan 1979). If c is not\\nsatisfiable, we disregard this rule. Otherwise, let np and nq be the arities of p and q. For the\\nrule r, recurrence is equivalent to:\\n\\nC |= c→ [|p(x̃p)| ≥ 1 + |q(x̃q)| ∧ |q(x̃q)| ≥ 0] (1)\\n\\nNote that the condition c→ |p(x̃p)| ≥ 0 can be omitted as it is implied by (1). Formula (1)\\nis logically equivalent to C |= c→ |p(x̃p)| ≥ 1+ |q(x̃q)| and C |= c→ |q(x̃q)| ≥ 0. Let x̃p be\\n(xp,1, . . . ,xp,np), x̃q be (xq,1, . . . ,xq,nq) and let µp,0, . . . ,µp,np ,µq,0, . . . ,µq,nq ∈R be such that\\nfor any atom p(e1, . . . ,enp)∈ BC\\n\\nP and any atom q(e1, . . . ,enq)∈BC\\nP : |p(e1, . . . ,enp)|= µp,0 +\\n\\n∑np\\ni=1 µp,iei and |q(e1, . . . ,enq)| = µq,0 + ∑\\n\\nnq\\ni=1 µq,iei. Hence, c should imply (µp,0− µq,0)+\\n\\n∑np\\ni=1 µp,ixp,i + ∑\\n\\nnq\\ni=1(−µq,i)xq,i ≥ 1 and µq,0 + ∑\\n\\nnq\\ni=1 µq,ixq,i ≥ 0. For the sake of uniformity,\\n\\nwe rewrite the second inequality as µq,0 + ∑np\\ni=1 0xp,i + ∑\\n\\nnq\\ni=1 µq,ixq,i ≥ 0. ', 'Both inequalities\\n\\ncan be presented using the scalar product notation as µ̃x̃≥ 1 and µ̃′x̃≥ 0, where:\\n\\nx̃ = (x0,xp,1, . . . ,xp,np ,xq,1, . . . ,xq,nq)\\n\\nx0 is a new variable fixed to 1 and used to obtain the free coefficient in the product\\nµ̃ = (µp,0−µq,0,µp,1, . . . ,µp,np ,−µq,1, . . . ,−µq,nq)\\n\\nµ̃′ = (µq,0,0, . . . ,0,µq,1, . . . ,µq,nq).\\n\\nHence, the binary rule r gives rise to the following two pseudo linear programming\\nproblems. The problems are pseudo linear rather than linear because symbolic parameters\\nappear in the objective functions.\\n\\nminimise θ = µ̃x̃ subject to c∧ x0 = 1 (2)\\n\\nminimise δ = µ̃′x̃ subject to c∧ x0 = 1 (3)\\n\\nWe note that c∧ x0 = 1 is satisfiable as c is satisfiable and x0 is a new variable, and we\\nrewrite c∧x0 = 1 as Ax̃≥ b in the standard way (Schrijver 1986). An affine level mapping\\n| · | ensuring recurrence exists at least for this rule if and only if θ∗ ≥ 1 and δ∗ ≥ 0, where\\nθ∗ and δ∗ denote the minima of the corresponding objective functions. Because of the\\n\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 5\\n\\nsymbolic constants µp,i and µq,i, neither (2) nor (3) is a linear programming problem. Now,\\nthe idea is to consider the dual form:\\n\\nmaximise η = bT ỹ subject to AT ỹ = µ̃T ∧ ỹ≥ 0 (4)\\n\\nmaximise γ = bT z̃ subject to AT z̃ = µ̃′T ∧ z̃≥ 0 (5)\\n\\nwhere ỹ and z̃ are tuples of adequate length of new variables. By the duality theorem of\\nlinear programming which holds in C (see (Schrijver 1986) for instance), we have θ∗ = η∗\\n\\nand δ∗ = γ∗. Furthermore, we observe that µ̃ appears linearly in the dual problem (4).\\nHence the constraints of (4) can be rewritten, by adding η≥ 1 as a set of linear inequations\\ndenoted Sp≥1+q\\n\\nr . Similarly, the constraints of (5) can be rewritten, by adding γ ≥ 0 as a\\nset of linear inequations, denoted Sq≥0\\n\\nr . Let us define defnP(p) as the set of binary rules\\ndefining p in P, Sp as the conjunction\\n\\nV\\n\\nr∈defnP(p)[S\\np≥1+q\\nr ∧Sq≥0\\n\\nr ], and SP as the conjunction\\nV\\n\\np∈ΠP\\nSp. We have by construction SP is satisfiable if and only if there exists a affine level\\n\\nmapping ensuring recurrence of P.\\nMoreover, as P is a finite set of binary rules, computing SP can be done in polynomial\\n\\ntime with respect to the size of P and results in a constraint the size of which is also\\npolynomial with respect to the size of P. Finally, testing satisfiability of SP in Q, Q+, R,\\nand R+ can be done in polynomial time (Khachiyan 1979).\\n\\nExample 3\\nApplying the algorithm to the example 1, we obtain the following two pseudo linear pro-\\ngramming problems corresponding to (2) and (3), respectively:\\n\\nminimise θ = µp,1x1−µp,1x2 subject to 72≥ x1∧ x2 = x1 + 1∧ x0 = 1\\n\\nminimise δ = µp,0 + µp,1x2 subject to 72≥ x1∧ x2 = x1 + 1∧ x0 = 1\\n\\nRewriting the system of constraints as Ax̃ ≥ b and switching to the dual form, we get the\\nsystem SP:\\n\\n\\uf8f1\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f2\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f3\\n\\nη = y1− y2−72 ∗ y3 + y4− y5,\\n\\nη≥ 1,\\n\\ny1− y2 = 0,−y3− y4 + y5 = µp,1,\\n\\ny4− y5 =−µp,1,\\n\\ny1 ≥ 0,\\n\\ny2 ≥ 0,\\n\\ny3 ≥ 0,\\n\\ny4 ≥ 0,\\n\\ny5 ≥ 0\\n\\n\\uf8fc\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8fd\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8fe\\n\\n∪\\n\\n\\uf8f1\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f2\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f3\\n\\nγ = z1− z2−72 ∗ z3 + z4− z5,\\n\\nγ≥ 0,\\n\\nz1− z2 = µp,0,\\n\\n−z3− z4 + z5 = 0,\\n\\nz4− z5 = µp,1,\\n\\nz1 ≥ 0,\\n\\nz2 ≥ 0,\\n\\nz3 ≥ 0,\\n\\nz4 ≥ 0,\\n\\nz5 ≥ 0\\n\\n\\uf8fc\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8fd\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8f4\\n\\n\\uf8fe\\n\\nSince SP is satisfiable, P is alm-recurrent. Note that projecting SP onto the µp,i’s gives\\n{µp,0 + 73 ∗µp,1 ≥ 0,µp,1 ≤ −1}. Any solution to this last constraint is a level mapping\\nensuring alm-recurrence of P.\\n\\nAn immediate consequence of the result above is that recurrence with affine level map-\\npings is also P-time decidable for non-binary CLP(R) program with rules which contain\\nmore than one atom in their bodies. Formally, the following theorem holds.\\n\\n\\n\\n6 Fred Mesnard and Alexander Serebrenik\\n\\nTheorem 3\\nAlm-recurrence of a constraint logic program P over Q,Q+,R and R+ is decidable in\\npolynomial time with respect to the size of P.\\n\\nProof\\nLet P be a constraint logic program. Let P′ be the binary constraint logic program such\\nthat for every rule q0(ỹ0)← c,q1(ỹ1), . . . ,qn(ỹn) with n≥ 1 in P, P′ contains the following\\nrules:\\n\\nq0(ỹ0)← c,q1(ỹ1).\\n\\n. . .\\n\\nq0(ỹ0)← c,qn(ỹn).\\n\\nand nothing else. From Definition 1, we note that P is recurrent if and only if P′ is re-\\ncurrent. Moreover, the size of P′ is polynomial in the size of P. Hence, by Theorems 2,\\nalm-recurrence of P′ is P-time decidable.\\n\\nAlthough the technique above is not complete for programs over N, it is a sound way to\\nprove recurrence of programs over this domain: if a program is recurrent over Q, it is also\\nrecurrent over N. For binary programs, as we allow negative coefficients in the level map-\\nping, we get a more powerful criterion than the one proposed in (Sohn and Van Gelder 1991).\\n', 'For instance, termination of Example 1 (considered as a CLP(N) program) cannot be\\nproved by (Sohn and Van Gelder 1991).\\n\\nFor binary CLP(Q) programs, the decision procedure described above has been pro-\\ntotyped in SICStus Prolog (SICS 2005) using the Simplex algorithm (Dantzig 1951) and\\na Fourier-based projection operator (Holzbaur 1995) to ease manual verification. There-\\nfore, the complexity of the prototype is not polynomial. The implementation is available at\\nhttp://www.univ-reunion.fr/∼gcc/soft/binterm4q.tgz\\n\\n4 Related Works\\n\\nThe basic idea of identifying decidable and undecidable subsets of logic programs goes\\nback to (Devienne et al. 1993).\\n\\nRecently, decidability of classes of imperative programs has been studied in (Cousot 2005;\\nPodelski and Rybalchenko 2004; Tiwari 2004). Tiwari considers real-valued programs with\\nno nested loops and no branching inside a loop (Tiwari 2004). Such programs correspond\\nto one-binary-rule CLP(R). The author provides decidability results for subclasses of these\\nprograms. Our approach does not restrict nesting of loops and it allows internal branching.\\nWhile in general termination of such programs is undecidable (Tiwari 2004), we identified\\na subclass of programs with decidable termination property. Termination of the following\\nCLP(R) program and its imperative equivalent can be shown by our method but not by the\\none proposed in (Tiwari 2004).\\n\\nExample 4\\n\\nq(x) ← −20≤ x,x≤ 20,y + 5 = x,q(y).\\nq(x) ← 0≤ x,x≤ 100,y + 1 = x,q(y).\\n\\nhttp://www.univ-reunion.fr/~gcc/soft/binterm4q.tgz\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 7\\n\\nwhile ((−20≤ x≤ 20) or (0 ≤ x≤ 100)) do\\nif (−20≤ x≤ 20) x = x−5 fi\\nif (0≤ x≤ 100) x = x−1 fi\\n\\nod\\n\\nSimilarly to (Tiwari 2004), Podelski and Rybalchenko (2004) have considered programs\\nwith no nested loops and no branching inside a loop. However, they focused on integer\\nprograms and provide a polynomial time decidability technique for a subclass of such\\nprograms. In case of general programs their technique can be applied to provide a sufficient\\ncondition for liveness.\\n\\nIn a recent paper, Cousot (2005) applied abstraction techniques and langrangian relax-\\nation to prove termination. Extension of the basic technique should be able to analyse\\nloops with disjunctions in their condition such as Example 4. However, complexity of the\\napproach is not discussed and it is not clear whether the technique is complete for some\\nclass of programs.\\n\\nOne might like to investigate a more expressive language of constraints including poly-\\nnomials. Recall that we require the constraints domain to be ideal, i.e., one needs a decision\\nprocedure for existentially closed conjunctions. Such a decision procedure exists, for in-\\nstance, for real-closed fields such as R (Tarski 1931; Renegar 1992). For some domains\\nsuch as Q, existence of a decision procedure is still an open problem, although it seems\\nto be unlikely (Pheidas 2000). If one restricts attention to real-closed fields, one might\\neven consider polynomial level-mappings of a certain power rather than the affine ones.\\nOne can show that in this case proving recurrence is equivalent to determining satisfia-\\nbility of the equivalent quantifier-free formula (Tarski 1931; Tarski 1951). Hence, recur-\\nrence is still decidable in this case. Although the known complexity bound of determining\\nthe equivalent quantifier-free formula given an existential formula is a double exponen-\\ntial (Basu et al. 1996; Collins 1975), to the best of our knowledge the complexity of the\\nsubclass of formulas which we obtain is an open question.\\n\\n5 Conclusion\\n\\nIn this paper we have considered constraints solving over the rationals and the reals. For\\nthese domains we have identified a class of CLP programs such that an affine level map-\\nping is sufficient to prove their recurrence. We have seen that membership to this class\\nis decidable and presented a polynomial-time decision procedure. The decision procedure\\ncan also be used as a sound termination proof technique for binary CLP(N) and has been\\nprototyped in SICStus Prolog for binary CLP(Q).\\n\\nAcknowledgements\\n\\nWe thank the referees for useful suggestions.\\n\\nReferences\\n\\nAFRATI, F. N., COSMADAKIS, S. S., AND FOUSTOUCOS, E. 2005. Datalog programs and their\\npersistency numbers. ACM Transactions on Computational Logic (TOCL), 6, 3, 481–518.\\n\\n\\n\\n8 Fred Mesnard and Alexander Serebrenik\\n\\nBASU, S., POLLACK, R., AND ROY, M.-F. 1996. On the combinatorial and algebraic complexity of\\nquantifier elimination. Journal of the ACM 43, 6, 1002–1045.\\n\\nBEZEM, M. 1993. Strong termination of logic programs. Journal of Logic Programming 15, 1&2,\\n79–97.\\n\\nCOLLINS, G. E. 1975. Quantifier elimination for real closed fields by cylindrical algebraic decom-\\nposition. In Second GI conference on Automata Theory and Formal Languages. Lecture Notes in\\nComputer Science, vol. 33. Springer, 134–183.\\n\\nCOUSOT, P. 2005. Proving program invariance and termination by parametric abstraction, lagrangian\\n', 'relaxation and semidefinite programming. In Verification, Model Checking, and Abstract Interpre-\\ntation, 6th International Conference, VMCAI, Paris, France, January 17-19, 2005, Proceedings,\\nR. Cousot, Ed. Lecture Notes in Computer Science, vol. 3385. Springer, 1–24.\\n\\nDANTZIG, G. B. 1951. Maximization of a linear function of variables subject to linear inequalities.\\nIn Activity Analysis of Production and Allocation - Proceedings of a Conference, T. Koopmans,\\nEd. Cowles Commission Monograph, vol. 13. Wiley, New York, 339–347.\\n\\nDEVIENNE, P., LEBÈGUE, P., AND ROUTIER, J.-C. P. 1993. Halting problem of one binary horn\\nclause is undecidable. In STACS 93, 10th Annual Symposium on Theoretical Aspects of Computer\\nScience, Würzburg, Germany, February 25-27, 1993, Proceedings., P. Enjalbert, A. Finkel, and\\nK. W. Wagner, Eds. Lecture Notes in Computer Science, vol. 665. Springer, 48–57.\\n\\nHOLZBAUR, C. 1995. OFAI clp(Q,R) Manual. Tech. Rep. TR-95-09, Austrian Research Institute\\nfor Artificial Intelligence (ÖFAI), Schottengasse 3, A-1010 Vienna, Austria.\\n\\nJAFFAR, J. AND MAHER, M. J. 1994. Constraint logic programming: A survey. Journal of Logic\\nProgramming 19/20, 503–582.\\n\\nJAFFAR, J., MAHER, M. J., MARRIOTT, K., AND STUCKEY, P. J. 1998. The semantics of constraint\\nlogic programs. Journal of Logic Programming 37, 1-3, 1–46.\\n\\nKHACHIYAN, L. 1979. A polynomial algorithm in linear programming. Soviet Mathematics—\\nDoklady 20, 191–194.\\n\\nMARCINKOWSKI, J. 1996. DATALOG SIRUPs uniform boundedness is undecidable. In Proceed-\\nings of the 11th Annual IEEE Symposium on Logic in Computer Science. 13–24.\\n\\nMARRIOTT, K. AND STUCKEY, P. J. 1998. Programming with Constraints: An Introduction. The\\nMIT Press.\\n\\nPHEIDAS, T. 2000. An effort to prove that the existential theory of is undecidable.\\nContemporary Mathematics 270, 237–252. Available at http://www.ams.org/mathscinet-\\ngetitem?mr=2001m:03085.\\n\\nPODELSKI, A. AND RYBALCHENKO, A. 2004. A complete method for the synthesis of linear\\nranking functions. In Verification, Model Checking, and Abstract Interpretation, 5th International\\nConference, Venice, January 11-13, 2004, Proceedings, B. Steffen and G. Levi, Eds. Lecture Notes\\nin Computer Science, vol. 2937. Springer, 239–251.\\n\\nRENEGAR, J. 1992. On the computational complexity and geometry of the first-order theory of the\\nreals. Journal of Symbolic Computation 13, 3, 255–352.\\n\\nSCHRIJVER, A. 1986. Theory of Linear and Integer Programming. Wiley.\\n\\nSEREBRENIK, A. AND MESNARD, F. 2004. On termination of binary CLP programs. In Logic\\nBased Program Synthesis and Transformation, 14th International Symposium, LOPSTR, Verona,\\nItaly, August 26-28, 2004, Revised Selected Papers, S. Etalle, Ed. Lecture Notes in Computer\\nScience, vol. 3573. Springer, 231–244.\\n\\nSICS. 2005. SICStus User Manual. Version 3.12.3. Swedish Institute of Computer Science.\\n\\nSOHN, K. AND VAN GELDER, A. 1991. Termination detection in logic programs using argument\\nsizes. In Proceedings of the Tenth ACM SIGACT-SIGART-SIGMOD Symposium on Principles of\\nDatabase Systems. ACM Press, 216–226.\\n\\nTARSKI, A. 1931. Sur les ensembles définissables de nombres réels. Fundamenta Mathematicae 17,\\n210–239.\\n\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 9\\n\\nTARSKI, A. 1951. A Decision Method for Elementary Algebra and Geometry, 2nd ed. University of\\nCalifornia Press.\\n\\nTIWARI, A. 2004. Termination of linear programs. In Computer-Aided Verification, CAV, R. Alur\\nand D. Peled, Eds. Lecture Notes on Computer Science, vol. 3114. Springer, 70–82.\\n\\n\\n\\tIntroduction\\n\\tPreliminaries\\n\\tAlm-recurrent programs\\n\\tRelated Works\\n\\tConclusion\\n\\tReferences\\n\\n'], 'name': '0701082v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0701/0701082v1.pdf', 'vectorized': None}, {'@search.score': 17.354563, '@search.rerankerScore': 3.1306679248809814, '@search.captions': [{'text': 'A CLP(C) program is a finite set of rules. A rule has the form H ← c⋄B where H and B are atoms and c is a finite conjunction of primitive constraints such that DC |= ∃c. A query has the form 〈A | d〉 where A is an atom and d is a finite conjunction of primitive constraints. Given an atom A := p(t̃), we write rel(A) to denote the predicate symbol p.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNTA4LzA1MDgxMDZ2MS5wZGY1', 'title': 'arXiv:cs/0508106v1  [cs.PL]  24 Aug 2005', 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n05\\n\\n08\\n10\\n\\n6v\\n1 \\n\\n [\\ncs\\n\\n.P\\nL\\n\\n] \\n 2\\n\\n4 \\nA\\n\\nug\\n 2\\n\\n00\\n5\\n\\nAn Improved Non-Termination Criterion for\\n\\nBinary Constraint Logic Programs\\n\\nEtienne Payet and Fred Mesnard\\n\\nIREMIA - Université de La Réunion, France\\nemail: epayet@univ-reunion.fr\\n\\nAbstract. On one hand, termination analysis of logic programs is now\\na fairly established research topic within the logic programming com-\\nmunity. On the other hand, non-termination analysis seems to remain a\\nmuch less attractive subject. If we divide this line of research into two\\nkinds of approaches: dynamic versus static analysis, this paper belongs\\nto the latter. It proposes a criterion for detecting non-terminating atomic\\nqueries with respect to binary CLP clauses, which strictly generalizes our\\nprevious works on this subject. We give a generic operational definition\\nand a logical form of this criterion. Then we show that the logical form\\nis correct and complete with respect to the operational definition.\\n\\n1 Introduction\\n\\nOn one hand, termination analysis of logic programs is a fairly established re-\\nsearch topic within the logic programming community, see the surveys [5, 12]. For\\nProlog, various tools are now available via web interfaces and we note that the\\nMercury compiler, designed with industrial goals in mind by its implementors,\\nhas included two termination analyzers (see [18] and [7]) for a few years.\\n\\nOn the other hand, non-termination analysis seems to remain a much less at-\\ntractive subject. We can divide this line of research into two kinds of approaches:\\ndynamic versus static analysis. In the former one, [1] sets up some solid founda-\\ntions for loop checking, while some recent work is presented in [16]. The main\\nidea is to prune at runtime at least all infinite derivations, and possibly some\\nfinite ones. In the latter approach, which includes the work we present in this\\narticle, [4, 6] present an algorithm for detecting non-terminating atomic queries\\nwith respect to a binary clause of the type p(s̃) ← p(t̃). The condition is de-\\nscribed in terms of rational trees, while we aim at generalizing non-termination\\nanalysis for the generic CLP(X) framework.\\n\\nOur analysis shares with some work on termination analysis [3] a key compo-\\nnent: the binary unfoldings of a logic program [8], which transforms a finite set\\nof definite clauses into a possibly infinite set of facts and binary definite clauses.\\nWhile some termination analyses begin with the analysis of the recursive bi-\\nnary clauses of an upper approximation of the binary unfoldings of an abstract\\nCLP(N) version of the original program, we start from a finite subset of the\\nbinary unfoldings of the concrete program P (a larger subset may increase the\\n\\nhttp://arXiv.org/abs/cs/0508106v1\\n\\n\\nprecision of the analysis, see [13] for some experimental evidence). First we de-\\ntect patterns of non-terminating atomic queries for binary recursive clauses and\\nthen propagate this non-termination information to compute classes of atomic\\nqueries for which we have a finite proof that there exists at least one infinite\\nderivation with respect to the subset of the binary unfoldings of P .\\n\\nThe equivalence of termination for a program or its binary unfoldings given\\nin [3] is a corner stone of both analyses. It allows us to conclude that any atomic\\nquery belonging to the identified above classes of queries admits an infinite left\\nderivation with respect to P . So in this paper, we deliberately choose to restrict\\nthe analysis to binary CLP clauses and atomic CLP queries as the result we\\nobtain can be directly lifted to full CLP.\\n\\nOur initial motivation, see [11], is to complement termination analysis with\\nnon-termination inside the logic programming paradigm in order to detect opti-\\nmal termination conditions expressed in a language describing classes of queries.\\nWe started from a generalization of the lifting lemma where we may ignore\\nsome arguments. For instance, from the clause p(f(X), Y ) ← p(X, g(Y )), we\\ncan conclude that the atomic query p(X, t) loops for any term t, thus ignoring\\nthe second argument. Then we have extended the approach, see [13] which gives\\nthe full picture of the non-termination analysis, an extensive experimental eval-\\nuation, and a detailed comparison with related works. For instance, from the\\nclause p(f(X), g(Y )) ← p(X, g(b)), and with the help of the criterion designed\\nin [13] we can now conclude that p(X, t) loops for any term t which is an instance\\nof g(X).\\n\\nAlthough we obtained interesting experimental results from such a criterion,\\nthe overall approach remains quite syntactic, with an ad hoc flavor and tight links\\nto some basic logic programming machinery such as the unification algorithm. So\\nwe moved to the constraint logic programming scheme: in [14], we started from\\na generic definition of the generalization of the lifting lemma we were looking\\nfor. Such a definition was practically useless but we were able to give a sufficient\\n', 'condition expressed as a logical formula related to the constraint binary clause\\np(x̃) ← c ⋄ p(ỹ) under consideration. For some constraint domains, we showed\\nthat the condition is also necessary. Depending on the constraint theory, the\\nvalidity of such a condition can be automatically decided. Moreover, we showed\\nthat the syntactic criterion we used in [11] was actually equivalent to the logical\\ncriterion and could be considered as a correct and complete implementation\\nspecialized for the algebra of finite trees Term.\\n\\nThe main contribution of this article consists in a strict generalization of the\\nlogical criterion defined in [14] which allows us to reconstruct the syntactic ap-\\nproaches described in [11] and [13]. We emphasize the improvement with respect\\nto [14] in Sect. 5 (see Example 21).\\n\\nThe paper is organized as follows. First, in Sect. 2, we introduce some prelim-\\ninary definitions. Then, in Sect. 3, we recall, using CLP terms, the subsumption\\ntest to detect looping queries. In Sect. 4, we present our generalized criterion for\\ndetecting looping queries, whilst in Sect. 5 we consider the connections with the\\nresults of [14].\\n\\n2\\n\\n\\n\\n2 Preliminaries\\n\\nFor any non-negative integer n, [1, n] denotes the set {1, . . . , n}. If n = 0, then\\n[1, n] = ∅.\\n\\n2.1 First Order Formulas\\n\\nThroughout this paper, we consider a fixed, infinite and denumerable set of\\nvariables V .\\n\\nA signature defines a set of function and predicate symbols and associates\\nan arity with each symbol. If φ is a first order formula on a signature Σ and\\nW := {X1, . . . , Xn} is a set of variables, then ∃W φ (resp. ∀W φ) denotes the\\nformula ∃X1 . . . ∃Xnφ (resp. ∀X1 . . . ∀Xnφ). We let ∃φ (resp. ∀φ) denote the\\nexistential (resp. universal) closure of φ. A Σ-structure D is an interpretation of\\nthe symbols in the signature Σ. It is a pair (D, [·]) where D is a set called the\\ndomain of D and [·] maps:\\n\\n– each function symbol f of arity n in Σ to a function [f ] : Dn → D,\\n– each predicate symbol p of arity n in Σ to a boolean function [p] : Dn →\\n{0, 1}.\\n\\nA D-valuation (or simply a valuation if the Σ-structure D is understood) is a\\nmapping v : V → D. Every D-valuation v extends (by morphism) to terms:\\n\\n– v(f(t1, . . . , tn)) := [f ](v(t1), . . . , v(tn)) if f(t1, . . . , tn) is a term.\\n\\nA D-valuation v induces a valuation [·]v of formulas to {0, 1}:\\n\\n– [p(t1, . . . , tn)]v := [p](v(t1), . . . , v(tn)) if p(t1, . . . , tn) is an atomic proposi-\\ntion,\\n\\n– if φ1 and φ2 are formulas and ◦ ∈ {∧,∨,→,↔}, [¬φ1]v and [φ1 ◦φ2]v are\\ndeduced from [φ1]v, [φ2]v and the truth table of ¬ and ◦,\\n\\n– if X is a variable and φ is a formula, [∃Xφ]v = 1 if and only if there exists\\na valuation v′ such that [φ]v′ = 1 and for each variable Y distinct from X ,\\nv′(Y ) = v(Y ),\\n\\n– if X is a variable and φ is a formula, [∀Xφ]v = 1 if and only if [φ]v′ = 1 for\\nevery valuation v′ such that for each variable Y distinct from X , v′(Y ) =\\nv(Y ).\\n\\nGiven a formula φ, we write D |=v φ if [φ]v = 1 and D 6|=v φ if [φ]v = 0. We\\nwrite D |= φ if and only if for every D-valuation v, we have D |=v φ. Notice\\nthat D |= ∀φ if and only if D |= φ, that D |= ∃φ if and only if there exists a\\nD-valuation v such that D |=v φ, and that D |= ¬∃φ if and only if D |= ¬φ.\\n\\nGiven a Σ-structure D, we say that a Σ-formula φ is satisfiable (resp. un-\\nsatisfiable) in D if D |= ∃φ (resp. D |= ¬φ). We say that D is a model of a set S\\nof Σ-formulas if for each element φ of S we have D |= φ. Given two sets S and\\nT of Σ-formulas, we say that S semantically implies T , written S |= T , if every\\nmodel of S is also a model of T .\\n\\n3\\n\\n\\n\\n2.2 Sequences\\n\\nSequences of distinct variables are denoted by X̃, Ỹ , Z̃, Ũ , . . . and sequences\\nof (not necessarily distinct) terms are denoted by s̃, t̃, . . . Given two sequences\\nof n terms s̃ := (s1, . . . , sn) and t̃ := (t1, . . . , tn), we write s̃ = t̃ either to\\ndenote the formula s1 = t1 ∧ · · · ∧ sn = tn or as a shorthand for “s1 = t1\\nand . . . and sn = tn”. Moreover, given a valuation v, we write v(s̃) to denote\\nthe sequence (v(s1), . . . , v(sn)). Finally, given a sequence X̃ := (X1, . . . , Xn) of\\ndistinct variables and given a formula φ, we write ∃X̃φ (resp. ∀X̃φ) to denote\\nthe formula ∃X1 . . .∃Xnφ (resp ∀X1 . . . ∀Xnφ).\\n\\n2.3 Constraint Domains\\n\\nWe recall some basic definitions about CLP, see [10] for more details. In this pa-\\nper, we consider a constraint logic programming language CLP(C) based on the\\nconstraint domain C := 〈ΣC ,LC ,DC , TC , solvC〉. The constraint domain signature\\nΣC is a pair 〈FC , ΠC〉 where FC is a set of function symbols and ΠC is a set of\\npredicate symbols. The domain of computation DC is a ΣC-structure (DC , [·]C)\\nthat is the intended interpretation of the constraints. We assume the following:\\n\\n– C is ideal,\\n– the predicate symbol = is in ΣC and is interpreted as identity in DC ,\\n– DC and TC correspond on LC ,\\n– TC is satisfaction complete with respect to LC ,\\n– the theory and the solver agree in the sense that for every c ∈ LC , solvC(c) =\\n\\n', 'true if and only if TC |= ∃c. Consequently, as DC and TC correspond on LC ,\\nwe have, for every c ∈ LC , solvC(c) = true if and only if DC |= ∃c.\\n\\nExample 1 (Rlin). The constraint domain Rlin has <, ≤, =, ≥ and > as pred-\\nicate symbols, +, −, ∗, / as function symbols and sequences of digits (possibly\\nwith a decimal point) as constant symbols. Only linear constraints are admitted.\\nThe domain of computation is the structure with reals as domain and where the\\npredicate symbols and the function symbols are interpreted as the usual relations\\nand functions over reals. The theory TRlin\\n\\nis the theory of real closed fields [17].\\nA constraint solver for Rlin always returning either true or false is described\\nin [15].\\n\\nExample 2 (Logic Programming). The constraint domain Term has = as pred-\\nicate symbol and strings of alphanumeric characters as function symbols. The\\ndomain of computation of Term is the set of finite trees (or, equivalently, of finite\\nterms), Tree, while the theory TTerm is Clark’s equality theory [2]. The interpre-\\ntation of a constant is a tree with a single node labeled with the constant. The\\ninterpretation of an n-ary function symbol f is the function fTree : Treen → Tree\\nmapping the trees T1, . . . , Tn to a new tree with root labeled with f and with\\nT1, . . . , Tn as child nodes. A constraint solver always returning either true or\\nfalse is provided by the unification algorithm. CLP(Term) coincides then with\\nlogic programming.\\n\\n4\\n\\n\\n\\n2.4 Operational Semantics\\n\\nThe signature in which all programs and queries under consideration are in-\\ncluded is ΣL := 〈FL, ΠL〉 with FL := FC and ΠL := ΠC ∪ Π ′\\n\\nL where Π ′\\nL, the\\n\\nset of predicate symbols that can be defined in programs, is disjoint from ΠC .\\nWe assume that each predicate symbol p in ΠL has a unique arity denoted by\\narity(p).\\n\\nAn atom has the form p(t̃) where p ∈ Π ′\\nL and t̃ is a sequence of arity(p) ΣL-\\n\\nterms. Throughout this paper, when we write p(t̃), we implicitly assume that t̃\\ncontains arity(p) terms. A CLP(C) program is a finite set of rules. A rule has the\\nform H ← c⋄B where H and B are atoms and c is a finite conjunction of primitive\\nconstraints such that DC |= ∃c. A query has the form 〈A | d〉 where A is an atom\\nand d is a finite conjunction of primitive constraints. Given an atom A := p(t̃),\\nwe write rel(A) to denote the predicate symbol p. Given a query S := 〈A | d〉, we\\nwrite rel(S) to denote the predicate symbol rel(A). The set of variables occurring\\nin some syntactic objects O1, . . . , On is denoted Var(O1, . . . , On).\\n\\nThe examples of this paper make use of the language CLP(Rlin) and the\\nlanguage CLP(Term). In program and query examples, variables begin with an\\nupper-case letter, [Head |Tail ] denotes a list with head Head and tail Tail , and\\n[ ] denotes an empty list.\\n\\nWe consider the following operational semantics given in terms of derivations\\nfrom queries to queries. Let 〈p(ũ) | d〉 be a query and r := p(s̃) ← c ⋄ q(t̃) be a\\nrule. Let r′ := p(s̃′)← c′ ⋄ q(t̃′) be a variant of r variable disjoint with 〈p(ũ) | d〉\\nsuch that solvC(s̃′ = ũ∧c′∧d) = true. Then, 〈p(ũ) | d〉=⇒\\n\\nr\\n〈q(t̃′) | s̃′ = ũ ∧ c′ ∧ d〉\\n\\nis a derivation step of 〈p(ũ) | d〉 with respect to r with r′ as its input rule. We\\n\\nwrite S\\n+\\n\\n=⇒\\nP\\n\\nS′ to summarize a finite number (> 0) of derivation steps from S to\\n\\nS′ where each input rule is a variant of a rule from program P . Let S0 be a query.\\nA sequence of derivation steps S0 =⇒\\n\\nr1\\n\\nS1 =⇒\\nr2\\n\\n· · · of maximal length is called a\\n\\nderivation of P ∪ {S0} if r1, r2, . . . are rules from P and if the standardization\\napart condition holds, i.e. each input rule used is variable disjoint from the initial\\nquery S0 and from the input rules used at earlier steps. We say S0 loops with\\nrespect to P if there exists an infinite derivation of P ∪ {S0}.\\n\\n3 Loop Inference with Constraints\\n\\nIn the logic programming framework, the subsumption test provides a simple\\nway to infer looping queries: if, in a logic program P , there is a rule p(s̃)← p(t̃)\\nsuch that p(t̃) is more general than p(s̃), then the query p(s̃) loops with respect\\nto P . In this section, we extend this result to the constraint logic programming\\nframework.\\n\\n3.1 A “More General Than” Relation\\n\\nA query can be viewed as a finite description of a possibly infinite set of atoms,\\nthe arguments of which are values from DC .\\n\\n5\\n\\n\\n\\nExample 3. Suppose that C = Rlin .\\n\\n– The query 〈p(2 ∗X) |X ≥ −1〉 describes those atoms p(x) where x is a real\\nand the term 2 ∗X can be made equal to x while the constraint X ≥ −1 is\\nsatisfied.\\n\\n– The query 〈q(X, Y ) |Y ≤ X + 2〉 describes those atoms q(x, y) where x and\\ny are reals and X and Y can be made equal to x and y respectively while\\nthe constraint Y ≤ X + 2 is satisfied.\\n\\nIn order to capture this intuition, we introduce the following definition.\\n\\nDefinition 1 (Set Described by a Query). The set of atoms that is described\\nby a query S := 〈p(t̃) | d〉 is denoted by Set(S) and is defined as: Set(S) =\\n{p(v(t̃)) | DC |=v d}.\\n\\n', 'Clearly, Set(〈p(t̃) | d〉) = ∅ if and only if d is unsatisfiable in DC . Moreover,\\ntwo variants describe the same set. Notice that the operational semantics we\\nintroduced above can be expressed using sets described by queries:\\n\\nLemma 1. Let S be a query and r := H ← c ⋄ B be a rule. There exists a\\nderivation step of S with respect to r if and only if Set(S) ∩ Set(〈H | c〉) 6= ∅.\\n\\nThe “more general than” relation we consider is defined as follows:\\n\\nDefinition 2 (More General). We say that a query S′ is more general than\\na query S if Set(S) ⊆ Set(S′).\\n\\nExample 4.\\n\\n– In any constraint domain, 〈p(X) | true〉 is more general than any query S\\nverifying rel(S) = p;\\n\\n– In the constraint domain Term, the query 〈p(Y ) |Y = f(X)〉 is more general\\nthan the query 〈p(Y ) |Y = f(f(X))〉;\\n\\n– In the constraint domain Rlin , the query 〈q(X, Y ) |Y ≤ X + 2〉 is more gen-\\neral than the query 〈q(X, Y ) |Y ≤ X + 1〉.\\n\\n3.2 Loop Inference\\n\\nSuppose we have a derivation step S =⇒\\nr\\n\\nT where r := H ← c ⋄ B. Then, by\\n\\nLemma 1, Set(S)∩Set(〈H | c〉) 6= ∅. Hence, if S′ is a query that is more general\\nthan S, as Set(S) ⊆ Set(S′), we have Set(S′)∩Set(〈H | c〉) 6= ∅. So, by Lemma 1,\\nthere exists a query T ′ such that S′ =⇒\\n\\nr\\nT ′. The following lifting result says that,\\n\\nmoreover, T ′ is more general than T :\\n\\nTheorem 1 (Lifting). Consider a derivation step S =⇒\\nr\\n\\nT and a query S′ that\\n\\nis more general than S. Then, there exists a derivation step S′ =⇒\\nr\\n\\nT ′ where T ′\\n\\nis more general than T .\\n\\nFrom this theorem, we derive two corollaries that can be used to infer looping\\nqueries just from the text of a CLP(C) program:\\n\\n6\\n\\n\\n\\nCorollary 1. Let r := H ← c ⋄ B be a rule. If 〈B | c〉 is more general than\\n〈H | c〉 then 〈H | c〉 loops with respect to {r}.\\n\\nCorollary 2. Let r := H ← c ⋄ B be a rule from a program P . If 〈B | c〉 loops\\nwith respect to P then 〈H | c〉 loops with respect to P .\\n\\nExample 5. Consider the CLP(Term) rule r:\\n\\nappend([X |Xs],Ys , [X |Zs])← true ⋄ append(Xs ,Ys,Zs)\\n\\nWe note that the query 〈append(Xs ,Ys,Zs) | true〉 is more general than the\\nquery S := 〈append([X |Xs],Ys , [X |Zs]) | true〉. So, by Corollary 1, S loops with\\nrespect to {r}. Therefore, there exists an infinite derivation ξ of {r}∪{S}. Then,\\nif S′ is a query that is more general than S, by successively applying the Lifting\\nTheorem 1 to each step of ξ, one can construct an infinite derivation of {r}∪{S′}.\\nSo, S′ also loops with respect to {r}.\\n\\n4 Loop Inference Using Filters\\n\\nThe condition provided by Corollary 1 is rather weak because it fails at inferring\\nlooping queries in some simple cases. This is illustrated by the following example.\\n\\nExample 6. Assume C = Rlin . Let\\n\\nr := p(X, Y )← X ≥ 0 ∧ Y ≤ 10 ⋄ p(X + 1, Y + 1) .\\n\\nWe have the infinite derivation:\\n\\n〈p(X, Y ) | c〉 =⇒\\nr\\n〈p(X1 + 1, Y1 + 1) | c ∧ c1〉\\n\\n=⇒\\nr\\n〈p(X2 + 1, Y2 + 1) | c ∧ c1 ∧ c2〉\\n\\n...\\n\\nwhere:\\n\\nc is the constraint X ≥ 0 ∧ Y ≤ 10,\\nc1 is the constraint X1 = X ∧ Y1 = Y ∧X1 ≥ 0 ∧ Y1 ≤ 10 and\\nc2 is the constraint X2 = X1 + 1 ∧ Y2 = Y1 + 1 ∧X2 ≥ 0 ∧ Y2 ≤ 10.\\n\\nBut as in r, 〈p(X + 1, Y + 1) | c〉 is not more general than 〈p(X, Y ) | c〉, Corol-\\nlary 1 does not allow to infer that 〈p(X, Y ) | c〉 loops with respect to {r}.\\n\\nIn this section, we extend the relation “is more general”. Instead of comparing\\natoms in all positions using the “more general” relation, we distinguish some\\npredicate argument positions for which we just require that a certain property\\nmust hold, while for the other positions we use the “more general” relation as\\nbefore. Doing so, we aim at inferring more looping queries.\\n\\n7\\n\\n\\n\\nExample 7 (Example 6 continued). Let us consider argument position 1 of pred-\\nicate symbol p. In the rule r, the argument of p(X, Y ) in position 1 is X and the\\nargument of p(X + 1, Y + 1) in position 1 is X + 1. Notice that the condition\\non X in c is X ≥ 0 and that if X ≥ 0 then X + 1 ≥ 0. Hence, let us define the\\ncondition δ as: a query satisfies δ if it has the form 〈p(t1, t2) | d〉 where t1 and\\nt2 are some terms and {v(t1) | DC |=v d} is included in the set of positive real\\nnumbers. Then, both S := 〈p(X, Y ) | c〉 and T := 〈p(X + 1, Y + 1) | c〉 satisfy δ.\\n\\nSo, if we consider a “more general than” relation where we “filter” queries\\nusing δ, as S and T both satisfy δ and as the “piece” 〈p(Y + 1) | c〉 of T is more\\ngeneral than the “piece” 〈p(Y ) | c〉 of S, by an extended version of Corollary 1\\nwe could infer that S loops with respect to {r}.\\n\\n4.1 Sets of Positions\\n\\nA basic idea in Example 7 lies in identifying argument positions of predicate\\nsymbols. Below, we introduce a formalism to do so.\\n\\nDefinition 3 (Set of Positions). A set of positions, denoted by τ , is a function\\nthat maps each predicate symbol p ∈ Π ′\\n\\nL to a subset of [1, arity(p)].\\n\\nExample 8. If we want to distinguish the first argument position of the predicate\\nsymbol p defined in Example 6, we set τ := 〈p 7→ {1}〉.\\n\\nDefinition 4. Let τ be a set of positions. Then, τ is the set of positions defined\\nas: for each predicate symbol p ∈ Π ′\\n\\n', 'L, τ (p) = [1, arity(p)] \\\\ τ(p).\\n\\nExample 9 (Example 8 continued). We have τ = 〈p 7→ {2}〉.\\n\\nUsing a set of positions τ , one can project syntactic objects:\\n\\nDefinition 5 (Projection). Let τ be a set of positions.\\n\\n– Let p ∈ Π ′\\nL be a predicate symbol. The projection of p on τ is the predicate\\n\\nsymbol denoted by pτ . Its arity equals the number of elements of τ(p).\\n\\n– Let p ∈ Π ′\\nL be a predicate symbol of arity n and t̃ := (t1, . . . , tn) be a se-\\n\\nquence of n terms. The projection of t̃ on τ , denoted by t̃τ is the sequence\\n(ti1 , . . . , tim\\n\\n) where {i1, . . . , im} = τ(p) and i1 ≤ · · · ≤ im.\\n\\n– Let A := p(t̃) be an atom. The projection of A on τ , denoted by Aτ , is the\\natom pτ (t̃τ ).\\n\\n– The projection of a query 〈A | d〉 on τ , denoted by 〈A | d〉τ , is the query\\n〈Aτ | d〉.\\n\\nExample 10 (Example 6 and Example 8 continued). The projection of the query\\n〈p(X, Y ) | c〉 on τ is the query 〈pτ (X) | c〉.\\n\\n8\\n\\n\\n\\n4.2 Filters\\n\\nAccording to the intuitions described in Example 7 above, we define a filter as\\nfollows.\\n\\nDefinition 6 (Filter). A filter, denoted by ∆, is a pair (τ, δ) where τ is a set\\nof positions and δ is a function that maps each predicate symbol p ∈ Π ′\\n\\nL to a\\nquery of the form 〈pτ (ũ) | d〉 where DC |= ∃d and ũ is a sequence of arity(pτ )\\nterms.\\n\\nExample 11 (Example 6 and Example 7 continued). Let δ be the function defined\\nas δ := 〈 p 7→ 〈pτ (X) |X ≥ 0〉 〉. Then, ∆ := (τ, δ) is a filter.\\n\\nExample 12. Suppose that C = Term . Let p ∈ Π ′\\nL be a predicate symbol whose\\n\\narity is 1. Let τ := 〈p 7→ {1}〉 and δ := 〈 p 7→ 〈pτ (f(X)) | true〉 〉. Then,\\n∆ := (τ, δ) is a filter.\\n\\nThe function δ is used to “filter” queries as indicated by the next definition.\\n\\nDefinition 7 (Satisfies). Let ∆ := (τ, δ) be a filter and S be a query. Let\\np := rel(S). We say that S satisfies ∆ if Set(Sτ ) ⊆ Set(δ(p)).\\n\\nNow we come to the extension of the relation “more general than”. Intuitively,\\n〈p(t̃′) | d′〉 is ∆-more general than 〈p(t̃) | d〉 if the “more general than” relation\\nholds for the elements of t̃ and t̃′ whose position is not in τ while the elements\\nof t̃′ whose position is in τ satisfy δ. More formally:\\n\\nDefinition 8 (∆-More General). Let ∆ := (τ, δ) be a filter and S and S′ be\\ntwo queries. We say that S′ is ∆-more general than S if S′\\n\\nτ is more general than\\nSτ and S′ satisfies ∆.\\n\\nExample 13.\\n\\n– In the context of Example 11, 〈p(X + 1, Y + 1) |X ≥ 0 ∧ Y ≤ 10〉 is ∆-more\\ngeneral than 〈p(X, Y ) |X ≥ 0 ∧ Y ≤ 10〉.\\n\\n– In the context of Example 12, 〈p(f(f(X))) | true〉 is ∆-more general than\\n〈p(f(X)) | true〉.\\n\\nNotice that for any filter ∆ := (τ, δ) and any query S, we have that Sτ is more\\ngeneral than itself (because the “more general than” relation is reflexive), but\\nS may not satisfy ∆. Hence, the “∆-more general than” relation is not always\\nreflexive.\\n\\nExample 14 (Example 12 continued). S := 〈p(g(X)) | true〉 is not ∆-more gen-\\neral than itself because, as Set(Sτ ) = {pτ(g(t)) | t is a term} and Set(δ(p)) =\\n{pτ (f(t)) | t is a term}, we have Set(Sτ ) ∩ Set(δ(p)) = ∅. Hence, S does not\\nsatisfy ∆.\\n\\n9\\n\\n\\n\\nThe fact that reflexivity does not always hold is an expected property. Indeed,\\nsuppose that a filter ∆ := (τ, δ) induces a “∆-more general than” relation that\\nis reflexive. Then for any queries S and S′, we have that S′ is ∆-more general\\nthan S if and only if S′\\n\\nτ is more general than Sτ (because, as S′ is ∆-more\\ngeneral than itself, S′ necessarily satisfies ∆). Hence, δ is useless in the sense\\nthat it “does not filter anything”. Filters equipped with such a δ are studied in\\nSect. 5 and were introduced in [14] where for any predicate symbol p, δ(p) is\\n〈pτ (X̃) | true〉. In this paper, we aim at generalizing the approach of [14]. Hence,\\nwe also consider functions δ that really filter queries.\\n\\n4.3 Derivation Neutral Filters: an Operational Definition\\n\\nIn the sequel of this paper, we focus on “derivation neutral” filters. The name\\n“derivation neutral” stems from the fact that if, in a derivation of a query S, we\\nreplace S by S′ that satisfies the filter, then we get a “similar” derivation.\\n\\nDefinition 9 (Derivation Neutral). Let r be a rule and ∆ be a filter. We say\\nthat ∆ is DN for r if for each derivation step S =⇒\\n\\nr\\nT and each query S′ that\\n\\nis ∆-more general than S, there exists a derivation step S′ =⇒\\nr\\n\\nT ′ where T ′ is\\n\\n∆-more general than T . This definition is extended to programs: ∆ is DN for P\\nif it is DN for each rule of P .\\n\\nDerivation neutral filters lead to the following extended version of Corollary 1\\n(to get Corollary 1, take ∆ := (τ, δ) such that τ(p) = ∅ for any p).\\n\\nProposition 1. Let r := H ← c ⋄B be a rule. Let ∆ be a filter that is DN for\\nr. If 〈B | c〉 is ∆-more general than 〈H | c〉 then 〈H | c〉 loops with respect to {r}.\\n\\nExample 15 (Example 7 continued). Suppose that ∆ is DN for r. Now we can\\ndeduce that the query 〈p(X, Y ) |X ≥ 0 ∧ Y ≤ 10〉 loops with respect to r because\\nthe query 〈p(X + 1, Y + 1) |X ≥ 0 ∧ Y ≤ 10〉 is ∆-more general than the query\\n〈p(X, Y ) |X ≥ 0 ∧ Y ≤ 10〉.\\n\\n', 'Computing a neutral filter from the text of a program is not that easy if we\\nuse the definition above. The next subsections present a logical and a syntactic\\ncharacterization that can be used to compute a filter that is DN for a given\\nprogram.\\n\\n4.4 A Logical Characterization of Derivation Neutral Filters\\n\\nFrom now on, we suppose that, without loss of generality, a rule has the form\\np(X̃) ← c ⋄ q(Ỹ ) where X̃ and Ỹ are disjoint sequences of distinct variables.\\nHence, c is the conjunction of all the constraints, including unifications. We\\ndistinguish the following set of variables that appear inside such a rule.\\n\\nDefinition 10 (Local Variables). Let r := p(X̃)← c⋄q(Ỹ ) be a rule. The set\\nof local variables of r is denoted by local var (r) and is defined as: local var (r) :=\\nVar(c) \\\\ (Var(X̃) ∪ Var(Ỹ )).\\n\\n10\\n\\n\\n\\nIn this section, we aim at characterizing DN filters in a logical way. To this\\nend, we define:\\n\\nDefinition 11 (sat). Let S := 〈p(ũ) | d〉 be a query and s̃ be a sequence of\\narity(p) terms. Then, sat(s̃, S) denotes a formula of the form ∃Var(S′)(s̃ = ũ′∧d′)\\nwhere S′ := 〈p(ũ′) | d′〉 is any variant of S variable disjoint with s̃.\\n\\nClearly, the satisfiability of sat(s̃, S) does not depend on the choice of the variant\\nof S. Now we give a logical definition of derivation neutrality. As we will see be-\\nlow, under certain circumstances, this definition is equivalent to the operational\\none we gave above.\\n\\nDefinition 12 (Logical Derivation Neutral). We say that a filter ∆ :=\\n(τ, δ) is DNlog for a rule r := p(X̃)← c ⋄ q(Ỹ ) if\\n\\nDC |= c→ ∀X̃τ\\n\\n[\\n\\nsat(X̃τ , δ(p))→ ∃Y [sat(Ỹτ , δ(q)) ∧ c]\\n]\\n\\nwhere Y := Var(Ỹτ ) ∪ local var(r).\\n\\nIntuitively, the formula in Definition 12 has the following meaning. If one holds\\na solution v for constraint c, then, changing the value given to the variables of X̃\\ndistinguished by τ to some value satisfying δ(p), there exists a value for the local\\nvariables and the variables of Ỹ distinguished by τ such that c is still satisfied.\\n\\nExample 16. Suppose that C = Rlin . Consider the rule r := p(X1, X2) ← c ⋄\\np(Y1, Y2) where c is the constraint X1 = A+B∧A ≥ 0∧B ≥ 0∧X2 ≤ 10∧Y1 =\\nX1 + 1 ∧ Y2 = X2 + 1. Then, the local variables of r are A and B. Any filter\\n∆ := (τ, δ) where τ(p) = {1} and δ(p) = 〈pτ (X) |X ≥ 0〉 is DNlog for r. Indeed,\\nX̃τ = X1, Y = {Y1, A, B} and sat(t, δ(p)) is true if and only if t ≥ 0. So the\\nformula of Definition 12 turns into DC |= c → ∀X1\\n\\n[\\n\\nX1 ≥ 0 → ∃{Y1,A,B}[Y1 ≥\\n\\n0 ∧ c]\\n]\\n\\n, which is true.\\n\\nExample 17. Suppose that C = Term. Consider the rule r := p(X) ← c ⋄ p(Y )\\nwhere c is the constraint X = f(A)∧Y = f(f(A)). Then, the only local variable\\nof r is A. Any filter ∆ := (τ, δ) where τ(p) = {1} and δ(p) = 〈pτ (X) |X = f(A)〉\\nis DNlog for r. Indeed, X̃τ = X , Y = {Y, A} and sat(t, δ(p)) is true if and only\\nif t has the form f(· · · ). So the formula of Definition 12 turns into\\n\\nDC |= c→ ∀X\\n[\\n\\nX has the form f(· · · )\\n→ ∃{Y,A}[Y has the form f(· · · ) ∧ c]\\n\\n]\\n\\n,\\n\\nwhich is true.\\n\\nThe logical definition of derivation neutrality implies the operational one:\\n\\nProposition 2. Let r be a rule and ∆ be a filter. If ∆ is DNlog for r then ∆ is\\nDN for r.\\n\\nThe reverse implication does not always hold. But when considering a special\\ncase of the (SC1) condition of solution compactness given in [9], we get:\\n\\n11\\n\\n\\n\\nTheorem 2. Let r be a rule and ∆ be a filter. Assume C enjoys the following\\nproperty: for each α ∈ DC, there exists a ground ΣC-term a such that [a] = α.\\nThen, ∆ is DN for r if and only if ∆ is DNlog for r.\\n\\nProof (Sketch). We show how the (SC1) condition is used to get this result.\\nBy Proposition 2, we just have to establish that DN⇒ DNlog. Let (τ, δ) := ∆\\n\\nand p(X̃) ← c ⋄ q(Ỹ ) := r. Suppose that ∆ is DN for r. We have to prove that\\nthen, the formula of Definition 12 holds. Assume that v is a valuation such that\\n\\nDC |=v c . (1)\\n\\nBy property of C, we can consider the query S := 〈p(ã) | true〉 where ã is a\\nsequence of ground terms such that [ã] = v(X̃). As r and S are variable disjoint,\\nwe have S =⇒\\n\\nr\\nT where T is the query 〈q(Ỹ ) | c ∧ X̃ = ã〉.\\n\\nAs we assumed (1), we have to establish that DC |=v ∀X̃τ\\n\\n[\\n\\nsat(X̃τ , δ(p)) →\\n\\n∃Y [sat(Ỹτ , δ(q)) ∧ c]\\n]\\n\\nholds. Assume v1 is a valuation such that\\n\\nDC |=v1\\nsat(X̃τ , δ(p)) (2)\\n\\nand for each variable X 6∈ X̃τ , v(X) = v1(X). By property of C, we can consider\\nthe query S′ := 〈p(b̃) | true〉 where b̃τ = ãτ and b̃τ is a sequence of ground terms\\nsuch that [b̃τ ] = v1(X̃τ ).\\n\\nIt can be noticed that S′ is ∆-more general than S. As ∆ is DN for r,\\nthere exists a query T ′ that is ∆-more general than T and such that S′ =⇒\\n\\nr\\nT ′.\\n\\nNecessarily, T ′ = 〈q(Ỹ ′) | c′ ∧ X̃ ′ = b̃〉 where p(X̃ ′) ← c ⋄ q(Ỹ ′) is a variant of r\\nvariable disjoint with S′.\\n\\nAs we assumed (2), we now have to establish that DC |=v1\\n∃Y [sat(Ỹτ , δ(q))∧c]\\n\\nholds. This is done using the fact that T ′ is ∆-more general than T and that\\nSet(T ′) = Set(〈q(Ỹ ) | c ∧ X̃ = b̃〉). ⊓⊔\\n\\nExample 18. In the constraint domain Term, DN is equivalent to DNlog.\\n\\n', '4.5 A Syntactic Characterization of Derivation Neutral Filters\\n\\nIn [11], we gave, in the scope of logic programming, a syntactic definition of\\nneutral arguments. Now we extend this syntactic criterion to the more general\\nframework of constraint logic programming. First, we need rules in flat form:\\n\\nDefinition 13 (Flat Rule). A rule r := p(X̃) ← c ⋄ q(Ỹ ) is said to be flat if\\nc has the form (X̃ = s̃∧ Ỹ = t̃) where s̃ is a sequence of arity(p) terms and t̃ is\\na sequence of arity(q) terms such that Var(s̃, t̃) ⊆ local var (r).\\n\\nNotice that there are some rules r := p(X̃)← c ⋄ q(Ỹ ) for which there exists no\\n“equivalent” rule in flat form. More precisely, there exists no rule r′ := p(X̃)←\\nc′ ⋄ q(Ỹ ) verifying DC |= ∃local var(r)c ↔ ∃local var(r′)c\\n\\n′ (take for instance r :=\\np(X)← X > 0 ⋄ p(Y ) in Rlin .)\\n\\nSyntactic derivation neutrality is defined that way:\\n\\n12\\n\\n\\n\\nDefinition 14 (Syntactic Derivation Neutral). Let ∆ := (τ, δ) be a filter\\nand r := p(X̃)← (X̃ = s̃∧ Ỹ = t̃)⋄ q(Ỹ ) be a flat rule. We say that ∆ is DNsyn\\nfor r if\\n\\n– (DNsyn1) 〈p(s̃) | true〉τ is more general than δ(p),\\n– (DNsyn2) δ(q) is more general than 〈q(t̃) | true〉τ ,\\n– (DNsyn3) Var(s̃τ ) ∩ Var(s̃τ ) = ∅,\\n– (DNsyn4) Var(s̃τ ) ∩ Var(t̃τ ) = ∅.\\n\\nExample 19. In Example 17, the rule r is flat. Moreover, the filter ∆ is DNsyn\\nfor r.\\n\\nA connection between DN, DNsyn and DNlog is as follows:\\n\\nProposition 3. Let r be a flat rule and ∆ be a filter. If ∆ is DNsyn for r then\\n∆ is DNlog for r hence (by Proposition 2) ∆ is DN for r. If ∆ is DNlog for r\\nthen (DNsyn1) holds.\\n\\nNotice that a DNlog filter is not necessarily DNsyn because one of (DNsyn2–\\n4) may not hold:\\n\\nExample 20. In Rlin , consider the flat rule r:\\n\\np(X1, X2)← X1 = A ∧ Y1 = A ∧X2 = A−A ∧ Y2 = A−A ⋄ p(Y1, Y2) .\\n\\nLet ∆ := (τ, δ) where τ(p) = {1} and δ(p) = 〈pτ (X) |X ≥ 0〉. Then, ∆ is DNlog\\nfor r, but none of (DNsyn2–4) hold.\\n\\nHowever, in the special case of logic programming, we have:\\n\\nProposition 4 (Logic Programming). Suppose that C = Term. Let r be a\\nflat rule and ∆ be filter. If ∆ is DNlog for r then (DNsyn3) and (DNsyn4)\\nhold.\\n\\n5 Connections with Earlier Results\\n\\nThe results of [14] can be easily obtained within the framework presented above.\\nIt suffices to consider the following special kind of filter:\\n\\nDefinition 15 (Open Filter). We say that ∆ := (τ, δ) is an open filter if for\\nall p ∈ Π ′\\n\\nL, δ(p) has the form 〈pτ (Z̃) | true〉 where Z̃ is a sequence of distinct\\nvariables.\\n\\nIn an open filter, the function δ “does not filter anything”:\\n\\nLemma 2. Let ∆ := (τ, δ) be an open filter. Then, a query S′ is ∆-more general\\nthan a query S if and only if S′\\n\\nτ is more general than Sτ .\\n\\nConsequently, an open filter is uniquely determined by its set of positions. When\\nreconsidering the definitions and results of the preceding section within such a\\ncontext, we exactly get what we presented in [14]. In particular, Definition 12\\ncan be rephrased as:\\n\\n13\\n\\n\\n\\nDefinition 16 (Logical Derivation Neutral). A set of positions τ is DNlog\\nfor a rule r := p(X̃) ← c ⋄ q(Ỹ ) if DC |= c → ∀X̃τ\\n\\n∃Yc where Y := Var(Ỹτ ) ∪\\nlocal var (r).\\n\\nAs stated in Sect 1, the framework presented in this paper is a strict gener-\\nalization of that of [14]. This is illustrated by the following example.\\n\\nExample 21 (Example 17 continued). First, notice that, as 〈p(Y ) | c〉 is not more\\ngeneral than 〈p(X) | c〉, Corollary 1 does not allow to infer that 〈p(X) | c〉 loops\\nwith respect to {r}.\\n\\nLet us try to use Definition 16 to prove that the argument of p is “irrelevant”.\\nWe let τ(p) = {1}. Hence, X̃τ = X , Ỹτ = Y and local var (r) = {A}. Let us\\nconsider a valuation v such that v(X) = f(a), v(Y ) = f(f(a)) and v(A) = a.\\nSo, we have DC |=v c. But we do not have DC |=v ∀X̃τ\\n\\n∃Yc. For instance, if\\nwe consider v1 such that v1(X) = a and v1(Z) = v(Z) for each variable Z\\ndistinct from X , we do not have DC |=v1\\n\\n∃Yc as the subformula X = f(A)\\nof c cannot hold, whatever value is assign to A. Consequently, we do not have\\nDC |=v c → ∀X̃τ\\n\\n∃Yc, so τ is not DNlog for r. As C = Term, by Theorem 2 τ is\\nnot DN for r. Therefore, using open filters with Proposition 1 we are not able\\nto prove that 〈p(X) | c〉 loops with respect to {r}.\\n\\nHowever, in Example 17, we noticed that any filter ∆ := (τ, δ) where τ(p) =\\n{1} and δ(p) = 〈pτ (X) |X = f(A)〉 is DNlog, hence DN, for r. Moreover, for such\\na filter, 〈p(Y ) | c〉 is ∆-more general than 〈p(X) | c〉. Consequently, by Proposi-\\ntion 1, 〈p(X) | c〉 loops with respect to {r}.\\n\\n6 Conclusion\\n\\nWe have presented a criterion to detect non-terminating atomic queries with\\nrespect to a binary CLP clause. This criterion generalizes our previous papers\\nin the CLP settings and allows us to reconstruct the work we did in the LP\\nframework. However, when switching from LP to CLP, we lose the ability to\\ncompute, given a binary clause, a useful filter. We plan to work on this and try to\\ndefine some conditions on the constraint domain which enable the computation\\nof such filters. ', 'Moreover, as pointed out by an anonymous referee, DNsyn and\\nDNlog seem to be independent notions which we proved to coincide only for open\\nfilters with the specific constraint domain Term . In Theorem 2 we investigate\\nthe relationship between DNlog and DN while Proposition 3 and Proposition 4\\nessentially establish some connections between DNsyn and DNlog. The study of\\nrelationship between DNsyn and DN is still missing and we intend to work on\\nthis shortly.\\n\\nReferences\\n\\n1. R. N. Bol, K. R. Apt, and J. W. Klop. An analysis of loop checking mechanisms\\nfor logic programs. Theoretical Computer Science, 86:35–79, 1991.\\n\\n14\\n\\n\\n\\n2. K. L. Clark. Negation as failure. In H. Gallaire and J. Minker, editors, Logic and\\n\\nDatabases, pages 293–322. Plenum Press, New York, 1978.\\n3. M. Codish and C. Taboch. A semantic basis for the termination analysis of logic\\n\\nprograms. Journal of Logic Programming, 41(1):103–123, 1999.\\n4. D. De Schreye, M. Bruynooghe, and K. Verschaetse. On the existence of non-\\n\\nterminating queries for a restricted class of Prolog-clauses. Artificial Intelligence,\\n41:237–248, 1989.\\n\\n5. D. De Schreye and S. Decorte. Termination of logic programs: the never-ending\\nstory. Journal of Logic Programming, 19-20:199–260, 1994.\\n\\n6. D. De Schreye, K. Verschaetse, and M. Bruynooghe. A practical technique for\\ndetecting non-terminating queries for a restricted class of Horn clauses, using di-\\nrected, weighted graphs. In Proc. of ICLP’90, pages 649–663. The MIT Press,\\n1990.\\n\\n7. J. Fischer. Termination analysis for Mercury using convex constraints. Master’s\\nthesis, The University of Melbourne, Department of Computer Science and Soft-\\nware Engineering, 2002.\\n\\n8. M. Gabbrielli and R. Giacobazzi. Goal independency and call patterns in the\\nanalysis of logic programs. In Proceedings of the ACM Symposium on applied\\n\\ncomputing, pages 394–399. ACM Press, 1994.\\n9. J. Jaffar and J. L. Lassez. Constraint logic programming. In Proc. of the ACM\\n\\nSymposium on Principles of Programming Languages, pages 111–119. ACM Press,\\n1987.\\n\\n10. J. Jaffar, M. J. Maher, K. Marriott, and P. J. Stuckey. The semantics of constraint\\nlogic programs. Journal of Logic Programming, 37(1-3):1–46, 1998.\\n\\n11. F. Mesnard, E. Payet, and U. Neumerkel. Detecting optimal termination condi-\\ntions of logic programs. In M. Hermenegildo and G. Puebla, editors, Proc. of the\\n\\n9th International Symposium on Static Analysis, volume 2477 of Lecture Notes in\\n\\nComputer Science, pages 509–525. Springer-Verlag, Berlin, 2002.\\n12. F. Mesnard and S. Ruggieri. On proving left termination of constraint logic pro-\\n\\ngrams. ACM Transactions on Computational Logic, pages 207–259, 2003.\\n13. E. Payet and F. Mesnard. Non-termination inference of logic pro-\\n\\ngrams. ACM Transactions on Programming Languages and Sys-\\n\\ntems. Accepted for publication. Preliminary version available at\\nhttp://www2.univ-reunion.fr/~gcc/papers.htm.\\n\\n14. E. Payet and F. Mesnard. Non-termination inference for constraint logic pro-\\ngrams. In Roberto Giacobazzi, editor, Proc. of the 11th International Symposium\\n\\non Static Analysis, volume 3148 of Lecture Notes in Computer Science, pages 377–\\n392. Springer-Verlag, Berlin, 2004.\\n\\n15. P. Refalo and P. Van Hentenryck. CLP (Rlin) revised. In M. Maher, editor, Proc. of\\n\\nthe Joint International Conf. and Symposium on Logic Programming, pages 22–36.\\nThe MIT Press, 1996.\\n\\n16. Y-D. Shen, L-Y. Yuan, and J-H. You. Loops checks for logic programs with func-\\ntions. Theoretical Computer Science, 266(1-2):441–461, 2001.\\n\\n17. J. Shoenfield. Mathematical Logic. Addison Wesley, Reading, 1967.\\n18. C. Speirs, Z. Somogyi, and H. Søndergaard. Termination analysis for Mercury. In\\n\\nP. van Hentenrick, editor, Proc. of the 1997 Intl. Symp. on Static Analysis, volume\\n1302 of LNCS. Springer-Verlag, 1997.\\n\\n15\\n\\n\\n'], 'name': '0508106v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0508/0508106v1.pdf', 'vectorized': None}, {'@search.score': 16.419804, '@search.rerankerScore': 3.1176469326019287, '@search.captions': [{'text': 'A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1 Constraint Logic Programming  Constraint logic programming (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers).', 'highlights': 'A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1<em> Constraint Logic Programming  Constraint logic programming</em> (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers).'}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMDExLzAwMTEwMzB2MS5wZGY1', 'title': 'arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000', 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n00\\n\\n11\\n03\\n\\n0v\\n1 \\n\\n [\\ncs\\n\\n.A\\nI]\\n\\n  2\\n1 \\n\\nN\\nov\\n\\n 2\\n00\\n\\n0\\n\\nLogic Programming Approaches for\\n\\nRepresenting and Solving Constraint\\n\\nSatisfaction Problems: A Comparison\\n\\nNikolay Pelov, Emmanuel De Mot, and Marc Denecker\\n\\nDepartment of Computer Science, K.U.Leuven\\nCelestijnenlaan 200A, B-3001 Heverlee, Belgium\\n\\nE-mail: {pelov,emmanuel,marcd}@cs.kuleuven.ac.be\\n\\nAbstract. Many logic programming based approaches can be used to\\ndescribe and solve combinatorial search problems. On the one hand there\\nis constraint logic programming which computes a solution as an answer\\nsubstitution to a query containing the variables of the constraint satis-\\nfaction problem. On the other hand there are systems based on stable\\nmodel semantics, abductive systems, and first order logic model gen-\\nerators which compute solutions as models of some theory. This paper\\ncompares these different approaches from the point of view of knowledge\\nrepresentation (how declarative are the programs) and from the point of\\nview of performance (how good are they at solving typical problems).\\n\\n1 Introduction\\n\\nConsistency techniques are widely used for solving finite domain constraint sat-\\nisfaction problems (CSP) [19]. These techniques have been integrated in logic\\nprogramming, resulting in finite domain constraint logic programming (CLP)\\n[20]. In this paradigm, a program typically creates a data structure holding the\\nvariables of the CSP to be solved, sets up the constraints and uses a labelling\\ntechnique to assign values to the variables. The constraint solver uses consistency\\ntechniques to prune the search. This leads to a rather procedural programming\\nstyle. Moreover, the problem description is not very declarative because the map-\\nping between domain variables and their value has an indirect representation in\\na term structure.\\n\\nIn this paper, we compare CLP and three computational paradigms allowing\\nproblem solving based on more declarative representations. A common feature of\\nthese approaches is that the relation between the CSP variables and their values\\nis encoded as a predicate or function relating identifiers of the CSP variables\\nwith their value. E.g. in the graph coloring problem, the predicate relates node\\nnumbers with colors. This representation allows for a more natural declarative\\nrepresentation of the problem.\\n\\nOne approach is specification in first order logic. As pointed out in [12], one\\ncan represent a CSP as a first order logic theory such that (part of) its models\\n\\nhttp://arXiv.org/abs/cs/0011030v1\\n\\n\\ncorrespond to the solutions of the CSP. Hence first order model generators such\\nas SEM [24] can be used to solve such problems.\\n\\nThe two other approaches use extensions of logic programming. Recently, a\\nlogic programming paradigm based on stable model semantics [6] has emerged.\\nNiemelä [14] proposes it as a constraint programming paradigm, Marek and\\nTruszczyński [13] introduce Stable Logic Programming and Lifschitz [11] pro-\\nposes Answer Set Programming. As described in [13], the methodology of these\\napproaches is to encode a computational problem by a logic program such that\\nits stable models represent the solutions. A number of efficient systems for com-\\nputing stable models have been developed. Of these, Niemelä’s smodels [15, 14]\\nis considered one of the most performant systems.\\n\\nAbduction [8] uses a similar predicate representation for the relation between\\nthe identifiers of CSP variables and their value. This predicate is declared to be\\nopen or abducible. Constraining this relation to be a solution, an abductive\\nsystem will return models of the abducible which are solutions of the CSP.\\n\\nWe use some typical CSP problems to compare the merits of the various\\napproaches. One experiment is in graph coloring. We have compared the rep-\\nresentation and the performance of CLP with the three other approaches in a\\nsequence of experiments where the size of the graph increases and the number\\nof colors remains constant. Another experiment is the n-queens problem where\\nboth the domain size and the number of constraints increases with increasing\\nproblem size. We also report on experiments using CLP, stable logic program-\\nming and abduction for solving a complex real world scheduling problem. For\\neach different system, we have tried to use any special features provided by it.\\n\\nIn Section 2 we review in more detail the various approaches and systems,\\nfocusing mainly on the knowledge representation aspects. Section 3 reports on\\nthe experiments and we conclude in Section 4.\\n\\nWe are not aware of any previous work which compares this wide range of\\nlogic based systems for their suitability in solving CSP problems. Mackworth [12]\\nexplores the space of possible CSP formalizations but assesses neither the quality\\nfrom point of view of knowledge representation nor the performance of actual\\nsystems. Also, approaches based on stable model semantics and abduction are\\nnot included in his work. ', 'This paper is an extension and revision of [17] which\\nfocuses more on the formal relations between the declarative specifications of\\nthe problems on the different systems.\\n\\nOne more problem which uses aggregate functions is included in the present\\npaper. So is an additional experiment for finding all solutions of the n-queens\\nproblem. Finally, some comments from the authors of the different systems were\\ntaken into account.\\n\\n2 Formalisms and Systems\\n\\nA constraint satisfaction problem (CSP) is usually defined as a finite set of con-\\n\\nstraint variables X = {X1, . . . , Xn} (the variables of the CSP), a finite domain\\nDi of possible values for each variable Xi, and a finite set of constraint relations\\n\\n\\n\\nR where each r ∈ R is a constraint between a subset of the set X of variables. A\\nsolution is an instantiation of the variables of X which satisfies all the constraints\\nin R.\\n\\n2.1 Constraint Logic Programming\\n\\nConstraint logic programming (CLP) [7] is an extension of logic programming\\nwhere some of the predicate and function symbols have a fixed interpretation over\\nsome subdomain (e.g. finite trees or real numbers). Special purpose constraint\\nsolvers are integrated with a logic programming system for efficient reasoning on\\nthese symbols. This results in a very expressive language which can efficiently\\nsolve problems in many domains.\\n\\nVan Hentenryck [20] pioneered the work on finite domain constraint logic\\nprogramming, CLP(FD), by introducing domain declarations for the logic vari-\\nables and integrating consistency techniques as part of the SLD proof procedure.\\nA CLP(FD) system supports standard arithmetic relations (=, 6=, <) and func-\\ntions (+,−, ∗) on the natural numbers. A typical formulation of the n-queens\\nproblem is as follows:\\n\\nqueens(N, L)←\\nlength(L, N),\\ndomain(L, 1, N),\\nconstrain all(L),\\nlabeling(L).\\n\\nconstrain all([]).\\nconstrain all([X |Xs])←\\n\\nconstrain between(X, Xs, 1)\\nconstrain all(Xs).\\n\\nconstrain between(X, [], N).\\nconstrain between(X, [Y |Y s], N)←\\n\\nsafe(X, Y, N),\\nN1 is N + 1,\\nconstrain between(X, Y s, N1).\\n\\nsafe(X1, X2, D)←\\nX1 6= X2, abs(X1 −X2) 6= D.\\n\\nExecuting the query queens(n, L) first creates a list L with n variables where\\nthe ith variable gives the column position of the queen on row i. Then the\\nconstraints expressed with the safe/3 predicate are added by using two nested\\nrecursive predicates. Such procedural code for setting up constraints and the\\nencoding of the solution in a large data structure results in a rather procedural\\nstyle which is typical for the CLP approach.\\n\\n2.2 First Order Logic: Model Generation\\n\\nThe most elegant solution for the n-queens problem is using many sorted first\\norder logic and first order model generation. Systems like FINDER and SEM\\n\\n\\n\\n[24] are examples. One can introduce functions (with the sorts of their domain\\nand range) and predicates (with the sorts of their domains and the sort bool as\\nrange). In addition, functions can be restricted to be injective, bijective, . . . This\\nallows to express the n-queens problem very concisely as:\\n\\nD = {1..n}\\n\\npos : D → D (bijection)\\n\\nabs(pos(X1)− pos(X2)) 6= X2 −X1 ← X1 < X2.\\n\\nThe first line declares D as a sort with interpretation consisting of the set of\\nintegers 1 to n. The following line introduces the function pos/1 as a bijection\\nfrom D to D. Hence, the range of the function is a permutation of its domain.\\nThis function represents the column positions of the queens. The only remaining\\nconstraint is that queens have to be on different diagonals. This is expressed by\\nthe formula on the third line using the predefined functions abs/1 and −/2. Due\\nto symmetry, one need only to verify the constraint for pairs of queens X1, X2\\n\\nsuch that X1 < X2.\\n\\nSolutions are given by the interpretation of the pos/1 function in the models\\nof this theory. In principle, this approach is applicable on any CSP problem by\\nrepresenting the CSP variables by logical constants. However, in most cases, CSP\\nvariables are just an encoding of some attribute of a set of first order objects,\\nsuch as the position of a queen or the color of a node in a graph. In such cases,\\nthere is no need to introduce the CSP variable. The attribute can be represented\\ndirectly as a function or predicate on these objects (e.g. pos).\\n\\nAs the domains of all sorts are finite, SEM first computes the grounding\\nof the theory and then uses backtracking combined with various inference and\\nsimplification rules to guide the search for models [24].\\n\\n2.3 Stable Logic Programming\\n\\nIn [14], Niemelä proposes logic programming with the stable model semantics [6]\\nas a constraint logic programming paradigm. The underlying idea is to represent\\na problem as a set of rules, each rule being the declarative expression of a piece\\nof knowledge about the problem domain and such that the stable models of the\\nwhole program are constrained to be solutions of the problem.\\n\\nThe smodels system [15] is an efficient implementation of the stable model\\nsemantics. ', 'It works with propositional rules and a special pre-processing program\\nis used for grounding strongly range restricted logic programs. The implementa-\\ntion combines bottom-up inference with backtracking search and employs pow-\\nerful pruning methods. A recent extension of the system [16] introduces choice\\nrules:\\n\\nl {l1, l2, . . . ln} u← B.\\n\\n\\n\\nwhere l1, l2, . . . ln are literals. The semantics of such a rule is that if the body B\\nis true then at least l and at most u literals among li should be true in a stable\\nmodel of the program.\\n\\nFollowing [14] and [16], the program for the n-queens problems can be for-\\nmulated as:\\n\\nd(1..n).\\n\\n1 {pos(X, Y ) : d(Y )} 1← d(X).\\n1 {pos(X, Y ) : d(X)} 1← d(Y ).\\n\\n← d(X1), d(Y1), d(X2), d(Y2), pos(X1, Y1), pos(X2, Y2),\\nX1 < X2, X2 −X1 = abs(Y1 − Y2).\\n\\nSolutions are given by the pos(i, j) atoms in the stable models of the program.\\nThe first line defines that d/1 is a domain with elements 1..n with n the size of\\nthe board. The first choice rule is used to define the solution space of the problem\\nby stating that for each X in the domain d(X), there exists exactly one Y such\\nthat pos(X, Y ) is true. The colon notation denotes an expansion of pos(X, Y )\\nfor every value of Y . Similarly, the second choice rule expresses that there is\\nexactly one queen on each column. The last rule defines the final constraint of\\nthe problem: no two queens on the same diagonal. Again, the “<” constraints in\\nthese rules eliminate instances which are redundant due to symmetry. The main\\ndifference with the first order logic specification is that the mapping between\\nqueens and their position is now represented by a predicate. Declaring that this\\npredicate represents a bijective function is succinctly expressed by the two choice\\nrules.\\n\\n2.4 Abduction\\n\\nAbductive logic programming [8] extends the logic programming paradigm with\\nabductive reasoning. An abductive logic program has three components: (1) a\\nlogic program P , (2) a set of predicates A called abducibles or open predicates,\\nand (3) a set of integrity constraints I. The abducibles are predicates not defined\\nin the program. The task of an abductive system is to find a set ∆ of ground\\nabducible atoms such that the integrity constraints are true in the logic program\\nconsisting of P ∪∆; formally: P ∪∆ |= I.\\n\\nKakas and Michael proposed an integration of CLP and an abductive logic\\nprogramming system [9]. Originally, it was defined only for definite programs\\nand integrity constraints and in [10] it was extended to deal with negation as\\nfailure through abduction in a similar way as in [5]. One restriction of ACLP\\nis that integrity constraints need to be of the form ← a(X̄), B, where a is an\\nabducible. As we will see, this forces sometimes to reformulate some constraints\\nby an additional recursion. Such restrictions are not present in SLDNFAC [3], a\\nmore recent integration of an abductive system with CLP that is based on the\\nmore general abductive procedure SLDNFA [2].\\n\\n\\n\\nThe SLDNFAC system uses ID-Logic [1] as specification language which is\\ntransformed into an abductive logic program by using a Lloyd-Topor transfor-\\nmation. The specification of the n-queens problem is:\\n\\nd(1..n).\\n\\nopen function(pos(d, d)).\\n\\nY1 6= Y2 ∧X2 −X1 6= Y2 − Y1 ∧X2 −X1 6= Y1 − Y2\\n\\n⇐ pos(X1, Y1) ∧ pos(X2, Y2) ∧X1 < X2.\\n\\nThe first line of the program defines d/1 as a domain predicate with the integers\\n1..n as elements (defining rows and columns). The next line states that the\\npredicate pos/2 represents an open function in the defined domain. It is used to\\nrepresent the column position of a queen in a row. Finally there is a constraint\\nsaying that two queens can not be on the same column and diagonal. This\\nrepresentation is almost identical to the FOL specification of section 2.2. The\\nmain difference is that the open function is represented by a predicate.\\n\\nAs mentioned, ACLP does not allow function declarations. Consequently, the\\nfact that pos predicate represents a function must be expressed by explicit con-\\nstraints. A standard way to axiomatize that the abductive predicate pos(X, Y )\\nshould be true for each X in the domain d(X) is by using the following rule and\\nintegrity constraints:\\n\\nhas pos(X)← d(Y ), pos(X, Y ).\\n← d(X), not has pos(X).\\n\\nUnfortunately, the integrity constraint does not satisfy the ACLP’s restriction\\nthat at least one positive abductive atom should occur in it. Hence, these axioms\\nhave to be reformulated using a recursive program which generates a position\\nfor each queen. The specification for the ACLP system is:\\n\\nA = {pos/2}\\n\\nproblem(N)← nqueens(N, N).\\nnqueens(0, N).\\nnqueens(X, N)← X > 0, Y in 1..N, pos(X, Y ),\\n\\nXnext is X − 1, nqueens(Xnext, N).\\n\\nattack(X1, Y1, X2, Y2)← Y1 = Y2.\\nattack(X1, Y1, X2, Y2)← Y1 + X1 = Y2 + X2.\\nattack(X1, Y1, X2, Y2)← Y1 −X1 = Y2 −X2.\\n\\n← pos(X1, Y1), pos(X2, Y2), X1 < X2, attack(X1, Y1, X2, Y2).\\n\\nThe n-queens problem is solved by solutions of the abductive query← problem(n).\\n', 'The ACLP representation is in the middle of the declarative FOL representation\\nand the more procedural CLP representation.\\n\\n\\n\\n3 Experiments\\n\\n3.1 The Systems\\n\\nThe finite domain CLP package is the one provided with ECLiPSe version 4.2.\\nBoth abductive systems, ACLP [10] and SLDNFAC, [3] are meta interpreters\\n\\nwritten in Prolog, running on ECLiPSe version 4.2 and making use of its fi-\\nnite domain library. For all these systems, a search strategy which first selects\\nvariables with the smallest domain which participate in the largest number of\\nconstraints was used.\\n\\nThe model generator SEM version 1.7 is a fine tuned package written in C.\\nsmodels version 2.25, the system for computing stable models, is implemented in\\nC++ and the associated program used for grounding is lparse version 0.99.54.\\nAll experiments have been done on the same hardware, namely Pentium II.\\n\\n3.2 Graph Coloring\\n\\n0.01\\n\\n0.1\\n\\n1\\n\\n10\\n\\n100\\n\\n1000\\n\\n10000\\n\\n10 100 1000\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nNodes\\n\\nGraph Coloring\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 1. Graph coloring\\n\\nOur first experiment is done with 4-colorable graphs. We used a graph gen-\\nerator1 program which is available from address http://web.cs.ualberta.ca/\\n1 The graphs have been generated with the following parameters: 0, 13, 6, n, 4, 0.2, 1,\\n\\n0 where n is the number of vertices. Graph-coloring problems generated with these\\nparameters are difficult.\\n\\n\\n\\n~joe/Coloring/Generators/generate.html. We applied the systems in a se-\\nquence of experiments with graphs of increasing size and constant number of\\ncolors. We have modified only one parameter of the problem namely the number\\nof vertices. Figure 1 gives the results of solving the problem with the different\\nsystems. Both axes are plotted in a logarithmic scale. On the x-axis we have put\\nthe number of vertices. Not surprisingly, CLP is the fastest system. The times\\nfor smodels is second best on this problem. We assume it is in part because of\\nthe very concise formulation. Using the so called technique of rules with excep-\\ntions [14], the two rules needed to describe the space of candidate solutions also\\nencode the constraint that the color is a function of the vertex. Hence there is\\nonly one other rule, namely the constraint that two adjacent vertices must have\\na different color. The difference with CLP is almost two orders of magnitude\\nfor the largest problems. The times reported for smodels do not include the\\ntime for grounding the problem, these times only consist of a small part of the\\ntotal time. Grounding the problem for 650 nodes takes only 10 seconds, whereas\\nsolving the problem takes over 100 seconds. SLDNFAC is slightly worse than\\nsmodels. Although meta-interpretation overhead tends to increase with prob-\\nlems size, the difference with smodels grows very slowly. The model generator\\nSEM deteriorates much faster and runs out of memory for the larger problems.\\nThe fact that it grounds the whole theory is a likely explanation. The differ-\\nence with smodels supports the claim that smodels has better techniques for\\ngrounding. ACLP performs substantially worse than SLDNFAC and also dete-\\nriorates faster. The difference is likely due to the function-specification available\\nin SLDNFAC. Contrary to ACLP, SLDNFAC exploits the knowledge that the\\nabducible encodes a function to reduce the number of explicitly stored integrity\\nconstraints.\\n\\n3.3 N-Queens\\n\\nFigure 2 gives the running times for the different systems for finding a first\\nsolution. Both axes are plotted on a linear scale. The time consumed while\\ngrounding is again not included in the graph (for 18 queens, half a second).\\nAgain, CLP gives the best results. SLDNFAC is second best and, although meta-\\ninterpretation overhead increases with problem size, deteriorates very slowly.\\nACLP is third2, with a small difference, probably due to the lack of the function-\\nspecification mentioned in the section above. The next one is SEM. It runs out\\nof memory for large problems (it needs about 120MB for 27 queens). smodels\\n\\nperforms very poorly on this problem, in particular when compared with its\\nperformance on the graph coloring problem. It is well-known that to obtain good\\nresults for computing the first solution for the n-queens problem, a good search\\nheuristic is needed, like the first fail principle used by the systems based on CLP.\\nWe believe that the bad performance of smodels is explained by the absence of\\n\\n2 The results with ACLP are substantially better than those in the previous paper [17].\\nThis is due to the removal of a redundant and time consuming complete consistency\\ncheck after the processing of each new CLP constraint.\\n\\n\\n\\n0\\n\\n2\\n\\n4\\n\\n6\\n\\n8\\n\\n10\\n\\n10 15 20 25 30\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nQueens\\n\\nN-Queens\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 2. N-queens: one solution\\n\\n0.01\\n\\n0.1\\n\\n1\\n\\n10\\n\\n100\\n\\n1000\\n\\n4 5 6 7 8 9 10 11 12 13\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nQueens\\n\\nN-Queens (all solutions)\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFig. 3. N-queens: all solutions\\n\\n\\n\\nappropriate heuristics. ', 'This is confirmed by the much better performance of the\\nsystem in computing all solutions.\\n\\nFigure 3 gives the running times for finding all solutions. The y-axis is plot-\\nted on a logarithmic scale. The CLP, ACLP and SLDNFAC systems are based\\non the same finite domain constraint solver, so their convergence is not unex-\\npected. Indeed, the abductive system generates a constraint problem which is\\nequivalent to the problem generated by the CLP program and no backtracking\\noccurs in the abductive system. Hence, its overhead becomes ignorable. Also\\nthe SEM system converges to the same performance as CLP (but runs out of\\nmemory for big problems). In this experiment, the smodels system performs\\nmuch better but is still the slowest system. A likely reason for this is that the\\nnumber of propositional variables in the n-queens problem grows quadratically\\nwith the problem size, in contrast with the graph coloring problem where the\\nnumber of variables grows only linearly (because of a constant number of colors).\\nConsequently, the grounding grows faster for this problem. The CLP consistency\\ntechniques seem to be much less sensitive to the domain size, and this carries\\nover to the abductive systems which reduce the problem to a CLP problem and\\nthen use the CLP solver to search for the solution.\\n\\n3.4 A Real World Problem\\n\\nA Belgian electricity company has a number of power plants divided in geo-\\ngraphic areas. Each power plant has a number of power generating units, each of\\nwhich must receive a given number (usually 1 or 2) of preventive maintenances\\nwith a fixed duration in the course of one year. The computational problem is to\\nschedule these maintenances according to some constraints and optimality crite-\\nria. Some of the constraints are: some time slots are prohibited for maintenance\\nfor some units; for each power plant, there is an upper limit on the total number\\nof units in maintenance per week for reasons of availability of personnel; some\\nof the maintenances are fixed in advance, . . . The objective of the problem is to\\nfind a schedule that maximizes the minimal weekly reserve, which is the sum\\nof the capacity of all units not in maintenance minus the expected weekly peak\\nload.\\n\\nThis is a rather difficult problem in several aspects. Firstly, the specification\\nuses aggregate expressions like cardinality and sum (e.g. for each area, there is\\nan upper limit to the total capacity for units in maintenance per week). Only\\nCLP, smodels and SLDNFAC support some form of aggregates and only these\\nsystems were used in our experiment. Also, the search space is very large, as\\nthere are 56 maintenances to be scheduled in 52 weeks which makes about 5652\\n\\ncombinations3. The company provided a set of constraints for which the optimal\\nsolution was known to have a minimal week reserve of 2100 (100%). The three\\nsystems found correct schedules but none was able to find this optimal solution.\\n\\n3 The maintenances with duration of more than one week cannot be scheduled in week\\n52, hence this number is only an upper approximation.\\n\\n\\n\\nThis application was first considered in a context of a master’s thesis [18] and\\nthen reported in [4], where a first attempt was done for integrating the SLDNFA\\nproof procedure with the CLP system ROPE [23, 22]. This early system needed\\n24 hours to reduce the problem to a constraint store. Later on, in [22] several\\ndifferent direct encodings in CLP of the problem were presented and compared.\\nRecently, [21] discussed an extension of the SLDNFAC system with aggregate\\nfunctions and this problem was used as a benchmark.\\n\\nThe first version of the smodels system did not support aggregate expres-\\nsions. A more recent version of the system added a limited support for rules\\nwith a body consisting of a single cardinality or sum constraint [16] and allowed\\nus to specify the problem. However, these aggregate constraints cannot be used\\nfor computing the sum or the cardinality of a set of atoms and we were not\\nable to express the optimization function. By setting increasing lower bounds on\\nthe reserve capacity, branch and bound can be simulated manually. It should be\\nnoted that, because of the very large size of the problem, the specification of the\\nproblem in the smodels system had to be redesigned with special care in order\\nto produce a ground program not exceeding the limits of the system.\\n\\nTable 1 summarizes the results of executing the problem with the different\\nsystems. The first row “Setup” gives the time used for pre-processing the problem\\nspecification. For the abductive systems, this is the time for reducing the high-\\nlevel specification to a set of constraints. For the smodels system this is the\\ntime for grounding the program. The rest of the rows give the times used by the\\nconstraint solver to find a solution with the given quality. The results for CLP\\nare taken from [22] for a standard encoding of the problem4 and the program\\nwas run under SICStus Prolog.\\n\\nReserve CLP SLDNFACsmodels\\n\\nSetup 45 36.4\\n\\n', '1900 63.2 8.07\\n2000 7.71 62.9 >8h\\n2010 25.85 63.8\\n2020 43.73 62.9\\n2030 57.28 63.0\\n2040 71.63 261.1\\n2050 26843.50 871.3\\n\\nTable 1. Power plant scheduling\\n\\nIn the case of SLDNFAC, it can be seen in Table 1 that substantial progress\\nwas made. Rather than the 24h needed in the earlier version [4], the current\\nSLDNFAC procedure only needs 45 seconds for reducing the problem and about\\n15 minutes for finding a solution of level 2050 (97.6%). A solution with reserve\\ncapacity of 2030 (96.5%) was found in less than two minutes. Note that the\\n\\n4 Without using global constraints, like cumulative.\\n\\n\\n\\ntimings for a solution with a reserve capacity of 1900 up to 2030 are similar.\\nThis is explained by the fact that in the five cases the same solution with reserve\\ncapacity of 2030 was computed. The small differences in timings are due to\\nnoise in the measurements. Strange enough, CLP deteriorates when it reaches\\na solution for a reserve capacity of 2050 whereas the SLDNFAC solution does\\nnot. This must be due to the fact that the constraint store built by the CLP\\nsolution differs from the one built by the SLDNFAC solution. This is accidental:\\nin general, constraint stores constructed by a hand made CLP program are more\\nefficient than the ones computed by SLDNFAC. The smodels system needed\\n40 seconds for grounding and the best solution we were able to find was 1900\\n(90.5%) in 8 seconds. We did not find better solutions in reasonable time.\\n\\n4 Conclusion\\n\\nFinite domain CLP is widely accepted as an excellent tool for CSP solving.\\nHowever CLP programs have drawbacks from the point of view of knowledge\\nrepresentation. As explained in Section 2.1, the variables of the CSP have to be\\norganized in a data structure and “procedural” code is required to create this\\ndata structure and to set up the constraints. This level of indirection increases\\nthe conceptual distance between the program and the problem and makes pro-\\ngrams less declarative. Recently, several attempts have been made to introduce\\nformalisms allowing more declarative formalizations. They are based on stable\\nmodel semantics [11, 13, 14] and on abduction [9, 10, 3]. Although these systems\\nhave an expressivity beyond what is needed to describe a CSP (they address\\nnon-monotonic reasoning while CSP solving requires only negation of primitive\\nconstraints), it is worthwhile to compare these systems with CLP which is state\\nof the art for CSP solving. Because both stable models and abduction express\\nsolutions to problems as models of their theory, we have also included first or-\\nder model generators in our study [24]. As argued in Section 2, these three\\napproaches are better than CLP from knowledge representation point of view,\\nthe formalizations are more natural, more readable, conceptually closer to the\\nproblem, in short they are more declarative than CLP programs. Which one of\\nthe three discussed mechanisms is the most declarative is likely a matter of taste\\nand familiarity.\\n\\nInevitably there is a price to be paid for these higher level descriptions. None\\nof the “declarative” systems experimented with comes close to the performance\\nlevel of CLP. This result holds although the CLP system is not favored by\\nthe problem choice. Indeed, in both graph coloring and n-queens problem, all\\nconstraints are disequality constraints which are known to give little propagation.\\n\\nOur experiments show that first order model generators do not scale well\\nand run out of memory for large problem instances even though the size of the\\nground program is smaller compared to smodels. We think that this is not\\nan inherent limitation of the approach but rather that such systems were writ-\\nten with the goal of fast performance and this is visible in our experiemnts. In\\ncontrast, smodels runs in linear space wrt the size of the grounding [15] and\\n\\n\\n\\nwas able to solve all problem sizes. Of the two abductive systems, SLDNFAC\\nsupports a substantially richer formalism and is performing slightly better than\\nACLP. As the two systems follow more or less the same strategy of top-down\\nreduction of integrity constraints and of forwarding the reduced ones to the CLP\\nsolver and as both are implemented as a Prolog meta-interpreter, the difference\\nseems to be mainly due to the support of function specifications. The fact that\\nthe SLDNFAC meta-interpreter outperforms SEM (a fine tuned C implementa-\\ntion) on both problems and compares very well with the C++ implementation of\\nsmodels (it is much better on the n-queens problem while it reaches almost the\\nsame performance on the graph coloring problem) suggest that its overall strat-\\negy is the best one of the three systems for CSP solving. Also the experiments\\nwith the large scheduling problem suggest this: the setup time is acceptable and\\ndifferences in search time seem to be due to differences in the order of traversing\\nthe search space. While the difference with CLP is substantial, a low level imple-\\n', 'mentation or compilation should be able to come close to the performance levels\\nof CLP, offering the best of both worlds: declarative problem formulations and\\nefficient execution. However, SLDNFA, the procedure underlying SLDNFAC, is\\ncomplex, hence building a direct implementation is a hard task. We believe the\\ndevelopment of such a system is a worthwhile topic for future research.\\n\\nAcknowledgements\\n\\nNikolay Pelov, Emmanuel De Mot and Marc Denecker are supported by the\\nGOA project LP+. We want to thank Maurice Bruynooghe for his contribution\\non the topic and anonymous referees for their useful comments.\\n\\nReferences\\n\\n[1] M. Denecker. Extending classical logic with inductive definitions. In J. Lloyd\\net al., editors, First International Conference on Computational Logic, volume\\n1861 of Lecture Notes in Artificial Intelligence, pages 703–717, London, U.K.,\\nJuly 2000. Springer.\\n\\n[2] M. Denecker and D. De Schreye. SLDNFA: an abductive procedure for abductive\\nlogic programs. Journal of Logic Programming, 34(2):201–226, Feb. 1998.\\n\\n[3] M. Denecker and B. Van Nuffelen. Experiments for integration CLP and ab-\\nduction. In K. Apt, A. Kakas, E. Monfroy, and F. Rossi, editors, Proceedings of\\nthe 1999 ERCIM/COMPULOG Workshop on Constraints, Paphos, Cyprus, Oct.\\n1999. University of Cyprus.\\n\\n[4] M. Denecker, H. Vandecasteele, D. De Schreye, G. Seghers, and T. Bayens.\\nScheduling by “abductive execution” of a classical logic specification. In\\nERCIM/COMPULOG Workshop on Constraints, Schloss Hagenberg, Austria,\\nOct.27–28 1997.\\n\\n[5] K. Eshghi and R. Kowalski. Abduction compared with negation by failure. In\\nG. Levi and M. Martelli, editors, Proceedings of the Sixth International Conference\\non Logic Programming, pages 234–254. Lisbon, Portugal, MIT Press, June 1989.\\n\\n\\n\\n[6] M. Gelfond and V. Lifschitz. The stable model semantics for logic programming.\\nIn R. A. Kowalski and K. A. Bowen, editors, Logic Programming, Proceedings\\nof the Fifth International Conference and Symposium, pages 1070–1080, Seattle,\\nWashington, Aug. 1988. MIT Press.\\n\\n[7] J. Jaffar and M. Maher. Constraint logic programming: A survey. Journal of\\nLogic Programming, 19/20:503–581, 1994.\\n\\n[8] A. C. Kakas, R. Kowalski, and F. Toni. Abductive logic programming. Journal\\nof Logic and Computation, 2(6):719–770, Dec. 1992.\\n\\n[9] A. C. Kakas and A. Michael. Integrating abductive and constraint logic program-\\nming. In L. Sterling, editor, Proceedings of the 12th International Conference on\\nLogic Programming, pages 399–413. Tokyo, Japan, MIT Press, 1995.\\n\\n[10] A. C. Kakas, A. Michael, and C. Mourlas. ACLP: Abductive constraint logic\\nprogramming. Journal of Logic Programming, 44(1–3):129–177, 2000.\\n\\n[11] V. Lifschitz. Answer set planning. In D. De Schreye, editor, Proceedings of the\\n16th International Conference on Logic Programming, pages 23–37. MIT Press,\\nDec. 1999.\\n\\n[12] A. K. Mackworth. The logic of constraint satisfaction. Journal of Artificial Intel-\\nligence, 58(1–3):3–20, Dec. 1992.\\n\\n[13] V. W. Marek and M. Truszczyński. Stable models and an alternative logic pro-\\ngramming paradigm. In K. R. Apt, V. W. Marek, M. Truszczyński, and D. S.\\nWarren, editors, The Logic Programming Paradigm: A 25-Year Perespective, pages\\n375–398. Springer, 1999.\\n\\n[14] I. Niemelä. Logic programs with stable model semantics as a constraint program-\\nming paradigm. Annals of Mathematics and Artificial Intelligence, 25(3,4):241–\\n273, 1999.\\n\\n[15] I. Niemelä and P. Simons. Efficient implementation of the well-founded and sta-\\nble model semantics. In M. Maher, editor, Logic Programming, Proceedings of the\\n1996 Joint International Conference and Syposium, pages 289–303, Bonn, Ger-\\nmany, Sept. 1996. MIT Press.\\n\\n[16] I. Niemelä, P. Simons, and T. Soininen. Stable model semantics of weight con-\\nstraint rules. In M. Gelfond, N. Leone, and G. Pfeifer, editors, Proceedings of the\\nFifth International Conference on Logic Programming and Nonmonotonic Rea-\\nsoning, volume 1730 of Lecture Nortes in Computer Science, pages 317–331, El\\nPaso, Texas, USA, Dec. 1999. Springer-Verlag.\\n\\n[17] N. Pelov, E. De Mot, and M. Bruynooghe. A comparison of logic programming\\napproaches for representation and solving of constraint satisfaction problems. In\\nM. Denecker, A. Kakas, and F. Toni, editors, 8th International Workshop on\\nNon-Monotonic Reasoning, Special Session on Abduction, Breckenridge, Colorado,\\nUSA, Apr. 2000.\\n\\n[18] G. Seghers and T. Bayens. Solving a combinatorial maintenance problem for elec-\\ntrical power plants, developed in OLP-FOL and CLP. Master’s thesis, Department\\nof Computer Science, K.U.Leuven, 1996.\\n\\n[19] E. Tsang. Foundations of Constraint Satisfaction. Computation in Cognitive\\nScience. Academic Press, 1993.\\n\\n[20] P. Van Hentenryck. Constraint Satisfaction in Logic Programming. MIT Press,\\n1989.\\n\\n[21] B. Van Nuffelen and M. Denecker. Problem solving in ID-logic with aggregates.\\nIn A. K. Mark Denecker, editor, Eight International Workshop on Nonmonotonic\\n', 'Reasoning, special track on Abductive Reasoning, Breckenridge, Colorado, USA,\\n2000. Workshop associated with KR’2000.\\n\\n\\n\\n[22] H. Vandecasteele. Constraint Logic Programming: Applications and Implementa-\\ntion. PhD thesis, K.U.Leuven, 1999.\\n\\n[23] H. Vandecasteele and D. De Schreye. Implementing a finite-domain CLP-language\\non top of Prolog: a transformational approach. In F. Pfenning, editor, Proceedings\\nof Logic Programming and Automated Reasoning, volume 822 of Lecture Notes in\\nArtificial Intelligence, pages 84–98, Kiev, Ukraine, 1994. Springer-Verlag.\\n\\n[24] J. Zhang and H. Zhang. Constraint propagation in model generation. In U. Mon-\\ntanari and F. Rossi, editors, Proc. of 1st International Conference on Principles\\nand Practice of Constraint Programming, volume 976 of Lecture Notes in Com-\\nputer Science, pages 398–414, France, Sept. 1995. Springer.\\n\\n\\n'], 'name': '0011030v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0011/0011030v1.pdf', 'vectorized': None}, {'@search.score': 13.492614, '@search.rerankerScore': 3.1030943393707275, '@search.captions': [{'text': 'A CLP(FD) system provides primitives for  accessing and updating attribute values. A CLP(FD) system provides equality (=), disequality (6=), and inequality con-  straints. In addition, a CLP(FD) system also provides some other constraints such  as global constraints.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNTA2LzA1MDYwMDV2MS5wZGY1', 'title': None, 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n05\\n\\n06\\n00\\n\\n5v\\n1 \\n\\n [\\ncs\\n\\n.P\\nL\\n\\n] \\n 2\\n\\n J\\nun\\n\\n 2\\n00\\n\\n5\\n\\nUnder consideration for publication in Theory and Practice of Logic Programming 1\\n\\nProgramming Finite-Domain Constraint\\n\\nPropagators in Action Rules\\n\\nNeng-Fa Zhou\\n\\nDepartment of Computer and Information Science\\n\\nCUNY Brooklyn College & Graduate Center\\n\\nzhou@sci.brooklyn.cuny.edu\\n\\nsubmitted 30 March 2003; revised 20 May 2004, 6 Januari 2005; accepted 30 May 2005\\n\\nAbstract\\n\\nIn this paper, we propose a new language, called AR (Action Rules), and describe how\\nvarious propagators for finite-domain constraints can be implemented in it. An action\\nrule specifies a pattern for agents, an action that the agents can carry out, and an event\\npattern for events that can activate the agents. AR combines the goal-oriented execution\\nmodel of logic programming with the event-driven execution model. This hybrid execution\\nmodel facilitates programming constraint propagators. A propagator for a constraint is an\\nagent that maintains the consistency of the constraint and is activated by the updates of\\nthe domain variables in the constraint. AR has a much stronger descriptive power than\\nindexicals, the language widely used in the current finite-domain constraint systems, and\\nis flexible for implementing not only interval-consistency but also arc-consistency algo-\\nrithms. As examples, we present a weak arc-consistency propagator for the all distinct\\n\\nconstraint and a hybrid algorithm for n-ary linear equality constraints. B-Prolog has been\\nextended to accommodate action rules. Benchmarking shows that B-Prolog as a CLP(FD)\\nsystem significantly outperforms other CLP(FD) systems.\\n\\nKEYWORDS: constraint programming, constraint propagation, action rules\\n\\n1 Introduction\\n\\nCLP(FD), the constraint logic programming language over finite domains, has\\n\\nbeen proved effective for solving a large number of real-life optimization prob-\\n\\nlems (Dincbas et al. 1990; Jaffar and Maher 1994). The key operation employed in\\n\\nCLP(FD) is called constraint propagation (Kumar 1992; Tsang 1993), which uses\\n\\nconstraints actively to prune search spaces as follows: whenever a variable changes,\\n\\ni.e., the variable has been instantiated or its domain has been updated, the do-\\n\\nmains of all the remaining variables are filtered to contain only those values that\\n\\nare consistent with this variable. There may exist different propagation rules for a\\n\\nconstraint depending on the level of consistency to be achieved. Constraint prop-\\n\\nagation has been employed to solve not only constraints over finite domains but\\n\\nalso constraints over trees, lists, finite sets, floating-point numbers, and many other\\n\\ndomains (Jaffar and Maher 1994).\\n\\nhttp://arXiv.org/abs/cs/0506005v1\\n\\n\\n2 N.F. Zhou\\n\\nIn early CLP(FD) systems, such as the CHIP system (Dincbas et al. 1988), con-\\n\\nstraints are interpreted rather than compiled. Constraints are first transformed into\\n\\ncanonical-form terms and are then executed by an interpreter that performs, among\\n\\nother things, constraint propagation. The propagation procedure adopted is general\\n\\nenough for handling all types of constraints. Learning from the success of compil-\\n\\ning Prolog programs into the Warren Abstract Machine (WAM) (Warren 1983),\\n\\na former research group at ECRC extended the WAM for compiling CLP(FD)\\n\\n(Aggoun and Beldiceanu 1991). The CHIP compiler compiles constraints into low-\\n\\nlevel instructions such that different specialized propagation procedures are used\\n\\nfor different types of constraints. This black-box approach has proved problematic\\n\\nbecause it is too complicated and lacks flexibility and extendibility. The extended\\n\\nWAM in the CHIP system (Aggoun and Beldiceanu 1991) has over 100 instructions\\n\\nfor compiling finite-domain constraints alone!\\n\\nA language construct, called indexicals, has been quite popular as an intermediate\\n\\nlanguage for compiling finite-domain constraints. The language was first proposed in\\n\\n(van Hentenryck et al. 1992) and then popularized by (Codognet and Diaz 1996).\\n\\nThis language is also adopted by other systems (Carlsson et al. 1997; Sidebottom and Havens 1996).\\n\\nAn indexical is a primitive constraint in the form of X in r, where X is a domain\\n\\nvariable and r is a range expression for X . For each indexical, a propagation pro-\\n\\ncedure specific to it is used. Indexicals are claimed to be a glass-box approach to\\n\\ncompiling constraints in contrast with the black-box CHIP compiler. Nevertheless,\\n\\nas the delaying mechanism is embedded in range expressions, indexicals are not as\\n\\nopen as claimed. Indexicals can be used to compile arithmetic constraints, but are\\n\\ntoo weak to be used to program many other kinds of propagators.\\n\\nCHR (Constraint Handling Rules) (Frühwirth 1998) may currently be the most\\n\\npowerful implementation language for constraints. It can be used to program not\\n\\nonly constraint propagators but also constraint reasoning rules. CHR has been\\n\\nimplemented and integrated with ECLiPSe, SICStus, HAL, and Oz. CHR resembles\\n\\n', 'a production system. In CHR, the left-hand side of a rule specifies a pattern of\\n\\nconstraints in the constraint store and the right-hand side specifies new constraints\\n\\nto replace those on the left-hand side or to be added into the store. The left-hand\\n\\nside of a rule may have multiple constraint patterns. This feature is helpful for\\n\\nreasoning about the constraint store. For example, A > B & B > C → A >\\n\\nC + 1 is a CHR rule that generates the constraint A > C + 1, which is helpful\\n\\nalbeit redundant. The strong descriptive power, however, is not offered without\\n\\ncost. For CHR, a sophisticated matching algorithm is needed to match constraint\\n\\npatterns against the constraint store. Now, constraint solvers implemented in CHR\\n\\nare still an order of magnitude slower than constraint interpreters implemented in\\n\\nC (Holzbaur and Fruhwirth 1999; Holzbaur et al. 2004).\\n\\nThis paper proposes a new language, called AR (Action Rules), which can be used\\n\\nto program event handling in general and constraint propagation in particular. An\\n\\naction rule specifies a pattern for agents, an action that the agents can carry out,\\n\\nand an event pattern for events that can activate the agents. An agent behaves in an\\n\\nevent-driven manner. An agent can be suspended when certain conditions on it are\\n\\nsatisfied and can be activated when certain events are posted. AR is an extension of\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 3\\n\\ndelay constructs such as delay clauses (Meier 1994) that allows for the descriptions\\n\\nof not only delay conditions but also activating events and actions (Zhou 1998).\\n\\nThe syntax, operational semantics, and implementation of AR will be described in\\n\\nSection 3.\\n\\nThe focus of this paper is on how to implement various propagators for finite-\\n\\ndomain constraints in AR. A propagator for a constraint is an agent that maintains\\n\\nthe consistency of the constraint and is activated by the updates of the domain vari-\\n\\nables in the constraint. In Section 4, we present propagators for binary, non-binary,\\n\\nand the global constraint all distinct. AR is more expressive than indexicals.\\n\\nSome of the propagators presented, such as the one for maintaining arc consistency\\n\\nfor binary equality constraints and the one for maintaining weak arc consistency\\n\\nfor all distinct, cannot be implemented in indexicals as efficiently.\\n\\nB-Prolog has been extended to accommodate AR and several constraint solvers\\n\\nincluding the ones over finite domains, Boolean, trees, and finite sets have been\\n\\ndeveloped in AR (Zhou 2002). Section 5 compares the performance of the finite-\\n\\ndomain solver of B-Prolog with GNU-Prolog (GP), a state-of-the-art implemen-\\n\\ntation of CLP(FD) (Diaz and Codognet 2001), and two other CLP(FD) systems:\\n\\nECLiPSe and SICStus. Benchmarking results show that B-Prolog is significantly\\n\\nfaster than GP and 4-6 times as fast as ECLiPSe and SICStus.\\n\\nReaders are assumed to be familiar with logic programming and constraint sat-\\n\\nisfaction, but no knowledge about the compilation is assumed. In Section 2, we\\n\\ndefine some preliminary terms and concepts about CLP(FD) and constraint prop-\\n\\nagation. Readers are referred to (Marriott and Stuckey 1998), (Hentenryck 1989)\\n\\nand (Kumar 1992) for the details. A brief description of the implementation of AR\\n\\nis given in Section 3, and a more detailed description can be found in (Zhou 2003).\\n\\n2 Preliminaries\\n\\n2.1 CLP(FD)\\n\\nCLP(FD) (Hentenryck 1989) is an extension of Prolog that supports built-ins for\\n\\nspecifying domain variables, constraints, and strategies for instantiating variables.\\n\\nThe domains of variables are declared as follows:\\n\\nV ars in D\\n\\nwhere V ars is a variable or a list of variables, and D is a list of ground terms\\n\\nor a range between two integers l..u. A domain variable is normally represented\\n\\nas a Prolog variable with attributes. A CLP(FD) system provides primitives for\\n\\naccessing and updating attribute values.\\n\\nA CLP(FD) system provides equality (=), disequality (6=), and inequality con-\\n\\nstraints. In addition, a CLP(FD) system also provides some other constraints such\\n\\nas global constraints. The global constraint all distinct(L) ensures that the el-\\n\\nements in the list L must be all pairwise different.\\n\\n\\n\\n4 N.F. Zhou\\n\\n2.2 Constraint propagation\\n\\nConstraint Propagation (Kumar 1992; Tsang 1993) is a key operation employed in\\n\\nCLP(FD) systems for maintaining the consistency of constraints. The basic idea of\\n\\nconstraint propagation is to activate the propagators of constraints whenever the\\n\\ndomains of the variables in the constraints are updated. Propagating the updates\\n\\nto other variables may result in the shrinking of the domains of the variables or the\\n\\ninstantiation of the variables.\\n\\nThere are different levels of consistency for constraints such as node, interval,\\n\\nbounds, arc, and path consistency (Tsang 1993; Marriott and Stuckey 1998). We\\n\\ndefine below three levels of consistency needed in this paper, namely node, interval\\n\\n', 'and arc consistency, and define the propagators that maintain them.\\n\\nA unary constraint p(X), where X has the domain D, is said to be node-consistent\\n\\nif, for any element x in D, p(x) is satisfied.\\n\\n∀x∈Dp(x)\\n\\nFor example, for the equality constraint X = Y +1, when X is instantiated to 3, the\\n\\nconstraint becomes unary and Y must be instantiated to 2 to make the constraint\\n\\nnode-consistent. As another example, for the disequality constraint X 6= Y , when\\n\\nX is instantiated to 3, 3 must be excluded from the domain of Y to make the\\n\\nconstraint node-consistent. The propagation rule that maintains node consistency\\n\\nis called forward checking. A propagator for a constraint that performs forward\\n\\nchecking is activated whenever the constraint becomes unary.\\n\\nLet C be a linear equality constraint c + a1 × X1 + a2 ×X2 + . . . + an ×Xn = 0\\n\\nwhere ai 6= 0 and Xi is defined over the domain Di (i = 1, . . . , n). Let\\n\\ngi(X1, . . . , Xi−1, Xi+1, . . . , Xn) =\\n\\n−c − a1 × X1 − . . . − ai−1 × Xi−1 − ai+1 × Xi+1 − . . . − an × Xn\\n\\nai\\n\\nand l and u be the functions defined as follows:\\n\\nl(gi(X1, . . . , Xi−1, Xi+1, . . . , Xn)) =\\n\\nmin{gi(x1, . . . , xi−1, xi+1, . . . , xn)|xk ∈ Dk, 1 ≤ k ≤ n, k 6= i}\\n\\nu(gi(X1, . . . , Xi−1, Xi+1, . . . , Xn)) =\\n\\nmax{gi(x1, . . . , xi−1, xi+1, . . . , xn)|xk ∈ Dk, 1 ≤ k ≤ n, k 6= i}\\n\\nThe constraint C is said to be interval consistent w.r.t. Xi if:\\n\\n∀x∈Di\\n(l(gi(X1, . . . , Xi−1, Xi+1, . . . , Xn)) ≤ x ≤ u(gi(X1, . . . , Xi−1, Xi+1, . . . , Xn))\\n\\nTo make the constraint interval consistent w.r.t. Xi, we have to exclude all the\\n\\nelements from Di that are not in the range. The constraint C is said to be interval\\n\\nconsistent if C is interval consistent w.r.t. all the variables. For example, the con-\\n\\nstraint X = Y +1, where X and Y have the domain 1..5, is not interval-consistent.\\n\\nTo make the constraint interval consistent, we have to exclude 1 from the domain\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 5\\n\\nof X and 5 from the domain of Y . Propagators for maintaining interval consistency\\n\\nare activated whenever a bound of a variable is updated or whenever a variable is\\n\\ninstantiated. The definition can be easily extended to an inequality constraint.\\n\\nConsider a binary constraint p(X, Y ) where X and Y are defined over the domains\\n\\nDx and Dy, respectively. The constraint is said to be arc-consistent w.r.t. X if for\\n\\nany element in Dx there exists a supporting element in Dy such that the constraint\\n\\nis satisfied:\\n\\n∀x∈Dx\\n∃y∈Dy\\n\\np(x, y)\\n\\nSimilarly, the constraint is arc-consistent w.r.t. Y if for any element in Dy there\\n\\nexists a supporting element in Dx such that the constraint is satisfied:\\n\\n∀y∈Dy\\n∃x∈Dx\\n\\np(x, y)\\n\\nThe constraint is arc-consistent if it is arc-consistent w.r.t. both X and Y . For\\n\\nexample, the equality constraint X = Y + 1 (X ∈ {2, 4, 5}, Y ∈ {1..4}) is not\\n\\narc-consistent since there is no element in the domain of X that supports 2 in\\n\\nthe domain of Y . To make the constraint arc-consistent, we must exclude 2 from\\n\\nthe domain of Y . Propagators for maintaining arc consistency are triggered when-\\n\\never changes occur to the domain of a variable. Maintaining arc consistency for\\n\\na non-binary constraint requires examining Cartesian products of the domains\\n\\n(Dechter 2003) and is thus very costly. For this reason, some CLP(FD) systems\\n\\nmaintain arc consistency only for binary constraints and many others do not con-\\n\\nsider arc consistency at all.\\n\\n2.3 Domain variables\\n\\nA domain variable is a suspension variable to which there are suspended propagators\\n\\nand some other information attached. A domain variable is represented in B-Prolog\\n\\nas a record that has the following fields:\\n\\nref reference to the value\\n\\ntype type of the domain\\n\\nmin minimum element in the domain\\n\\nmax maximum element in the domain\\n\\nsize number of elements that remain in the domain\\n\\nins cs list of propagators to be executed when the variable is instantiated\\n\\nbound cs list of propagators to be executed when a bound is updated\\n\\ndom cs list of propagators to be executed when an inner element is excluded\\n\\nelms pointer to the bit vector representation of the elements\\n\\nwhere ref refers to the variable itself if the variable is not instantiated, and elms is\\n\\na pointer to a bit vector that represents the elements. When a domain is an interval\\n\\nwithout holes, no bit vector is necessary and elms is a null pointer.\\n\\nThe following built-in predicates and functions are available on domain variables.\\n\\n• dvar(X): Succeeds if X is a domain variable.\\n\\n\\n\\n6 N.F. Zhou\\n\\n• min(X), max(X): Functions that return, respectively, the minimum and max-\\n\\nimum elements of the domain of X .\\n\\n• size(X, Size): The size of the domain of X is Size.\\n\\n• exclude(X, E): Excludes the element E from the domain of X .\\n\\n• Xin D: The new domain for X is the intersection of its existing domain and\\n\\nD where D is a set of ground terms or a range l..u of integers.\\n\\nA failure occurs when the domain of a variable becomes empty. When the domain\\n\\n', 'of a variable becomes a singleton, the variable is instantiated to the element auto-\\n\\nmatically.\\n\\nAn event is posted whenever the domain of a variable is updated. For a domain\\n\\nvariable X , instantiating X posts the event ins(X),1 updating the lower or upper\\n\\nbound of the domain posts the event bound(X), and excluding an inner element E\\n\\nfrom the domain posts the event dom(X, E). Notice that the event bound(X) is not\\n\\nposted when X is instantiated and the event dom(X, E) is not posted when either\\n\\nbound of the domain of X is updated. This implies that a propagator that maintains\\n\\narc consistency has to handle not only dom(X, E) events but also bound(X) and\\n\\nins(X) events.\\n\\nEach event on a domain variable activates its corresponding list of propagators.\\n\\nThe event ins(X) activates the propagator list ins cs of X , bound(X) activates\\n\\nthe list bound cs, and dom(X, E) activates the list dom cs.\\n\\n3 The AR Language\\n\\nAR is designed for programming interactive agents. In this section, we describe the\\n\\nsyntax, operational semantics, and implementation of AR.\\n\\n3.1 Syntax\\n\\nAn action rule takes the following form:\\n\\nAgent, Condition, {Event} => Action\\n\\nwhere Agent is an atomic formula that represents a pattern for agents, Condition\\n\\nis a conjunction of conditions on the agents, Event is a non-empty disjunction\\n\\nof patterns for events that can activate the agents, and Action is a sequence of\\n\\nsubgoals.2 Condition and the following comma can be omitted if no condition is\\n\\nneeded on Agent. Action cannot be empty. The subgoal true represents an empty\\n\\naction that always succeeds. An action rule degenerates into a commitment rule if\\n\\nEvent together with the enclosing braces are missing. Conditions, event patterns,\\n\\nand actions are all atomic formulas where the delimiter ‘,’ is used to separate the\\n\\nconstituents.\\n\\nAn AR predicate consists of a sequence of rules defining agents of the same\\n\\n1 A variable is said to be instantiated if it is bound to another term, possibly another variable.\\n2 Subgoals in Action can be any subgoals including those defined by Prolog clauses.\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 7\\n\\npredicate symbol. In a program, AR predicates can be intermingled with Prolog\\n\\npredicates. In this paper, the term agents is used to refer to subgoals that can\\n\\nbe suspended and activated, and the term predicate is used refer to both AR and\\n\\nProlog predicates unless explicitly specified.\\n\\nAll conditions must be in-line tests.3 In the implementation of AR in B-Prolog,\\n\\nthe following types of conditions are allowed:\\n\\n• Type and mode checking: Predicates like integer(X), var(X), and nonvar(X).\\n\\n• Matching: A matching call takes the form of X = Y where one of the ar-\\n\\nguments must be a non-variable term at compile time and the other must\\n\\nbe a variable (again at compile time) that occurs before in the rule. The\\n\\nnon-variable term serves as a pattern and the variable refers to a term to be\\n\\nmatched against the pattern. This call succeeds if the pattern and the term\\n\\nbecome identical after a substitution is applied to the pattern. For instance,\\n\\nthe condition f(X) = Y succeeds if Y is a structure whose functor is f/1.\\n\\n• Term inspection: Several built-in predicates including arg/3, functor/3, ==/2,\\n\\n\\\\==/2, and n vars gt/2 can be used in the condition of a rule to inspect the\\n\\narguments of an agent. The call n vars gt(Term, N) succeeds if the number\\n\\nof variables occurring in Term is greater than N .\\n\\n• Arithmetic comparison: Checks the arithmetic equality (=:=), disequality\\n\\n(=\\\\=), or inequality (>, >=, <, and =<) of two terms which must be ground\\n\\nat runtime.\\n\\nA set of built-in events is provided.4 As far as programming constraint propaga-\\n\\ntors is concerned, an event pattern can be one of the following:\\n\\n• generated: The action of the rule is executed when the agent is suspended\\n\\nfor the first time.\\n\\n• ins(X): The agent is activated when an event ins(X) is posted.\\n\\n• bound(X): The agent is activated when an event bound(X) is posted.\\n\\n• dom(X) and dom(X, E): The agent is activated when an event dom(X, E′) is\\n\\nposted. Before the action is executed, E is made to reference the element E′.\\n\\nA user program can create and post its own events and define agents to handle\\n\\nthem. A user-defined event takes the form of event(X, T) where X is a suspension\\n\\nvariable that connects the event with its handling agents, and T is a Prolog term\\n\\nthat contains the information to be transmitted to the agents. If the event poster\\n\\ndoes not have any information to be transmitted to the agents, then the second\\n\\nargument T can be omitted. The built-in post(E) posts the event E.\\n\\nIn an action rule, the event pattern dom(X, T) or event(X, T) is not allowed to\\n\\ncoexist with any other event patterns and T must be a first-occurring variable so\\n\\nthat when the action of the rule is executed T always refers to the second argument\\n\\nof the event.\\n\\n3 An in-line call is compiled into instructions that do not invoke any predicates. ', 'A test does not\\nchange the instantiation status of the variables in its arguments.\\n\\n4 In the implementation in B-Prolog, built-in events are provided for programming constraint\\npropagators, graphical user interfaces, and interactive agents.\\n\\n\\n\\n8 N.F. Zhou\\n\\n3.2 Examples\\n\\nThe following defines an agent that echoes the messages sent to it by event posters.\\n\\necho_agent(X), {event(X,Message)} => write(Message).\\n\\nThe following query,\\n\\necho_agent(Ping), echo_agent(Pong),\\n\\npost(event(Ping,ping)), post(event(Pong,pong))\\n\\ngenerates two echo agents echo agent(Ping) and echo agent(Pong), and activates\\n\\nthem by posting two events. The event event(Ping,ping) activates the agent\\n\\necho agent(Ping), and the event event(Pong,pong) activates echo agent(Pong).\\n\\nThe following defines the freeze predicate in Prolog-II (Colmerauer 1984).\\n\\nfreeze(X,G), var(X), {ins(X)} => true.\\n\\nfreeze(X,G) => call(G).\\n\\nThe primitive freeze(X,G) is logically equivalent to call(G) but the execution of\\n\\nG is delayed until X is instantiated to a non-variable term. The agent freeze(X,G) is\\n\\nsuspended waiting for an event ins(X) when X is a variable. When an event ins(X)\\n\\nis posted, the condition var(X) is tested again. If it succeeds, then the action true\\n\\nis executed and the agent becomes suspended again. As long as X is a free variable,\\n\\nthe agent freeze(X,G) is suspended. Only when X becomes a non-variable term,\\n\\ncan the second rule be applied.\\n\\nConsider, as another example, how to implement the following indexical:\\n\\nX in min(Y)+min(Z)..max(Y)+max(Z).\\n\\nwhich ensures that the constraint X = Y+Z is interval-consistent w.r.t. X.\\n\\n‘V in V+V’(X,Y,Z),{generated,ins(Y),bound(Y),ins(Z),bound(Z)} =>\\n\\nreduce_domain(X,Y,Z).\\n\\nreduce_domain(X,Y,Z) =>\\n\\nL is min(Y)+min(Z), U is max(Y)+max(Z),\\n\\nX in L..U.\\n\\nThe propagator is activated whenever a bound of Y or Z is updated or either one is\\n\\ninstantiated. The action reduce domain(X,Y,Z) enforces that the domain of X be\\n\\nin the range min(Y)+min(Z)..max(Y)+max(Z). The action is also executed before\\n\\nthe propagator is first suspended so that no preprocessing is needed to enforce\\n\\ninterval consistency.\\n\\n3.3 Operational Semantics\\n\\nThe operational semantics of AR can be presented as a state-transition system\\n\\nas shown in Figure 1. An agent may be in one of the following states: start, sleep,\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 9\\n\\nFig. 1. Diagram of state transition of agents.\\n\\nwoken, and end. When an agent is generated, it enters the start state and is executed\\n\\nimmediately. A typical agent transits to the end state through the sleep and woken\\n\\nstates. An agent is said to be floundering if it stays in the sleep state forever. It is\\n\\nthe programmer’s responsibility to prevent agents from floundering.\\n\\nWhen an agent is generated, the system searches in its predicate in textual order\\n\\nfor a rule whose agent-pattern matches the agent and whose condition is satisfied.\\n\\nThis kind of rule is said to be applicable to the agent. Formally, an action rule\\n\\n“H, C, {E} => B” or a commitment rule “H, C => B” is applicable to an agent α\\n\\nif there exists a unifier θ such that Hθ = α and Cθ is satisfied.5 If no rule is found\\n\\napplicable, the agent fails. If a commitment rule is found, the agent is substituted\\n\\nfor the body,6 and its state is changed to end.\\n\\nIf an action rule “H, C, {E} => B” is found for the agent, the agent is suspended,\\n\\ntransiting from start to sleep. It will stay in the sleep state until it is activated by\\n\\none of the events in E.\\n\\nWhen an event is posted, all the sleeping agents waiting for the event in the\\n\\nsystem are woken up and the event is erased after that so that no agents generated\\n\\nlater will be responsive to this event. The woken agents are added to the queue of\\n\\nactive subgoals in some order. It is up to the implementer of the language to use\\n\\na strategy to schedule activated agents. Whatever scheduling strategy is adopted,\\n\\nthe programmer should not rely on the strategy to guarantee the correctness of\\n\\nprograms.\\n\\nSuppose an agent was put into sleep by the action rule “H, C, {E} => B” and\\n\\nwas woken up by one of the events in E. After this agent is picked by the scheduler,\\n\\nthe system tests the condition C again. If it is satisfied, the action B is executed.\\n\\nIf the action succeeds, the agent is re-suspended. If the action fails, the agent fails\\n\\nas well. If the condition C of the action rule does not hold, the system searches for\\n\\nan alternative applicable rule for the agent just as for a newly generated agent.\\n\\nThere is no primitive for killing agents explicitly. An agent never disappears as\\n\\nlong as action rules are applied to it successfully. An agent transits to the end state\\n\\nonly when a commitment rule is applied to it.\\n\\n5 Notice that since one-directional matching rather than full unification is used to search for an\\napplicable rule and in the condition no variable in α can be instantiated, the agent remains the\\nsame after an applicable rule is found.\\n\\n', '6 A commitment rule is similar to a guarded clause in concurrent logic languages (Shapiro 1989),\\nbut an agent can never be blocked while it is being matched against an agent pattern.\\n\\n start sleep woken end \\n\\n\\n\\n10 N.F. Zhou\\n\\n3.4 The Implementation\\n\\nThe abstract machine of B-Prolog, called ATOAM (Zhou 1996b), is extended to\\n\\nsupport agents (Zhou 2003). This subsection briefly describes this implementation.\\n\\nA more detailed description can be found in (Zhou 2003).\\n\\n3.4.1 The frame structure for agents\\n\\nThe ATOAM is a variant of the Warren Abstract Machine (WAM) (Warren 1983).\\n\\nUnlike in the WAM where arguments are passed through argument registers, argu-\\n\\nments in the ATOAM are passed through stack frames and only one frame is used\\n\\nfor each subgoal. Each time a predicate is invoked by a subgoal, a frame is placed\\n\\non top of the control stack unless the frame currently at the top can be reused.\\n\\nFrames for different types of predicates have different structures.\\n\\nAgents are stored as frames on the control stack. The frame for an agent has the\\n\\nfollowing slots in addition to those included in a normal frame:7\\n\\nSTATE: State of the agent\\n\\nEVENT: Activating event\\n\\nREEP: Re-entrance program pointer\\n\\nPREV: Previous agent in the chain\\n\\nThe STATE slot has one of those states shown in Figure 1 as its value. The EVENT\\n\\nslot stores the last event that activated the agent. The action rule of the agent can\\n\\nhave access to this event. The REEP slot stores the program pointer to continue\\n\\nwhen the agent is activated. The PREV slot stores the pointer to the previous\\n\\nagent’s frame in the chain of agents.\\n\\nThe frames on the control stack comprise three chains, namely the chain of active\\n\\nsubgoals8 that are being executed, the chain of choice points, i.e., subgoals that have\\n\\nalternative clauses to be tried when execution backtracks to them, and the chain\\n\\nof agents in either sleep or woken states.\\n\\nStoring agents on the stack facilitates context switching for agents (Zhou 1996a)\\n\\nbut complicates memory management. With frames of agents on the stack, the\\n\\nchronological order of frames is no longer preserved, and therefore a garbage collec-\\n\\ntor is needed to collect useless frames on the control stack and run-time checking\\n\\nis needed to determine whether the current frame can be reused.\\n\\n3.4.2 When and how to invoke agents?\\n\\nFor the sake of efficiency, events are not checked after each instruction but checked\\n\\nat the entry and exit points of each predicate. If it is found that the list of events\\n\\n7 A normal frame has the following slots: arguments, FP (parent frame), CPS (continuation\\nprogram pointer on success), TOP (top of the control stack), BTM (bottom of the frame),\\nand local variables. A choice point frame has the following additional slots: CPF (continuation\\nprogram pointer on failure), B (parent choice point), H (top of the heap), and T (top of the\\ntrail stack).\\n\\n8 i.e., the frames connected by FP.\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 11\\n\\nis not empty, those agents that are waiting for the events are added into the active\\n\\nchain and the current predicate is interrupted. After the activated agents com-\\n\\nplete their execution successfully, the interrupted predicate resumes its execution.\\n\\nThe programmer has no control over the order in which agents are added. In our\\n\\nimplementation, the first-generated-first-served strategy is used.\\n\\nAt a point during execution, there may be multiple events posted that are all\\n\\nexpected by an agent. If this is the case, then the agent must be activated once for\\n\\neach of the events. If an agent is found to be active already when the system tries\\n\\nto add it into the active chain, the sytem makes a copy of it and adds the copy into\\n\\nthe chain.\\n\\nThe actions of constraint propagators are to reduce the domains of variables. This\\n\\ncharacteristic is exploited to improve the performance of constraint propagators.\\n\\nSome events that cannot lead to the shrinking of any domains are ignored. For\\n\\nexample, if multiple events of bound(X) are posted at the same time, then only one\\n\\nof them needs to be handled, and if bound(X) and ins(X) are posted at the same\\n\\ntime, then the bound(X) event is ignored. In this way, many redundant activations\\n\\nof rules that do not contribute to the reduction of any domains can be suppressed.\\n\\nThis optimization is applied to constraint propagators only and not general agents.\\n\\nIn a CLP(FD) program, constraint propagation is normally intertwined with\\n\\nnon-deterministic subgoals such as labeling that assign values to variables. If a\\n\\nnon-deterministic predicate is interrupted by events, then no choice point can be\\n\\ncreated for the interrupted predicate until the activated agents are all executed.\\n\\nConsider the following example:\\n\\n?-p(X),X=f(Y),q(X),write(X).\\n\\np(X),var(X),{ins(X)} => true.\\n\\np(X) => X=f(a).\\n\\nq(X):-fail.\\n\\nq(X).\\n\\nFirst the agent p(X) is generated, waiting for X to be instantiated. The subgoal\\n\\n', 'X=f(Y) posts an event ins(X) after X bound to f(Y). At the entry of q(X), the\\n\\nevent is detected and p(X) is activated. If there were a choice point created for q(X)\\n\\nbefore p(X) is activated, the binding Y=a given by the second rule of p(X) would\\n\\nbe lost when fail in q/1 is executed since Y is older than the choice point, and the\\n\\noutput from write(X) would be f(Y) not f(a).\\n\\n4 Programming Constraint Propagators in AR\\n\\nThe high descriptive power of AR opens new ways to implementing constraint\\n\\npropagators. In this section, we implement propagators that maintain node, in-\\n\\nterval, and arc consistency for binary constraints, a hybrid algorithm for non-\\n\\nbinary constraints, and a weak arc-consistency propagator for the global constraint\\n\\nall distinct.\\n\\n\\n\\n12 N.F. Zhou\\n\\n4.1 Binary constraints\\n\\nWe consider how to implement propagators for the binary constraint A × X =\\n\\nB × Y + C, where X and Y are domain variables, A and B are positive integers,\\n\\nand C is an integer of any kind. Similar propagators can be implemented for other\\n\\ntypes of binary constraints.\\n\\n4.1.1 Forward checking\\n\\nRecall that forward checking enforces node consistency. The following shows a prop-\\n\\nagator that performs forward checking for the binary constraint.\\n\\n‘aX=bY+c’(A,X,B,Y,C) =>\\n\\n‘aX=bY+c_forward’(A,X,B,Y,C).\\n\\n‘aX=bY+c_forward’(A,X,B,Y,C),var(X),var(Y),{ins(X),ins(Y)} => true.\\n\\n‘aX=bY+c_forward’(A,X,B,Y,C),var(X) =>\\n\\nT is B*Y+C, X is T//A, A*X=:=T.\\n\\n‘aX=bY+c_forward’(A,X,B,Y,C) =>\\n\\nT is A*X-C, Y is T//B, B*Y=:=T.\\n\\nThe operation op1//op2, which is equivalent to truncate(op1/op2), gives the\\n\\ninteger quotent of the division. When both X and Y are variables, the propagator\\n\\nis suspended. When either variable is instantiated, the propagator computes the\\n\\nvalue for the other variable.\\n\\n4.1.2 Interval consistency\\n\\nThe following propagator, which extends the forward-checking propagator, main-\\n\\ntains interval consistency for the constraint.\\n\\n‘aX=bY+c’(A,X,B,Y,C) =>\\n\\n‘aX=bY+c_reduce_domain’(A,X,B,Y,C),\\n\\n‘aX=bY+c_forward’(A,X,B,Y,C),\\n\\n‘aX=bY+c_interval’(A,X,B,Y,C).\\n\\nThe subgoal ‘aX=bY+c reduce domain’(A,X,B,Y,C) preprocess the constraint\\n\\nto make it interval-consistent when the constraint is generated.\\n\\n‘aX=bY+c_reduce_domain’(A,X,B,Y,C) =>\\n\\n‘aX in bY+c_reduce_domain’(A,X,B,Y,C),\\n\\nMC is -C,\\n\\n‘aX in bY+c_reduce_domain’(B,Y,A,X,MC).\\n\\n‘aX in bY+c_reduce_domain’(A,X,B,Y,C) =>\\n\\nL is (B*min(Y)+C) /> A,\\n\\nU is (B*max(Y)+C) /< A,\\n\\nX in L..U.\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 13\\n\\nThe operation op1 /> op2 returns the lowest integer that is greater than or equal\\n\\nto the quotient of op1 by op2 and the operation op1 /< op2 returns the greatest\\n\\ninteger that is less than or equal to the quotient. It can be proved easily that no\\n\\nvalue outside the range L..U satisfies the constraint.\\n\\nThe subgoal ‘aX=bY+c interval’(A,X,B,Y,C) maintains interval consistency\\n\\nfor the constraint.\\n\\n‘aX=bY+c_interval’(A,X,B,Y,C) =>\\n\\n‘aX in bY+c_interval’(A,X,B,Y,C), % reduce X when Y changes\\n\\nMC is -C,\\n\\n‘aX in bY+c_interval’(B,Y,A,X,MC). % reduce Y when X changes\\n\\n‘aX in bY+c_interval’(A,X,B,Y,C),\\n\\nvar(X),var(Y),\\n\\n{generated,bound(Y)}\\n\\n=>\\n\\n‘aX in bY+c_reduce_domain’(A,X,B,Y,C).\\n\\n‘aX in bY+c_interval’(A,X,B,Y,C) => true.\\n\\nNotice that the action ‘aX=bY+c reduce domain’(A,X,B,Y,C) is executed only\\n\\nwhen both variables are free. If either one turns to be instantiated, then the forward-\\n\\nchecking rule takes care of that situation.\\n\\n4.1.3 Arc consistency\\n\\nThe following propagator, which extends the one shown above, maintains arc con-\\n\\nsistency for the constraint.\\n\\n‘aX=bY+c’(A,X,B,Y,C) =>\\n\\n‘aX=bY+c_reduce_domain’(A,X,B,Y,C),\\n\\n‘aX=bY+c_forward’(A,X,B,Y,C),\\n\\n‘aX=bY+c_interval’(A,X,B,Y,C),\\n\\n‘aX=bY+c_arc’(A,X,B,Y,C).\\n\\n‘aX=bY+c_arc’(A,X,B,Y,C) =>\\n\\n‘aX in bY+c_arc’(A,X,B,Y,C), % reduce X when Y changes\\n\\nMC is -C,\\n\\n‘aX in bY+c_arc’(B,Y,A,X,MC).% reduce Y when X changes\\n\\n‘aX in bY+c_arc’(A,X,B,Y,C),var(X),var(Y),{dom(Y,Ey)} =>\\n\\nT is B*Ey+C,\\n\\nEx is T//A,\\n\\n(A*Ex=:=T -> exclude(X,Ex);true).\\n\\n‘aX in bY+c_arc’(A,X,B,Y,C) => true.\\n\\nWhenever an element Ey is excluded from the domain of Y, the propagator ‘aX in\\n\\nbY+c arc’(A,X,B,Y,C) is activated. If both X and Y are variables, the propagator\\n\\n\\n\\n14 N.F. Zhou\\n\\nexcludes Ex, the counterpart of Ey, from the domain of X. Again, if either X or Y\\n\\nbecomes an integer, the propagator does nothing. The forward checking rule takes\\n\\ncare of that situation.\\n\\n4.2 Non-binary Constraints\\n\\nIn indexical-based CLP(FD) systems, constraints are split into indexicals that con-\\n\\ntain no more than three variables. This algorithm has several advantages. Firstly,\\n\\nit generates linear-size code. Secondly, indexicals can be implemented in a low-level\\n\\nlanguage to achieve better performance. Thirdly, information propagation can be\\n\\nrestricted to only those constraints for which the domains have the possibility to\\n\\nbe reduced (Codognet and Diaz 1996). For example, consider the two ternary con-\\n\\nstraints T 1 = X1 + X2 and T 1 + X3 + X4 = 0. ', 'If T 1 = X1 + X2 is activated\\n\\nby an update of X1, as long as the shared variable T 1 does not change the other\\n\\nconstraint needs not be activated. The disadvantages of this algorithm are that new\\n\\ndomain variables have to be introduced and the granularity of constraints becomes\\n\\nsmaller and thus context switching becomes more costly. In B-Prolog, each domain\\n\\nvariable takes at least 10 words, letting alone the space for the constraints and\\n\\ndata structures for the elements. The space overhead cannot be neglected when the\\n\\nnumber of variables is large.\\n\\nIn comparison with indexicals, the high descriptive power of AR opens new ways\\n\\nto compiling non-binary constraints. We present two algorithms. One is called unite,\\n\\nwhich adopts one propagator for each constraint to maintain interval consistency.\\n\\nThe other one, called hybrid, maintains interval consistency when the constraint\\n\\ncontains more than two variables and maintains arc consistency when the constraint\\n\\nturns into binary.\\n\\n4.2.1 Unite: use one propagator for each constraint\\n\\nLet A1 × X1 + . . . + An × Xn + C = 0 be an n-ary constraint where each Ai\\n\\n(i = 1, . . . , n) is a non-zero integer and each Xi is a domain variable or an integer.\\n\\nThe propagator for the constraint takes the following form:\\n\\n‘A1*X1+...+An*Xn+C=0’(C,A1,A2,...,An,X1,X2,..,Xn),\\n\\n{generated,ins(X1),bound(X1),...,ins(Xn),bound(Xn)}\\n\\n=>\\n\\n... % reduce the domains of X1,...,Xn.\\n\\nIn the action, attempts are made to reduce the lower and upper bounds of the\\n\\ndomain of every variable.\\n\\nTo facilitate the generation of the code for reducing domains, the compiler splits\\n\\nthe expression A1×X1 + . . .+An×Xn +C into the following list of sub-expressions\\n\\neach of which contains at most three variables:\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 15\\n\\nT0 = C,\\n\\nT1 = T0 + A1 ∗ X1,\\n\\nT2 = T1 + A2 ∗ X2,\\n\\n. . .\\n\\nTn = Tn−1 + An ∗ Xn\\n\\nThe generated reducer first computes the lower and upper bounds of the temporary\\n\\nvariables9 by propagating information forward from T0 to Tn. The lower and upper\\n\\nbounds of Ti are computed from those of Ti−1 and Ai × Xi (i = 1, . . . , n). After\\n\\nthat, the reducer propagates information backward from Tn to T1. For each tuple\\n\\nTi = Ti−1 + Ai × Xi, the new bounds of Ti−1 and Xi are computed from those of\\n\\nTi.\\n\\nFor example, the following shows the propagator generated for the constraint\\n\\nX1+X2+X3+C = 0.\\n\\n‘X1+X2+X3+C=0’(C,X1,X2,X3)\\n\\n{generated,ins(X1),bound(X1),ins(X2),bound(X2),\\n\\nins(X3),bound(X3)}\\n\\n=>\\n\\n‘X1+X2+X3+C=0_reducer’(C,X1,X2,X3).\\n\\n‘X1+X2+X3+C=0_reducer’(C,X1,X2,X3) =>\\n\\nLt1 is C+min(X1), Ut1 is C+max(X1), % T1 = C+X1\\n\\nLt2 is Lt1+min(X2), Ut2 is Ut1+max(X2), % T2 = T1+X2\\n\\nLt3 is Lt2+min(X3), Ut3 is Ut2+max(X3), % T3 = T2+X3\\n\\nLt3 =< 0, Ut3 >= 0, % T3 = 0\\n\\n%\\n\\nNewLx3 is 0-Ut2, NewUx3 is 0-Lt2, % T3 = T2+X3\\n\\nX3 in NewLx3..NewUx3,\\n\\nNewLt2 is 0-max(X3), NewUt2 is 0-min(X3),\\n\\n%\\n\\nNewLx2 is NewLt2-Ut1, NewUx2 is NewUt2-Lt1,% T2 = T1+X2\\n\\nX2 in NewLx2..NewUx2,\\n\\nNewLt1 is NewLt2-max(X2), NewUt1 is NewUt2-min(X2),\\n\\n%\\n\\nNewLx1 is NewLt1-C, NewUx1 is NewUt1-C, % T1 = C+X1\\n\\nX1 in NewLx1..NewUx1,\\n\\nNewLt1-max(X1) =< C, NewUt1-min(X1) >= C.\\n\\nThe advantage of this algorithm is that only one propagator is used for each con-\\n\\nstraint whose code size is linear in the number of variables in the constraint. The\\n\\nweakness of this algorithm is that the reducer is not fast. Whenever a variable is in-\\n\\nstantiated or a variable’s bound is updated, the reducer tries to reduce the domains\\n\\nof all the variables including the seed variable that triggers the propagator.\\n\\n9 Temporary variables are plain variables, not domain variables. Therefore, this compilation\\nscheme is different from compiling constraints into indexicals.\\n\\n\\n\\n16 N.F. Zhou\\n\\n4.2.2 Hybrid: combining interval and arc consistency algorithms\\n\\nFor a non-binary constraint, it is too expensive to maintain arc consistency. One\\n\\npractical strategy is to maintain interval consistency while there are multiple vari-\\n\\nables in the constraint and to maintain arc consistency when the constraint turns\\n\\ninto binary. The following shows the propagator for the linear non-binary constraint\\n\\nA1 × X1 + ... + An × Xn + C=0.\\n\\n‘A1*X1+...+An*Xn+C=0’(C,A1,A2,...,An,X1,X2,..,Xn),\\n\\nn_vars_gt([X1,...,Xn],2),\\n\\n{generated,ins(X1),bound(X1),...,ins(Xn),bound(Xn)}\\n\\n=>\\n\\n... % reduce domains of X1,...,Xn.\\n\\n‘A1*X1+...+An*Xn+C=0’(C,A1,A2,...,An,X1,X2,..,Xn) =>\\n\\nnary_to_binary([C,A1,X2,A2,X2,...,An,Xn],NewC,B1,B2,Y1,Y2),\\n\\ncall_binary_constraint_propagator(NewC,B1,Y1,B2,Y2).\\n\\nThe propagator is activated whenever any variable is instantiated or its bound is\\n\\nupdated. When n vars gt([X1,...,Xn],2) succeeds, i.e. when there are multiple\\n\\nvariables in the constraint, the domains are reduced to make the constraint interval-\\n\\nconsistent. When the constraint becomes binary, the condition n vars gt fails and\\n\\nthe second rule is tried. The subgoal nary to binary transforms the constraint into\\n\\n', 'the binary constraint B1×Y 1+B2×Y 2+NewC=0, and the next subgoal invokes\\n\\nan appropriate propagator for the binary constraint.10\\n\\n4.3 Propagators for all distinct\\n\\nThe constraint all distinct(L) holds if the elements in L are pairwise different.\\n\\nOne naive implementation method for this constraint is to generate binary dise-\\n\\nquality constraints between all pairs of variables in L. This implementation has\\n\\ntwo problems: First, the space required to store the constraints is quadratic in the\\n\\nnumber of variables in L; Second, splitting the constraint into fine-grained ones may\\n\\nlose possible propagation opportunities (Regin 1994; Puget 1998). This subsection\\n\\npresents two propagators for the constraint. The propagation algorithms are not\\n\\nnew. The goal of this subsection is to illustrate the expressive power of AR.\\n\\n4.3.1 A linear-space propagator\\n\\nTo solve the space problem, we define all distinct in the following way:\\n\\nall_distinct(L) => all_distinct(L,[]).\\n\\nall_distinct([],Left) => true.\\n\\n10 In the implementation in B-Prolog, the two built-ins n vars gt and nary to binary do not take\\nthe constraint as an argument but instead access the constraint in the parent subgoal. In this\\nway, no copy of the constraint needs to be made.\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 17\\n\\nall_distinct([X|Right],Left) =>\\n\\noutof(X,Left,Right),\\n\\nall_distinct(Right,[X|Left]).\\n\\noutof(X,Left,Right), var(X), {ins(X)} => true.\\n\\noutof(X,Left,Right) => exclude_list(X,Left),exclude_list(X,Right).\\n\\nexclude_list(X,[]).\\n\\nexclude_list(X,[Y|Ys]):- exclude(Y,X),exclude_list(X,Ys).\\n\\nFor each variable X, let Left be the list of variables to the left of X and Right be the\\n\\nlist of variables to the right of X in L. The subgoal outof(X,Left,Right) holds if X\\n\\nappears in neither Left nor Right. Instead of generating disequality constraints be-\\n\\ntween X and all the variables in Left and Right, the subgoal outof(X,Left,Right)\\n\\nsuspends until X is instantiated. After X becomes non-variable, exclude list(X,Left)\\n\\nand exclude list(X,Right) exclude X from the domains of the variables in Left\\n\\nand Right, respectively.\\n\\nThere is one propagator outof(X,Left,Right) for each element X in the list,\\n\\nwhich takes constant space. Therefore, all distinct(L) takes linear space in the\\n\\nsize of L. Notice that the two lists Left and Right are not merged into one bigger\\n\\nlist; otherwise, the constraint would take quadratic space.\\n\\n4.3.2 Weak arc consistency\\n\\nIn terms of pruning ability, the linear-space propagator is the same as the naive\\n\\none that splits a constraint of all distinct into binary disequality constraints. In\\n\\nthis subsection, we present a propagator that has stronger prunning power than\\n\\nthe naive propagator.\\n\\nGiven any set of values D of size n, the constraint all distinct(L) is said to be\\n\\nweak arc consistent if there are at most n variables in L whose domains are subsets\\n\\nof D. For each variable X in L, let L−{X} be the list of variables in L but X , n be\\n\\nthe size of the domain of X , and m be the number of variables in L − {X} whose\\n\\ndomains are subsets of that of X . If m + 1 > n, then the constraint is unsatisfiable\\n\\nsince it is impossible to assign n values to more than n variables such that each\\n\\nvariable gets a different value. If m + 1 = n, then for each value v in X ’s domain,\\n\\nwe can safely exclude v from the domains of all the variables whose domains are\\n\\nnot subsets of that of X .\\n\\nConsider the following query,\\n\\nX in {1,2}, Y in {1,2}, Z in {1,2}, all_distinct([X,Y,Z]).\\n\\nthe weak arc-consistency propagator detects the inconsistency of the constraint\\n\\nwithout labeling any variables. For the following query,\\n\\nX in {1,2}, Y in {1,2}, Z in {1,2,3}, all_distinct([X,Y,Z]).\\n\\nthe algorithm assigns 3 to Z without labeling any variables.\\n\\n\\n\\n18 N.F. Zhou\\n\\nThe weak arc-consistency propagator is not as powerful as the algorithm proposed\\n\\nby Regin (Regin 1994) in terms of pruning ability but is much easier to implement.\\n\\nTo incorporate weak arc-consistency checking into the linear-space propagator, we\\n\\nonly need to redefine outof(X,Left,Right) as follows:\\n\\noutof(X,Left,Right), var(X), {generated,ins(X),bound(X),dom(X)} =>\\n\\noutof_reducer(X,Left,Right).\\n\\noutof(X,Left,Right) => exclude_list(X,Left),exclude_list(X,Right).\\n\\nwhere outof reducer(X,Left,Right) first counts the variables in Left and Right\\n\\nwhose domains are subsets of the domain of X and then decides what action to take\\n\\ndepending on the count and the size of the domain of X.\\n\\nThe key operation is to decide whether a domain is a subset of another domain.\\n\\nIn the worst case, the two domains have to be scanned. There are several facts that\\n\\ncan be used to avoid scanning domain elements. A domain D1 cannot be a subset\\n\\nof another domain D2 if D1 has a larger size or has a larger interval. Also if two\\n\\ndomains are intervals without holes, then scanning the elements is unnecessary.\\n\\nAnother fact that can be used in the detection is that if the event is dom(X,E)\\n\\n', 'meaning that E has been excluded from X’s domain, then another domain Y cannot\\n\\nbe a subset of X if E is included in Y. To take advantage of this fact, the propagator\\n\\ncan be rewritten into the following:\\n\\nall_distinct(L) => all_distinct(L,[]).\\n\\nall_distinct([],Left) => true.\\n\\nall_distinct([X|Right],Left) =>\\n\\noutof(X,Left,Right),\\n\\noutof_dom(X,Left,Right),\\n\\nall_distinct(Right,[X|Left]).\\n\\noutof(X,Left,Right), var(X), {generated,ins(X),bound(X)} =>\\n\\noutof_reducer(X,Left,Right).\\n\\noutof(X,Left,Right) => exclude_list(X,Left),exclude_list(X,Right).\\n\\noutof_dom(X,Left,Right),var(X), {dom(X,E)} =>\\n\\noutof_reducer(X,E,Left,Right).\\n\\noutof_dom(X,Left,Right) => true.\\n\\nThe subgoal outof reducer(X,E,Left,Right) takes E into account when detecting\\n\\nwhether a domain is a subset of that of X.\\n\\n5 Performance Evaluation\\n\\nB-Prolog has been extended to accommodate AR and the finite-domain constraint\\n\\nsolver described in this paper has been developed in AR. In this section, we evaluate\\n\\nthe performance of the finite-domain constraint solver.\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 19\\n\\nTable 1. Comparison of CPU times.\\n\\nProgram XP Linux\\n\\nBP-IC BP-AC GP EP SP BP-IC GP\\n\\nalpha 1 0.82 1.02 7.23 3.17 1 0.77\\nbridge 1 0.94 1.20 3.60 3.57 1 0.92\\ncars 1 1.00 1.67 7.03 4.67 1 1.60\\ncolor 1 1.14 1.00 6.29 3.01 1 1.25\\neq10 1 0.98 3.77 4.77 4.92 1 3.78\\neq20 1 1.06 2.00 4.23 3.34 1 1.96\\n\\nmagic3 1 1.38 1.98 8.44 4.41 1 1.52\\nmagic4 1 1.18 1.96 8.45 6.27 1 1.57\\nolympic 1 0.75 2.25 11.25 4.75 1 1.43\\n\\nqueens(25) 1 1.01 0.43 4.24 5.03 1 0.43\\nsendmoney 1 1.09 3.65 6.74 7.78 1 2.62\\nsudoku81 1 1.00 2.28 6.67 6.18 1 1.36\\n\\nzebra 1 1.13 2.33 7.86 9.61 1 1.77\\n\\n<arithmetic mean> 1 1.04 1.96 6.68 5.13 1 1.61\\n<geometric mean> 1 1.03 1.72 6.36 4.84 1 1.42\\n\\nWe compared the performance of B-Prolog version 6.7 (BP)11 with three other\\n\\nCLP(FD) systems: ECLiPSe 5.8 #77 (EP), GNU-Prolog version 1.2.16 (GP), and\\n\\nSICStus 3.12.0 (SP). There are two solvers available in BP: one is called BP-AC\\n\\nwhich adopts the hybrid algorithm presented in this paper for equality constraints\\n\\nand the other called BP-IC which maintains only interval consistency for equality\\n\\nconstraints. BP-AC is the default solver.12. The linear-space propagator is used for\\n\\nall distinct in both solvers.\\n\\nTable 1 shows the CPU times taken by the four solvers to run a set of bench-\\n\\nmarks,13 assuming the time taken by BP-IC be 1. Most of the benchmarks have been\\n\\nwidely used by other authors to compare CLP(FD) systems (Carlsson et al. 1997;\\n\\nCodognet and Diaz 1996; Hentenryck 1989). Three new programs were added by\\n\\nthe author into the set: color is a program that colors a map with 110 regions;\\n\\nolympic is a puzzle taken from a Mathematics Olympic game for elementary stu-\\n\\ndents; and sudoku81 is a program for solving a puzzle. The left-to-right labeling\\n\\nstrategy is used to instantiate variables in all the benchmarks. The CPU times were\\n\\nmeasured on a 1.7GHz CPU running Windows XP. Each program was run at least\\n\\n10 times and the average was taken. For some programs, execution was repeated\\n\\nup to 1000 times to obtain a stable average. Garbage collection was disabled. GP\\n\\nhas a native code compiler for Linux. The comparison with GP was also conducted\\n\\non Linux.\\n\\n11 Available from www.probp.com.\\n12 To switch to BP-IC, set the Prolog flag constr consistency to int\\n13 Available from probp.com/bench.tar.gz.\\n\\n\\n\\n20 N.F. Zhou\\n\\nTable 2. Comparison of numbers of backtracks.\\n\\nProgram BP-AC BP-IC GP\\n\\nalpha 4605 8440 8440\\nbridge 0 0 0\\ncars 53 53 34\\ncolor 560 560 560\\neq10 49 49 49\\neq20 49 49 49\\n\\nmagic3 2 2 2\\nmagic4 18 18 18\\nolympic 36 50 50\\n\\nqueens(25) 7255 7255 7255\\nsendmoney 2 2 2\\nsudoku81 0 0 0\\n\\nzebra 2 2 2\\n\\nThe BP solvers compare favorably with GP and are significantly faster than EP\\n\\nand SP. EP is the slowest among the compared solvers, probably because of the\\n\\noverhead of supporting priority-based scheduling (Wallace et al. 2004). BP outper-\\n\\nforms GP remarkably for programs that contain non-binary equality constraints,\\n\\nsuch as eq10, eq20, and sendmoney. This result reveals that the disadvantages of\\n\\nsplitting n-ary constraints into indexicals outweigh the advantages. On the other\\n\\nhand, GP is more than twice as fast as BP for queens(25). The high speed for\\n\\nqueens may be attributed to an optimization technique adopted in GP that com-\\n\\nbines indexicals. If the propagators for the disequality constraints were combined\\n\\nfor the program in BP,14 the speed would be doubled.\\n\\nComparing BP-AC and BP-IC reveals that the hybrid algorithm is effective for\\n\\nalpha and olympic only. The BP-AC solver is adopted as the default one since for\\n\\nsome programs, such as the queens program given in (Puget and Leconte 1995),15\\n\\nBP-AC is exponentially faster than BP-IC. BP-AC is slightly slower than BP-IC for\\n\\nsome of the programs. In general, this happens for programs for which the efforts\\n\\nto reduce domains do not pay off.\\n\\nTable 2 gives the numbers of backtracks performed by the three solvers. BP-AC\\n\\n', 'makes the same number of backtracks as BP-IC except for alpha and olympic, and\\n\\nGP makes fewer backtracks than BP-AC for cars. Basically, the three solvers explore\\n\\nthe same search trees for most of the programs. Therefore, the comparison results\\n\\nshown in Table 1 reflect the real performance of the solvers.\\n\\nGP and BP are quite different. In GP constraints are compiled into indexicals\\n\\n14 For the three disequality constraints X 6= Y , X 6= Y + N , and X 6= Y − N , we can use one\\npropagator rather than three to handle the ins(X) and ins(Y ) events.\\n\\n15 This program is not included in the benchmark set since it requires support of negative integer\\ndomains and thus cannot run on GP.\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 21\\n\\ndefined in C while in BP constraints are compiled into propagators defined in action\\n\\nrules. Although the GP Prolog engine may not have much impact on the perfor-\\n\\nmance of constraint programs, the BP engine does have a great impact since all the\\n\\npropagators are defined in action rules. One evidence for this observation is that the\\n\\nBP constraint solver becomes 20-30 percent faster after the main switch statement\\n\\nin the emulator is changed to a jump table. A further speed-up is expected if a\\n\\nnative code compiler is employed.\\n\\nThere are other factors that affect the performance of a solver, such as domain\\n\\nrepresentation, interaction with other solvers, and garbage collection(Wallace et al. 2004).\\n\\nGP supports only finite domains of positive integers, while BP supports not only\\n\\nfinite integer domains but also trees and finite domains of ground terms and sets\\n\\n(Zhou 2002). In BP, integer domains are represented as described in Subsection 2.3.\\n\\nBP adopts a sound and complete arithmetic that guarantees that solutions found\\n\\nare correct and no solution is lost. When excluding an inner element from a large\\n\\ninterval domain, the system generates a disequality constraint rather than brutally\\n\\nchanges the interval into a bit vector as is done in GP.16 BP has a garbage col-\\n\\nlector that collects garbage on the heap and the control stack, but GP does not\\n\\nsupport garbage collection yet. Garbage collection may suppress some optimization\\n\\ntechniques.\\n\\n6 Related Work\\n\\nCLP(FD) systems have undergone an evolution process, from closed to open and\\n\\nfrom low level to high level. Several constructs have been proposed to facilitate the\\n\\nimplementation of constraint propagators. Examples include attributed variables\\n\\n(Holzbaur 1992), indexicals (Codognet and Diaz 1996), extended indexicals called\\n\\nprojection constraints (Sidebottom and Havens 1996), delay clauses (Meier 1994;\\n\\nZhou 1998), and constraint handling rules (Frühwirth 1998). An action rule is an\\n\\nextension of a delay clause that allows for the descriptions of not only delay condi-\\n\\ntions on subgoals but also activating events and actions. This section compares AR\\n\\nwith these constructs introduced into Constraint Logic Programming. Constructs\\n\\nintroduced into other languages such as ILOG (Puget and Leconte 1995) and Oz\\n\\n(Schulte 2002) are not compared.\\n\\nAR is more powerful and flexible than indexicals. We have described in this\\n\\npaper several propagation algorithms in AR, some of which cannot be encoded\\n\\nin indexicals (e.g., the hybrid algorithm for n-ary constraints) and some of which\\n\\ncannot be implemented as efficiently (e.g., arc consistency for binary constraints).\\n\\nConsider the following indexical taken from (Carlsson et al. 1997),\\n\\nX in dom(Y ) + C\\n\\nwhich maintains arc consistency for the constraint X = Y + C w.r.t. X . Whenever\\n\\nan element y is excluded from the domain of Y , the indexical is activated. Because\\n\\n16 Generating a disequality constraint is less efficient than changing an interval into a bit vector\\nsince the disequality constraint needs to be checked each time the variable is instantiated.\\n\\n\\n\\n22 N.F. Zhou\\n\\nthe indexical does not know what the excluded element is, it has to go through the\\n\\ndomain elements of Y in the worst case to locate a possible no-good value in the\\n\\ndomain of X . In contrast, in the propagator implemented in AR, the propagator\\n\\nknows exactly what element is excluded from the domain of Y and thus can compute\\n\\nthe counterpart in the domain of X in constant time.\\n\\nCompiling constraints into indexicals enables the use of more specialized propaga-\\n\\ntors and restricts propagation to within a small number of constraints (Codognet and Diaz 1996).\\n\\nNevertheless, this approach has to introduce new temporary variables and lower\\n\\nthe granularity of propagators. Our experiment reveals that B-Prolog outperforms\\n\\nGNU-Prolog for almost all the benchmarks that contain non-binary constraints.\\n\\nThis result reveals that the disadvantages of splitting constraints outweigh the ad-\\n\\nvantages. Similar observations have been made independently in (Carlsson et al. 1997;\\n\\nHarvey and Stuckey 2003; Zhou 1998). In (Harvey and Stuckey 2003), the same two-\\n\\n', 'phase algorithm is used to reduce domains of linear constraints.\\n\\nAttributed variables (Holzbaur 1992) are variables with attached attributes each\\n\\nof which has a list of handlers. Touching an attribute triggers the corresponding\\n\\nlist of handlers. In order to make context switching swift for handlers, systems such\\n\\nas ECLiPSe treats handlers as demons rather than as normal subgoals. A demon\\n\\nis different from a normal subgoal in that it does not disappear after execution but\\n\\ninstead waits for another activation. In this sense, agents in our system are similar\\n\\nto demons. Nevertheless, an agent can be activated by different kinds of events and\\n\\nan agent may take different actions depending on the conditions. An agent can\\n\\nbe defined by multiple action rules and the rules are compiled into a tree by the\\n\\ncompiler such that shared tests are combined and conditions that failed once need\\n\\nnot be tested again. SICStus (Carlsson et al. 1997) provides interfaces for imple-\\n\\nmenting propagators and also some sort of delay construct similar to attributed\\n\\nvariables that triggers propagators when events are posted.\\n\\nAR is an extension of our early delay construct proposed in (Zhou 1998) that\\n\\nallows for the event dom(X, E) and user-defined events. The support of the event\\n\\ndom(X, E) is essential for implementing arc consistency algorithms and also prop-\\n\\nagators for set constraints (Zhou 2002). Our delay construct is an extension of\\n\\nMeier’s delay clause construct (Meier 1994) that allows for not only delay condi-\\n\\ntions but also events and actions. In Meier’s delay clause, events are implicitly\\n\\nextracted from delay conditions and a delayed subgoal never takes actions as long\\n\\nas the delay condition is satisfied. In retrospect, all these constructs were inspired\\n\\nby early work by Colmerauer and Naish (Colmerauer 1984; Naish 1985).\\n\\nOther rule-based languages have been designed for implementing constraint prop-\\n\\nagators. CHR resembles a production system. In CHR, the left-hand side of a rule\\n\\nspecifies a pattern of constraints in the constraint store and the right-hand side\\n\\nspecifies new constraints to replace those on the left-hand side or to be added into\\n\\nthe store. It should be possible to implement in CHR all the propagation algorithms\\n\\ndescribed in this paper provided certain built-ins are added. If events are treated as\\n\\nconstraints, then an action rule can be translated into a CHR rule. Treating events\\n\\nas constraints, however, can hardly achieve the same performance. Events are re-\\n\\nmoved automatically after all the agents that are waiting for them are activated.\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 23\\n\\nIn CHR, there must be rules to remove the events explicitly. The left-hand sides\\n\\nof CHR rules can have multiple constraint patterns. Therefore, it is impossible in\\n\\ngeneral to translate a CHR rule into action rules straightforwardly. It is not clear\\n\\nwhether or not it is possible to simulate CHR rules in action rules and how if the\\n\\nanswer is yes. It would be an interesting direction to explore in the future.\\n\\n7 Conclusion\\n\\nThere is a need for an implementation language for constraint propagators that\\n\\nis expressive enough and can be implemented efficiently. This paper has presented\\n\\nsuch a language called AR. The expressiveness of the language is illustrated though\\n\\nseveral examples that cannot be implemented in indexicals: the propagator for\\n\\nmaintaining arc consistency of binary equality constraints; a weak arc-consistency\\n\\npropagator for the all distinct constraint; and a hybrid algorithm for non-binary\\n\\nequality constraints that combines interval and arc consistency ones. The efficiency\\n\\nis evaluated through benchmarking. For a set of widely used benchmarks, our solver\\n\\nimplemented in B-Prolog is significantly faster than that of GNU-Prolog, one of the\\n\\nfastest finite-domain constraint solvers available now.\\n\\nThe results are encouraging and promising since our solver is implemented in\\n\\na high-level language and B-Prolog is an emulator-based system which provides\\n\\nmore facilities than GNU-Prolog such as garbage collection and constraint solving\\n\\nover other domains. The high-performance of our solver stems from the follow-\\n\\ning facts. Firstly, only one propagator is generated for each non-binary equality\\n\\nconstraint that maintains interval consistency. Our solver performs especially well\\n\\nfor the benchmarks that contain non-binary equality constraints. This reveals that\\n\\ncompiling non-binary equality constraints into indexicals has more cons than pros.\\n\\nSecondly, the hybrid algorithm adopted in our solver is a good compromise be-\\n\\ntween the need to achieve high-level consistency to cut search spaces and the need\\n\\nto reduce the cost. The cost of achieving arc consistency for binary constraints\\n\\nis relatively small, but the effect can be very big for certain programs. Thirdly,\\n\\nour solver employs optimization techniques that reduce redundant activations of\\n\\npropagators.\\n\\n', 'Our solver can be improved further in the following aspects: (1) develop new\\n\\noptimization techniques for further avoiding redundant activations of propagators;\\n\\nand (2) implement consistency algorithms beyond interval and arc consistency such\\n\\nas path consistency and Regin’s algorithm for all distinct.\\n\\nAcknowledgement\\n\\nThe author would like to thank Kazunori Ueda and the referees for very detailed\\n\\nand helpful comments on the presentation. This research is supported in part by\\n\\nRF-CUNY and CUNY Software Institute.\\n\\nReferences\\n\\nAggoun, A. and Beldiceanu, N. 1991. Overview of the CHIP compiler system. In\\n\\n\\n\\n24 N.F. Zhou\\n\\nICLP’91: Proceedings 8th International Conference on Logic Programming, K. Fu-\\nrukawa, Ed. MIT Press, 775–789.\\n\\nCarlsson, M., Ottosson, G., and Carlson, B. 1997. An open-ended finite domain\\nconstraint solver. In Proceedings of Programming Language Implementation and Logic\\nProgramming (PLILP). LNCS 1292, Springer-Verlag, 191–205.\\n\\nCodognet, P. and Diaz, D. 1996. Compiling constraints in clp(FD). Journal of Logic\\nProgramming 27, 3, 185–226.\\n\\nColmerauer, A. 1984. Equations and inequations on finite and infinite trees. In Proceed-\\nings of the International Conference on Fifth Generation Computer Systems (FGCS-84).\\nICOT, Tokyo, Japan, 85–99.\\n\\nDechter, R. 2003. Constraint Processing. Morgan Kaufmann Publishers.\\n\\nDiaz, D. and Codognet, P. 2001. Design and implementation of the GNU Prolog\\nsystem. Journal of Functional and Logic Programming 2001(1), 1–29.\\n\\nDincbas, M., Simonis, H., and van Hentenryck, P. 1990. Solving large combinatorial\\nproblems in logic programming. Journal of Logic Programming 8, 75–93. Special Issue:\\nLogic Programming Applications.\\n\\nDincbas, M., van Hentenryck, P., Simonis, H., Aggoun, A., Graf, T., and\\n\\nBerthier, F. 1988. The constraint logic programming language CHIP. In Proceedings\\nof the International Conference on Fifth Generation Computer Systems (FGCS-88).\\nICOT, 693–702.\\n\\nFrühwirth, T. 1998. Theory and practice of constraint handling rules, special issue on\\nconstraint logic programming. Journal of Logic Programming 37, 95–138.\\n\\nHarvey, W. and Stuckey, P. J. 2003. Improving linear constraint propagation by\\nchanging constraint representation. Constraints: An International Journal 8, 2, 173–\\n207.\\n\\nHentenryck, P. V. 1989. Constraint Staisfaction in Logic Programming. MIT Press.\\n\\nHolzbaur, C. 1992. Metastructures vs. attributed variables in the context of extensible\\nunification. In Proceedings of the Fourth International Symposium on Programming\\nLanguage Implementation and Logic Programming, M. Bruynooghe and M. Wirsing,\\nEds. LNCS 631, Springer-Verlag, 260–268.\\n\\nHolzbaur, C., de la Banda, Garcia, M., Stuckey, P. J., and Duck, G. J. 2004.\\nOptimizing compilation of constraint handling rules in HAL. To appear in Theory and\\nPractice of Logic Programming (TPLP).\\n\\nHolzbaur, C. and Fruhwirth, T. 1999. Compiling constraint handling rules into Prolog\\nwith attributed variables. In International Conference on Principles and Practice of\\nDeclarative Programming (PPDP). LNCS 1702, Springer-Verlag, 117–133.\\n\\nJaffar, J. and Maher, M. J. 1994. Constraint logic programming: A survey. Journal\\nof Logic Programming 19/20, 503–582.\\n\\nKumar, V. 1992. Algorithms for constraint satisfaction problems: A survey. AI Maga-\\nzine 13, 32–44.\\n\\nMarriott, K. and Stuckey, P. 1998. Programming with Constraints: An Introduction.\\nMIT Press.\\n\\nMeier, M. 1994. Better late than never. In Implementations of Logic Programming\\nSystems, E. Tick and G. Succi, Eds. Kluwer Academic Publishers.\\n\\nNaish, L. 1985. Negation and control in Prolog. Ph.D. thesis, University of Melbourne.\\n\\nPuget, J. and Leconte, M. 1995. Beyond the glass box: Constraints as objects. In\\nProc. International Logic Programming Symposium. MIT Press, 513–527.\\n\\nPuget, J.-F. 1998. A fast algorithm for the bound consistency of alldiff constraints.\\nIn Proceedings of the National Conference on Artificial Intelligence (AAAI-98). AAAI\\nPress, 359–366.\\n\\n\\n\\nProgramming Finite-Domain Constraint Propagators in Action Rules 25\\n\\nRegin, J. 1994. A filtering algorithm for constraints of difference in CSPs. In Proceedings\\nof the National Conference on Artificial Intelligence(AAAI-94). AAAI Press, 362–367.\\n\\nSchulte, C. 2002. Programming constraint services: high-level programming of standard\\nand new constraint services. Lecture Notes in Computer Science, vol. 2302. Springer-\\nVerlag.\\n\\nShapiro, E. 1989. The family of concurrent logic programming languages. ACM Comput.\\nSurveys 21, 412–510.\\n\\nSidebottom, G. and Havens, W. 1996. Nicolog: A simple yet powerful cc(FD) language.\\nJournal of Automated Reasoning 17, 371–403.\\n\\nTsang, E. 1993. Foundations of Constraint Satisfaction. Academic Press.\\n\\nvan Hentenryck, P., Saraswat, V., and Deville, Y. 1992. Constraint Processing in\\ncc(FD). Technical report, Brown University.\\n\\nWallace, M., Schimpf, J., Shen, K., and Harvey, W. 2004. On benchmarking con-\\nstraint logic programming platforms. Constraints, An International Journal 9, 1, 5–34.\\n\\n', 'Warren, D. H. D. 1983. An abstract Prolog instruction set. Technical report, SRI\\nInternational.\\n\\nZhou, N.-F. 1996a. A novel implementation method of delay. In Proc. Joint International\\nConference and Symposium on Logic Programming. MIT Press, 97–111.\\n\\nZhou, N.-F. 1996b. Parameter passing and control stack management in Prolog imple-\\nmentation revisited. ACM Transactions on Programming Languages and Systems 18, 6,\\n752–779.\\n\\nZhou, N.-F. 1998. A high-level intermediate language and the algorithms for compiling\\nfinite-domain constraints. In Proc. Joint International Conference and Symposium on\\nLogic Programming. MIT Press, 70–84.\\n\\nZhou, N.-F. 2002. Implementing constraint solvers in B-Prolog. In IFIP World Congress,\\nIntelligent Information Processing. Kluwer Academic Publishers, 249–260.\\n\\nZhou, N.-F. 2003. A high-performance abstract machine for Prolog and its extensions.\\nTechnical Report TR-2003014, CUNY Computer Science (www.cs.gc.cuny.edu/tr/).\\n\\n\\n\\tIntroduction\\n\\tPreliminaries\\n\\tCLP(FD)\\n\\tConstraint propagation\\n\\tDomain variables\\n\\n\\tThe AR Language\\n\\tSyntax\\n\\tExamples\\n\\tOperational Semantics\\n\\tThe Implementation\\n\\n\\tProgramming Constraint Propagators in AR\\n\\tBinary constraints\\n\\tNon-binary Constraints\\n\\tPropagators for all_distinct\\n\\n\\tPerformance Evaluation\\n\\tRelated Work\\n\\tConclusion\\n\\tReferences\\n\\n'], 'name': '0506005v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0506/0506005v1.pdf', 'vectorized': None}, {'@search.score': 15.0589905, '@search.rerankerScore': 3.070925235748291, '@search.captions': [{'text': 'CLP(FD) languages have been suc-  cessfully used for solving a variety of industrial and academic problems. However,  in some constraint problems, where domain elements need to be acquired, it may  not be wise to perform the acquisition of the whole domains of variables before the  beginning of the constraint propagation process.', 'highlights': '<em>CLP(FD)</em> languages have been suc-  cessfully used for solving a variety of industrial and academic problems. However,  in some constraint problems, where domain elements need to be acquired, it may  not be wise to perform the acquisition of the whole domains of variables before the  beginning of the constraint propagation process.'}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNDA4LzA0MDgwNTZ2MS5wZGY1', 'title': None, 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n04\\n\\n08\\n05\\n\\n6v\\n1 \\n\\n [\\ncs\\n\\n.L\\nO\\n\\n] \\n 2\\n\\n4 \\nA\\n\\nug\\n 2\\n\\n00\\n4\\n\\nTo appear in Theory and Practice of Logic Programming (TPLP) 1\\n\\nA CHR-based Implementation\\n\\nof Known Arc-Consistency\\n\\nMARCO ALBERTI, MARCO GAVANELLI, EVELINA LAMMA\\n\\nDipartimento di Ingegneria, Università degli Studi di Ferrara\\n\\nPAOLA MELLO, MICHELA MILANO\\n\\nDipartimento di Elettronica, Informatica e Sistemistica, Università degli Studi di Bologna\\n\\nsubmitted 31 August 2002; revised 13 November 2003, 30 June 2004; accepted 9 August 2004\\n\\nAbstract\\n\\nIn classical CLP(FD) systems, domains of variables are completely known at the beginning\\nof the constraint propagation process. However, in systems interacting with an external\\nenvironment, acquiring the whole domains of variables before the beginning of constraint\\npropagation may cause waste of computation time, or even obsolescence of the acquired\\ndata at the time of use.\\n\\nFor such cases, the Interactive Constraint Satisfaction Problem (ICSP) model has been\\nproposed (Cucchiara et al. 1999a) as an extension of the CSP model, to make it possible\\nto start constraint propagation even when domains are not fully known, performing ac-\\nquisition of domain elements only when necessary, and without the need for restarting the\\npropagation after every acquisition.\\n\\nIn this paper, we show how a solver for the two sorted CLP language, defined in previous\\nwork (Gavanelli et al. 2004) to express ICSPs, has been implemented in the Constraint\\nHandling Rules (CHR) language, a declarative language particularly suitable for high level\\nimplementation of constraint solvers.\\n\\n1 Introduction\\n\\nConstraint Logic Programming on Finite Domains (CLP(FD)) represents one of the\\n\\nmost successful implementations of declarative languages. By means of constraints,\\n\\nthe user can give the specifications of a combinatorial problem and possibly solve\\n\\nit, exploiting efficient propagation algorithms. CLP(FD) languages have been suc-\\n\\ncessfully used for solving a variety of industrial and academic problems. However,\\n\\nin some constraint problems, where domain elements need to be acquired, it may\\n\\nnot be wise to perform the acquisition of the whole domains of variables before the\\n\\nbeginning of the constraint propagation process. For instance, in configuration prob-\\n\\nlems (Mailharro 1998; ILOG 1999) domain elements represent components, which\\n\\nhave to be synthesized before being used. The set of components is not known\\n\\nbeforehand, and sometimes even the size of the set cannot be estimated. Often,\\n\\na minimization of the set of components is required, thus the constraint solver\\n\\nproduces a new component only when it is strictly necessary.\\n\\nIn systems that need to interact with an external environment, domain elements\\n\\nhttp://arXiv.org/abs/cs/0408056v1\\n\\n\\n2 M.Alberti et al.\\n\\ncan be produced by an acquisition system that retrieves information about the outer\\n\\nworld. An example is given by Faltings and Macho-Gonzalez (2003) where Internet\\n\\napplications are faced and obviously not all the information can be computed before\\n\\nstarting the constraint satisfaction process. As another example, consider a visual\\n\\nsearch system (Cucchiara et al. 1999b) where domain elements are basic visual fea-\\n\\ntures (like segments, points, or surface patches) extracted from the image. In a\\n\\nclassical CLP(FD) computation, all domain values must be known when defining\\n\\nthe variables, so all the possible visual features would have to be extracted before\\n\\nstarting the visual search process, even if only a small subset of them will be actu-\\n\\nally used. The synthesis of visual features is usually very time consuming, because\\n\\nthe information encoded with signals must be converted into symbolic form. Thus,\\n\\nthe extraction of domain elements that will not be used can result in a significant\\n\\nwaste of computation time. Also, in systems that interact with an evolving environ-\\n\\nment, full acquisition of all the domain elements is not wise (Barruffi et al. 1999). In\\n\\nfact, if all the possible information is acquired beforehand, some of the information\\n\\nmight be obsolete at the end of the acquisition.\\n\\nFor all these reasons, a new model called Interactive Constraint Satisfaction\\n\\nProblem (ICSP) has been proposed (Cucchiara et al. 1999a) as an extension of the\\n\\nwidely used Constraint Satisfaction Problem (CSP) model. In an ICSP, domains\\n\\nconsist of a known part, containing the available elements, plus a variable that\\n\\nsemantically represents a set of values that could be added to the domain in the\\n\\nfuture. In a sense, in an ICSP, domains can be considered as streams of information\\n\\nfrom one system to the constraint solver. Constraint propagation can be performed\\n\\neven when the domains are not completely known, and domain values can be re-\\n\\nquested from an acquisition system during constraint propagation; in other words,\\n\\nconstraint propagation and value acquisition interact (thus Interactive in the name\\n\\n', 'of the framework) and are interleaved, whereas in classical CSP frameworks domain\\n\\nelements are completely known before the beginning of the propagation. In this way,\\n\\nthe acquisition system can possibly extract only elements consistent with the im-\\n\\nposed constraints, thus focusing the attention only on significant data. Various prop-\\n\\nagation algorithms have been proposed (Cucchiara et al. 2001) for exploiting the\\n\\navailable information and acquiring new domain values only when strictly necess-\\n\\nary. Reducing the number of extracted elements can provide a notable speedup\\n\\n(Cucchiara et al. 1999a).\\n\\nIn (Gavanelli et al. 2004) we describe a corresponding CLP language. Our lan-\\n\\nguage is two sorted. The first sort is the classical sort on Finite Domains (FD). The\\n\\nsecond sort, called I-Set, is based on a structure similar to streams, and represents\\n\\ndomains of the FD variables. From the constraints on the FD sort, the system can\\n\\nstart propagation before having full knowledge of domain elements. Each element\\n\\nwill be inserted on demand in the domain, without having to restart constraint\\n\\npropagation from scratch. Moreover, constraints can be imposed on domains, thus\\n\\nhelping the user defining I-Sets1 declaratively. In this paper, we present an imple-\\n\\n1 In this article, the I-Set notation (with calligraphic I) will denote the sort, while the notation\\nI-Set (with non-calligraphic I) will denote a particular I-Set.\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 3\\n\\nmentation of the two-sorted language in Constraint Handling Rules (CHR). CHR\\n\\n(Frühwirth 1998) is a declarative language for defining new constraint solvers at a\\n\\nvery high level. CHR can be used for rapid prototyping, and has proven effective\\n\\nin various real life applications. The purpose of this paper is to show how Con-\\n\\nstraint Handling Rules can be effectively used to implement the solver for our two\\n\\nsorted ICSP-based language. In previous work (Cucchiara et al. 1999a), the propa-\\n\\ngation algorithms have been proposed and separately implemented, but we did not\\n\\ndescribe the full implementation of the solver for ICSP problems. The algorithms\\n\\nwere implemented using non fully declarative constructs (e.g., metaterms with de-\\n\\nstructive assignment). The high level, declarative encoding in CHR consists of a\\n\\nsolver for the I-Set sort, a solver for the FD sort, and an interface between them\\n\\ndesigned to exploit the advantages of the ICSP model in systems interacting with\\n\\nexternal acquisition modules.\\n\\nOf course, other aspects in the model of a problem, besides domain elements,\\n\\ncould be unknown: in a CSP there could be unknown variables or unknown con-\\n\\nstraints. Typically, in all Constraint Programming systems new constraints can be\\n\\neasily added, while removal of constraints is more complex (Dechter and Dechter 1988).\\n\\nThe addition of variables has been taken into account by Dynamic CSP mod-\\n\\nels (Mittal and Falkenhainer 1990). Our work is focussed on unknown domain el-\\n\\nements, and proposes an interaction based on the acquisition, from an external\\n\\nsystem, of domain elements.\\n\\nThe rest of the paper is organized as follows. The declarative and operational\\n\\nsemantics of the language defined by Gavanelli et al. (2004) are briefly recalled\\n\\nin Section 2. In Section 3 we describe the architecture of the language from an\\n\\nimplementation viewpoint, and in Section 4 we show how it is implemented in the\\n\\nCHR language. Discussion of related work (including a detailed comparison with\\n\\n(Mailharro 1998), which is very related to our work from the operational viewpoint)\\n\\nand conclusions follow.\\n\\n2 Syntax and Semantics\\n\\nThe language defined in (Gavanelli et al. 2004) is based on a two sorted CLP, where\\n\\nthe first sort is the classical sort on Finite Domains (FD) and the second is the sort\\n\\non I-Set. I-Sets are used both as domains for FD variables and as communication\\n\\nchannels with an external source providing elements.\\n\\nIn this section, we briefly recall the syntax and semantics of the language.\\n\\nIn the following, we comply to the conventions in (Jaffar et al. 1998). In particu-\\n\\nlar, every constraint domain C (where C can be FD, I-Set, or FD+I-Set) contains:\\n\\nthe constraint domain signature ΣC , the class of constraints LC (a set of first-order\\n\\nΣ-formulas), the domain of computation DC (a Σ-structure that is the intended\\n\\ninterpretation of constraints), the constraint theory TC (a Σ-theory that describes\\n\\nthe logical semantics of the constraints), and the solver solvC .\\n\\n\\n\\n4 M.Alberti et al.\\n\\n2.1 The I-Set sort\\n\\nThe I-Set sort is meant to provide domains for variables in the FD sort. Domains\\n\\nare thus considered as first-class objects, and they can be declaratively defined by\\n\\nmeans of constraints. In a sense, they can be considered as streams, but they are in-\\n\\ntrinsically non-ordered, and do not contain repeated elements. Declaratively, I-Sets\\n\\nare sets; thus unification and constraints should consider I-Set terms modulo the\\n\\n', 'set theory (Dovier et al. 1996): {A|{A|B}} = {A|B}, {A|{B |C}} = {B |{A|C}},\\n\\nwhich states that sets do not contain repeated elements and order is not important.\\n\\nNon-ground elements are forbidden in an I-Set; this restriction can be exploited for\\n\\nmore efficient propagation algorithms. In fact, we represent an I-Set as the union\\n\\nof a set of ground elements (which we name the known part of the I-Set) and a\\n\\nvariable representing its unknown part.\\n\\nIn CLP(I-Set), the constraint domain signature, Σ\\nI-Set, contains the following\\n\\nconstraints:\\n\\n• s-member(E ,S ) ⇔ E ∈ S ,\\n\\n• union(A,B ,C ) ⇔ A ∪ B = C ,\\n\\n• intersection(A,B ,C ) ⇔ A ∩ B = C ,\\n\\n• difference(A,B ,C ) ⇔ A \\\\ B = C ,\\n\\n• inclusion(A,B) ⇔ A ⊆ B ,\\n\\nwhere E represents a ground term, and A, B , and C represent I-Sets.\\n\\nThe operational semantics of the I-Set sort is defined in terms of state of I-Sets,\\n\\nprimitives used to check and modify the state, and events over I-Sets.\\n\\nThe state of an I-Set is defined by its known part, i.e. the set of the elements which\\n\\nare known to belong to the I-Set (as opposed to its unknown part, representing\\n\\nthe elements which have not yet been acquired for the I-Set), and its open-closed\\n\\ncondition, i.e., an I-Set is open if new elements can be inserted into it, closed\\n\\notherwise.\\n\\nA convenient notation to express the state of an I-Set is one based on Prolog-like\\n\\nlists. An I-Set is represented by a structure S defined by S ::= {}, or S ::= {T |S},\\n\\nor S ::= V , where T is a ground term and V is a variable.\\n\\nThe known part of an I-Set is the set of all the ground elements in the list\\n\\nrepresenting it; an I-Set is closed if its continuation (tail) is ground, open otherwise.\\n\\nFor example, I-Set {1, 2, 3, 4|T} is open, and its known part is the set {1, 2, 3, 4};\\n\\nI-Set {1, 2, 3, 4} has the same known part, but it is closed.\\n\\nWe have primitives to modify and check the state of an I-Set. Two primitives are\\n\\nused to modify the state, namely:\\n\\n• ensure member(Element,Iset): enforces Element to be a member of the known\\n\\npart of Iset, possibly adding it if it is not already member, or failing if it is\\n\\nnot already member and the I-Set is closed;\\n\\n• close(Iset): closes Iset; after execution of this primitive, no new elements can\\n\\nbe added to the I-Set.\\n\\nThe following primitives are used to check the state of an I-Set:\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 5\\n\\n• known(Iset,KnownPart): KnownPart is the list of elements in the known part\\n\\nof Iset;\\n\\n• is closed(Iset): checks if the Iset is closed.\\n\\nAn event is a notification of how the status of the computation has been modified,\\n\\nwhich may be relevant for the rest of the computation and is to be processed\\n\\nproperly. The semantics of an event is defined by rules specifying its interactions\\n\\nwith the constraints in the store. It is quite apparent that the concept of event finds\\n\\na natural representation as a CHR constraint; nevertheless, we prefer, in defining the\\n\\noperational semantics of the language, to keep events and proper I-Set constraints\\n\\ndistinct. The concept of event makes it possible to express the semantics of I-Set\\n\\nconstraints with simple (CHR-like) rules. For example, this rule is all that is needed\\n\\nto define the fact that, in the inclusion/2 constraint, all elements in the first I-Set\\n\\nalso appear in the second:\\n\\ninserted(Element , Iset1), inclusion(Iset1, Iset2) =⇒\\n\\nensure member(Element , Iset2)\\n\\nThis rule simply states that, if the inserted(Element,Iset1) event is raised (i.e.,\\n\\nif Element has been inserted into Iset1) and Iset1 is known to be included in\\n\\nIset2, the propagation process must make sure that the element is also present\\n\\nin Iset2. This may imply the insertion of Element into Iset2, with a subsequent\\n\\ninserted(Element,Iset2) event, if Iset2 is open and Element is not already a member,\\n\\nor a failure, if Iset2 is closed and Element is not already a member.\\n\\nPropagation of closure can also be managed with ease. For instance, the rule\\n\\nclosed(Iset2), inclusion(Iset1, Iset2),\\n\\nknown(Iset1,K1), known(Iset2),K2 =⇒\\n\\npermutation(K1,K2)|\\n\\nclose(Iset1)\\n\\n(1)\\n\\nstates that if Iset1 ⊆ Iset2, Iset2 is closed (as indicated by the closed(Iset2) event),\\n\\nand the known elements in Iset1 are all the known elements in Iset2, then also\\n\\nIset1 is closed (by the close(Iset1) primitive).\\n\\n2.2 The FD sort\\n\\nThe FD sort shares the same declarative semantics of the classical FD sort. Thus,\\n\\nthe usual constraints in CLP(FD) are considered (arithmetic, relational constraints\\n\\nplus user-defined constraints). We suppose that the symbols <,≤, +,−,×, . . . be-\\n\\nlong to ΣFD and are interpreted as usual.\\n\\nSince we want cope with incompletely specified variable domains avoiding use-\\n\\nless value acquisition, we use a constraint propagation based on the available\\n\\nknowledge, when domains are still partially specified. For this reason, we proposed\\n\\n(Gavanelli et al. 2004) an extension, for the partially known case, of the concept\\n\\nof consistency, called known consistency. ', 'In this paper, we provide only the defini-\\n\\ntion of node and arc-consistency; the extension to higher degrees of consistency is\\n\\nstraightforward.\\n\\n\\n\\n6 M.Alberti et al.\\n\\nDefinition 2.1\\n\\nA unary constraint c(Xi) is known node-consistent iff\\n\\n∀vi ∈ K c\\ni , vi ∈ c(Xi),\\n\\nwhere K c\\ni is the known part of the domain of Xi . A binary constraint c(Xi ,Xj ) is\\n\\nknown arc-consistent iff\\n\\n∀vi ∈ K c\\ni , ∃vj ∈ K c\\n\\nj s.t. (vi , vj ) ∈ c(Xi ,Xj ),\\n\\nwhere K c\\ni and K c\\n\\nj are the known parts of the domains of Xi and Xj , respectively.\\n\\nA constraint network is known arc-consistent (KAC) iff all unary constraints are\\n\\nknown node-consistent and all binary constraints are known arc-consistent.\\n\\nThe following proposition shows the link between known arc-consistency and arc-\\n\\nconsistency (Mackworth 1977). The proof can be found in (Gavanelli et al. 2004).\\n\\nProposition 1\\n\\nEvery algorithm achieving KAC (i.e. any algorithm that computes an equivalent\\n\\nproblem that is KAC) and that ensures at least a known element in each vari-\\n\\nable domain is able to detect inconsistency in the same instances as an algorithm\\n\\nachieving AC.\\n\\nIn other words, if there exists an arc-consistent sub-domain, then there exists a\\n\\nmaximal arc-consistent sub-domain; so if KAC does not detect inconsistency, AC\\n\\nwill not detect inconsistency either.\\n\\nKAC is equivalent to AC when domains are completely known. The advantage\\n\\nin using KAC is that the check for known arc-consistency can be performed lazily,\\n\\nwithout full knowledge of all the elements in every domain.\\n\\n2.3 Linking the two sorts\\n\\nIntuitively, we want to bind CLP(FD) with CLP(I-Set) with the intended semantics\\n\\nthat I-Sets provide domains for FD variables.\\n\\nGiven the two CLP languages LFD and L\\nI-Set, we define the CLP language L\\n\\nas the union of the two languages, with a further constraint, :: , defined as follows:\\n\\n• the signature Σ = ΣFD ∪ ΣI-Set ∪ { :: };\\n• the intended interpretation D keeps the original mappings in the FD and\\n\\nI-Set sorts; i.e., D|ΣF D\\n= DFD and D|ΣI-Set\\n\\n= DI-Set.\\n\\nThe declarative semantics of the constraint is\\n\\nX :: S ↔ X ∈ S\\n\\nwhere X is a FD variable. The :: /2 constraint links a FD variable to its domain\\n\\nas in most CLP(FD) frameworks, with the difference that S , being and I-Set,\\n\\nmay be non-completely specified. The :: /2 constraint should not be confused with\\n\\nthe s-member/2 constraint of Section 2.1, which represents the constraint of set\\n\\nmembership between a ground element and an I-Set.\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 7\\n\\nFig. 1. FD Constraints as filters on variable domains\\n\\nIn CLP(FD) systems, domains provide ancillary information about variables. Do-\\n\\nmains contain the possible values that a variable can take; if a value is not consistent\\n\\nwith the imposed constraints, it is operationally removed from the domain. This\\n\\nhelps many systems (Dincbas et al. 1988; Puget 1994; IC-Parc 2001; SICStus 2003)\\n\\nto obtain higher performance; in fact, domain wipe-outs are detected early and\\n\\nmany alternatives are efficiently pruned. On the other hand, in the I-Set sort, do-\\n\\nmains must be manipulated as logical entities: if an element declaratively belongs\\n\\nto a domain, it cannot be removed.\\n\\nSuppose that we have constraint {1, 2, 3} ⊆ D stating that the elements 1, 2 and\\n\\n3 should belong to the set D , the constraint X :: D that links variable X to the\\n\\ndomain D, and X 6= 1 that states that X should be different from 1. Usual constraint\\n\\npropagation of the constraint X 6= 1 would remove element 1 from the domain D ,\\n\\nbut this is inconsistent with the constraint {1, 2, 3} ⊆ D so the computation would\\n\\nfail. This behavior is not correct, because the set of constraints {1, 2, 3} ⊆ D ,\\n\\nX ∈ D , and X 6= 1 is satisfiable.\\n\\nFor this reason, in our framework, the domain of a variable X is represented\\n\\nby two streams: a Definition Domain, Dd\\nX , that contains all the values synthesized\\n\\nfor the variable, and a stream of Removed Values, Dr\\nX , that is the set of elements\\n\\nproven to be inconsistent with the imposed constraints. The set of available items\\n\\nfor X , also called Current Domain, Dc\\nX , is given by the relation:\\n\\nDc\\nX = Dd\\n\\nX \\\\ Dr\\nX · (2)\\n\\nIt should be noticed that Dc\\nX remains open until Dd\\n\\nX is closed. Dr\\nX , instead, is always\\n\\nopen, so to make it possible to move elements into it from the current domain even\\n\\nif the definition domain has been closed.\\n\\nWith the imposed constraints, it is possible to declaratively add a newly synthe-\\n\\nsized value to the definition domain (imposing the constraint v ∈ Dd\\nX ) or remove an\\n\\ninconsistent element from the current domain (w /∈ Dc\\nX or, equivalently, w ∈ Dr\\n\\nX ;\\n\\nsee Fig. 1). In this way, during search, an inconsistent element will not be tried if it\\n\\nbelongs to Dr\\nX and a possible domain wipe-out will be detected when Dc\\n\\nX is empty.\\n\\n\\n\\n8 M.Alberti et al.\\n\\nNote that the relation in Eq. (2) automatically propagates two types of informa-\\n\\ntion from the definition domain to the current domain of a variable. ', 'First, whenever\\n\\na domain element is synthesized, it is considered in the current domain and can be\\n\\nexploited for propagation. Second, if no more values are available to the definition\\n\\ndomain, also the current domain becomes closed.\\n\\nNotice that more than one FD variable can range on the same definition domain\\n\\nor, equivalently, their definition domains can be linked by an equality constraint;\\n\\nhowever, each of them will have its own current domain and set of removed values.\\n\\nBy definition, the user cannot close the current domain of a variable: the user should\\n\\nonly access the definition domain directly. This is not a restriction, because if one\\n\\nwants to close independently the current domain of different variables (as in the\\n\\nprevious example), he can define two different definition domains (and, possibly,\\n\\nimpose some constraints among them, e.g., Dd\\nX ⊆ Dd\\n\\nY ).\\n\\nIn order to achieve KAC, it is necessary to remove elements and to promote\\n\\nelements, i.e., to move ideally some elements from the unknown part to the known\\n\\npart. Elements can then be removed (i.e., prevented from entering the current\\n\\ndomain) if they are shown to be inconsistent. An algorithm for achieving KAC is\\n\\nshown in (Gavanelli et al. 2004).\\n\\nThe addition, besides the deletion, of elements to the domain might seem non\\n\\nmonotonic. However, the current domain is kept open as long as new acquisitions are\\n\\npossible (i.e., until the definition domain is closed), the unknown part representing\\n\\nthe set of future acquisitions. Thus, declaratively, when a new element enters the\\n\\nknown part of the current domain, it is not properly added: it is just made explicit.\\n\\nA similar behavior is also achieved by Mailharro (1998) with the use of a wildcard\\n\\nrepresenting values entering the domain.\\n\\nClearly, the repeated acquisition of the same element would result in a loop;\\n\\nthis can be avoided by having an acquisition module that does not provide twice\\n\\nthe same element to the same I-Set (as hypothesized, for instance, by Mailharro\\n\\n(1998)).\\n\\nExample: Numeric CSP. Various applications could be thought exploiting inter-\\n\\nactive constraint propagation, as many systems need to interact with an exter-\\n\\nnal environment during propagation: some real-world examples can be found in\\n\\n(Gavanelli et al. 2004). In this section, we give a simple example, aimed at showing\\n\\na typical ICSP computation, rather than at showing the power of the language.\\n\\nWith the given language, we can state in a natural way the following problem:\\n\\n:-X :: DX ,Y :: DY ,Z :: DZ , intersection(DX ,DY ,DZ ),Z > X ·\\n\\ndefining three variables, X , Y , and Z , with constraints on them and their domains.\\n\\nKAC propagation can start even with domains fully unknown, i.e., when DX , DY\\n\\nand DZ are variables. Let us suppose that the elements are acquired through in-\\n\\nteraction with a user and the first element retrieved for X is 1. This element is\\n\\ninserted in the definition domain of X , i.e., Dd\\nX = {1|(Dd\\n\\nX )′}; since it is consistent\\n\\nwith FD constraints, it is not redirected to the Dr\\nX stream; value 1 is considered\\n\\nin the current domain, i.e., Dc\\nX = {1|(Dc\\n\\nX )′}. Then KAC propagation tries to find\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 9\\n\\na support for this element in each domain of those variables linked by FD con-\\n\\nstraints; in our instance DZ . A value is requested for DZ and the user gives a\\n\\n(possibly consistent) value: 2. This element is inserted into the definition domain of\\n\\nZ : Dd\\nZ = {2|(Dd\\n\\nZ )′}. The constraint imposed on domains can propagate, so element\\n\\n2 has to be inserted in the definition domain of Y and X , thus Dc\\nY = Dd\\n\\nY = {2|D ′\\nY }\\n\\nand Dc\\nX = Dd\\n\\nX = {1, 2|D ′′\\n\\nX}.\\n\\nSince the acquired element is consistent with FD constraints involving Z , it enters\\n\\nthe current domain of Z . KAC propagation must now find a known support for\\n\\nelement 2 for X , so another request is performed. If the user replies that there is\\n\\nno other element in the domain of Z, then 2 is sent to the stream of removed values\\n\\nfor X (thus, it is not considered in the current domain of X ). It will remain in the\\n\\ndefinition domain because the element semantically belongs to the domain even if\\n\\nno consistent solution can exist containing it.\\n\\nWhen KAC propagation reaches the quiescence, each element of the current do-\\n\\nmain of each variable has a support for each FD constraint involving that variable.\\n\\n3 Implementation concepts\\n\\nSince one of the aims of the ICSP model is to manage efficiently those problems\\n\\nin which value acquisition is costly, it is useful to exploit the link between the two\\n\\nsorts to avoid unnecessary acquisition of domain elements. For instance, as shown\\n\\nin the example in Section 2.3, it is possible to infer the presence of a value in the\\n\\nknown part of an I-Set from I-Set constraints, without acquiring it directly.\\n\\nThus, for the sake of efficiency, the implementation of the language must be aware\\n\\n', 'of the link between the two sorts, given by the :: /2 constraint (see Section 2.3),\\n\\nand exploit it when useful. Nonetheless, the two sorts are clearly distinct, and need\\n\\nto be handled by different computational mechanisms.\\n\\nIn more detail, it is possible to devise two constraint solvers: one for the FD sort,\\n\\nmeant to ensure KAC (see Def. 2.1) of the FD constraint network, and one for the\\n\\nI-Set sort, meant to ensure satisfaction of I-Set constraints.\\n\\nThese solvers only need to interact in two cases:\\n\\n• when, during FD KAC check, a new element is acquired, I-Set propagation\\n\\nmust be activated in order to satisfy I-Set constraints;\\n\\n• conversely, when a new element enters the known part of an I-Set, FD KAC\\n\\ncheck must be activated over all the FD variables which have their definition\\n\\ndomain in the I-Set.\\n\\nThe CHR language is a perfectly suitable tool for this purpose, letting us deal with\\n\\nthe two sorts separately, and to manage the link between them with ease.\\n\\n3.1 FD sort concepts\\n\\nThe aim of the FD solver is to keep the constraint network known arc-consistent.\\n\\nThis is achieved by preventing elements from entering current domains if no KAC\\n\\nsupport is found for the constraints involving them. In more detail, each time a new\\n\\n\\n\\n10 M.Alberti et al.\\n\\nFig. 2. State transitions for (Variable,Element) pairs\\n\\nelement E is promoted from the unknown to the known part of an I-Set C , it is\\n\\ninserted into the definition domain of each variable V such that V :: C (E ∈ Dd\\nV\\n\\nwith the notation of Sect. 2.3). The algorithm then tries to find a KAC support\\n\\nfor E : if support is found, then E is also inserted into the Current Domain of V\\n\\n(E ∈ Dc\\nV ); otherwise, although it stays in the definition domain of V , it enters the\\n\\nstream of Removed Values for V (E ∈ Dr\\nV ).\\n\\nIn this way, at any step of the propagation, all of the values in current domains\\n\\nare certainly supported.\\n\\n3.1.1 Values’ states\\n\\nThe process described above can be clearly formalized as a sequence of state tran-\\n\\nsitions for (V ,E ) pairs. These states are:\\n\\n• unknown: E has not yet been acquired as a value for V ;\\n\\n• candidate: E has been inserted into Dd\\nV , but (V ,E ) has not yet been chosen\\n\\nfor supporting another value and no KAC control is being run on it;\\n\\n• observed: (V ,E ) provides support for some other observed pair, but it has not\\n\\nyet been proven to be supported;\\n\\n• present: (V ,E ) is supported, and has thus been inserted into Dc\\nV ;\\n\\n• removed: E is not supported, and has thus been inserted into Dr\\nV .\\n\\nThe possible state transitions are shown in Figure 2.\\n\\n3.1.2 Lazy value acquisition\\n\\nThe ICSP framework is more suitable for those applications in which the process\\n\\nof acquiring domain values is computationally costly. In this perspective, the KAC\\n\\ncheck procedure has been designed so as to acquire new values only when it is\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 11\\n\\nreally necessary, i.e., when no support for a value can be found among already\\n\\nknown values.\\n\\n3.2 I-Set sort concepts\\n\\nThe task performed by the I-Set solver is to ensure the satisfaction of the I-Set\\n\\nsort constraints, and to propagate the closure of definition domains, when possible.\\n\\nAs shown in the example below, it is possible to infer that an element belongs\\n\\nto an I-Set from I-Set sort constraints, thus reducing the number of necessary\\n\\nacquisitions and improving efficiency.\\n\\nIn particular, each time an element is added to an I-Set, an inserted/2 event\\n\\n(see Section 2.1) is raised, which starts a check for the satisfaction of the I-Set\\n\\nconstraints involving the I-Set itself.\\n\\nExample Let us suppose the constraint intersection(DX ,DY ,DZ ) is given among\\n\\nthe DX , DY and DZ I-Sets, and that the current values of the domains are\\n\\nDX = {2, 4|D ′\\nX}; DY = {3, 4|D ′\\n\\nY }; DZ = {4|D ′\\nZ}.\\n\\nIf 5 is added to DZ , the system immediately ensures 5 to be a member of both\\n\\nDX and DY , without the need for acquiring the element. If 3 is added to DZ , the\\n\\nsystem only needs to add it to DX . Conversely, if 3 is added to DX , it is also added\\n\\nto DZ ; if 1 is added to DX , instead, the system cannot infer anything, and thus\\n\\nmakes no additions.\\n\\nI-Set constraints also have to be taken into account to propagate closure of I-Sets,\\n\\nwhen possible (as in the example shown in Sect. 2.1). For this purpose, we use a\\n\\nclosed/1 event, which notifies that an I-Set has been closed.\\n\\n3.3 Interaction between sorts\\n\\nThe link between the two sorts, represented by the :: /2 constraint (see Section\\n\\n2.3), is implemented as an interaction mechanism between the solvers activated\\n\\nwhen, on the one hand, a new element is acquired during a KAC check and, on the\\n\\nother hand, an element is inserted into an I-Set.\\n\\nSemantically, we use the inserted/2 event for both of these cases (see Section 2.1).\\n\\nAt the implementation level, the event causes the control to pass from one solver\\n\\nto another.\\n\\n3.4 Algorithms\\n\\n3.4.1 Priority among supporting values\\n\\n', 'A (Variable,Element) pair is supported if, for each constraint involving Variable,\\n\\nsupport is found in the known part of other variables’ domains. But supporting\\n\\npairs may not be supported in their turn: this implies that, if a pair is found to\\n\\nbe unsupported, new support needs to be found for all of the pairs that it was\\n\\nsupporting. For efficiency, we keep track of which pairs support which other pairs\\n\\n\\n\\n12 M.Alberti et al.\\n\\nfor which constraints, so that, in case a pair is found unsupported, it is possible to\\n\\nrevise only the affected constraints.\\n\\nHowever, because of states (see Sect. 3.1.1), it is possible to reduce the number of\\n\\nsupports to keep track of. If an element is supported by an element whose state is\\n\\npresent, there is no need for keeping track of the support, because a present element\\n\\nis already known to be supported, as explained in Sect. 3.1.1. Thus, when seeking\\n\\nsupport for a constraint, present elements should be tried first.\\n\\nLikewise, an element whose state is observed is more convenient than an element\\n\\nwhose state is candidate, because the algorithm is already seeking support for it,\\n\\nand can thus avoid seeking support for a new element (note that all candidates will\\n\\neventually be checked; but in this way, when their turn comes, there will be, in\\n\\ngeneral, more present elements).\\n\\nSo, a priority can be established among eligible supporting elements: first present,\\n\\nthen observed, then candidates. Only when no support is found among these ele-\\n\\nments, a new element needs to be acquired: if the definition domain of the corre-\\n\\nsponding variable is open, an element can be requested, otherwise the support seek\\n\\nprocedure fails.\\n\\n3.4.2 The support graph\\n\\nSupport dependencies can be represented by a (directed) support graph, in which\\n\\nnodes represent observed (Variable,Element) pairs, and arcs represent support de-\\n\\npendencies.\\n\\nWhen a candidate pair becomes observed, the corresponding node is added to the\\n\\ngraph. This may happen at the beginning of graph construction, when the graph is\\n\\nempty and the candidate is chosen to be the first node, or later, during the support\\n\\nseeking procedure, if the candidate provides support for an observed.\\n\\nA new node needs support for the FD constraints involving it. For each FD\\n\\nconstraint, the following attempts, in this order (see Sect. 3.4.1) are made, until\\n\\none succeeds:\\n\\n1. support is found in present elements only: the graph needs no modifications;\\n\\n2. one of the supporting elements is observed: an arc is added from the support-\\n\\ning node to the supported, marked with the constraint;\\n\\n3. one of the supporting elements is candidate: a new node is added for the\\n\\ncandidate, an arc is added from the supporting node to the supported, marked\\n\\nwith the constraint.\\n\\nIf none of these attempts succeeds, a variable (other than Variable) is chosen for\\n\\nacquisition among those involved by the constraint, and the search for support is\\n\\nrestarted from the support-in-candidates attempt (step 3). The search for support\\n\\nneeds to be restarted because, in order to satisfy I-Set constraints, new candidates\\n\\nmay have been added, which may provide support for the considered FD constraint.\\n\\nA node is deleted from the graph if it is found to have no support; in this case,\\n\\nnew support is sought for all of the nodes that it was supporting.\\n\\nOnce a graph is fully built, all of its nodes can be inserted into the current\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 13\\n\\ndomains (observed-to-present transition), whereas the unsupported nodes will be\\n\\ninserted into the stream of removed values.\\n\\nThe procedure reaches quiescence only when there are no more candidates to\\n\\nsearch support for.\\n\\n4 CHR implementation\\n\\nIn this section, we show how the concepts explained in Section 3 have been im-\\n\\nplemented in a constraint solver using the Constraint Handling Rules library of\\n\\nSICStus Prolog.\\n\\n4.1 I-Set variables and constraints\\n\\nI-Sets are represented by CHR variables: these variables (also “link variables” here-\\n\\nafter) act as a link for the information stored in constraints, and are never instan-\\n\\ntiated. To keep memory of the state of I-Sets we use CHR constraints, meant to\\n\\ninteract in order to ensure satisfaction of I-Set constraints.\\n\\nThe state of an I-Set is represented by means of three CHR constraints:\\n\\niset known(Iset,Known) links an I-Set to its known part, iset open(Iset) indicates\\n\\nthat the I-Set is open (i.e., other elements can be inserted), and closed(Iset) indi-\\n\\ncates that the I-Set is closed.\\n\\nAn I-Set is created by the user either explicitly (new iset object/3 predicate)\\n\\nor implicitly, imposing constraint icsp def domain/2 (which implements the :: /2\\n\\nconstraint of Sect. 2.3) between an FD variable and the link variable of an I-Set. It\\n\\nis possible to define the domain as empty or as having a starting known part.\\n\\nEach constraint among I-Sets (see Section 2.1 for the formal definitions) is\\n\\n', 'represented by a corresponding CHR constraint among the link variables of the\\n\\nI-Sets that it involves, namely the iset member/2 (in this case, the first argu-\\n\\nment is a ground FD value), iset union/3, iset intersection/3, iset inclusion/2, and\\n\\niset difference/3 constraints.\\n\\nThe satisfaction of I-Set constraints is ensured incrementally (see Section 3.2).\\n\\nFor instance, the following rule is used for implementing the iset intersection/3\\n\\nconstraint.\\n\\nintersection_right_to_left @\\n\\niset_inserted(Iset3,Element),\\n\\niset_intersection(Iset1,Iset2,Iset3)\\n\\n# _iset_intersection\\n\\n==> ensure_membership(Iset1,Element),\\n\\nensure_membership(Iset2,Element)\\n\\npragma passive(_iset_intersection).\\n\\nThe rule is activated when a new element is added to the I-Set represented\\n\\nby the third argument of an iset intersection/3 constraint: this is notified by the\\n\\niset inserted/2 constraint, which implements the inserted event of Sect. 2.1. The\\n\\nrule imposes constraint ensure membership/2 on each of the other two I-Sets and\\n\\n\\n\\n14 M.Alberti et al.\\n\\nthe element; if necessary, the element will be inserted into the I-Sets. Notice that\\n\\nensure membership/2 is defined so as to fail if the I-Set is closed and the element\\n\\nis not already in its known part. Constraint iset intersection/3 is declared passive\\n\\nfor efficiency, because it is not necessary to generate code for it (I-Set constraints\\n\\nas iset intersection/3 are imposed only at the beginning of the computation).\\n\\nTwo more rules (not shown here for lack of space) manage the case of an element\\n\\nhaving been inserted into the first or second argument of the iset intersection/3\\n\\nconstraint.\\n\\nThe close/1 primitive of Sect. 2.1 is implemented by the following CHR:\\n\\nclose_iset @\\n\\nclose(Iset), iset_open(Iset) # _iset_open\\n\\n<=> closed(Iset)\\n\\npragma passive(_iset_open).\\n\\nCHR constraint close/1 is imposed to close the I-Set; the effect of this rule is to\\n\\nremove constraint iset open/1 for the I-Set, and to impose CHR constraint closed/1\\n\\nfor the I-Set. Constraint closed/1 also implements the event notifying that the\\n\\nargument I-Set has been closed, which can interact with I-Set constraints so as to\\n\\npropagate closure when possible. For instance, the rule of Sect. 2.1 is implemented\\n\\nas follows:\\n\\nclosure_propagation_inclusion @\\n\\nclosed(Iset2),\\n\\niset_inclusion(Iset1,Iset2) # _iset_inclusion,\\n\\niset_known(Iset1,K1) # _iset_known1,\\n\\niset_known(Iset2,K2) # _iset_known2,\\n\\n==> permutation(K1,K2) |\\n\\nclose(Iset1) pragma passive(_iset_inclusion),\\n\\npassive(_iset_known1), passive(_iset_known2).\\n\\nPredicate permutation/2 in the guard checks that the two I-Sets have the same\\n\\nelements.\\n\\n4.2 FD variables and constraints\\n\\n4.2.1 FD variables and domains\\n\\nFD variables are represented as CHR constrained variables. Their do-\\n\\nmain is an I-Set; constraint :: /2 (see Section 2.3) is implemented as\\n\\nthe icsp def domain(Variable,Iset) CHR constraint, whereas the current do-\\n\\nmain of the variable and its set of removed values are represented by the\\n\\nicsp curr domain(Variable,(Present,Removed)) CHR constraint, where Present is\\n\\nthe list of present elements and Removed is the list of removed elements.\\n\\n4.2.2 FD constraints\\n\\nFD constraints are represented by the fd constraint(ConstraintName, ListOfArgu-\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 15\\n\\nments) CHR constraint. For instance, FD constraint X < Z is represented by the\\n\\nfd constraint(lt,[X,Z]) CHR constraint.\\n\\nFD constraints are defined by the user simply as one or more clauses for the\\n\\nProlog predicate fd verify/2 needed to verify whether the constraint is satisfied by\\n\\na list of ground arguments. This way of defining FD constraints supports non-binary\\n\\nconstraints, and easy extensibility of the system.\\n\\nFor instance, a possible definition of the FD </2 constraint could be\\n\\nfd_verify(lt,[A,B]):- A<B.\\n\\n4.2.3 KAC procedure\\n\\nCandidate (see Section 3.1.1) elements for each variable are stored in the cur-\\n\\nrent candidates(Variable,ListOfElements) constraint.\\n\\nKAC check over candidates is performed by building a support graph (see Section\\n\\n3.4.2). Nodes of the graph are (Variable, Element) pairs. A pair is a node of the\\n\\ngraph if and only if it is member of the list argument of the observed candidates/1\\n\\nCHR constraint; an arc (indicating support dependency) is represented by the relies\\n\\n((Var1,Val1), (Var2,Val2), FDConstraint) CHR constraint, where FDConstraint is\\n\\nthe FD constraint for which (Var2,Val2) supports (Var1,Val1).\\n\\nGraph construction is achieved by the following CHR rule:\\n\\nkac_check_start @\\n\\nkac_unlock,\\n\\ncurrent_candidates(Var,[Candidate|MoreCandidates])\\n\\n# _current_candidates\\n\\n<=> current_candidates(Var,MoreCandidates),\\n\\nobserved_candidate((Var,Candidate)),\\n\\ncheck_candidate((Var,Candidate)),\\n\\n!, flush_candidates, end_flush_candidates,\\n\\nkac_unlock pragma passive(_current_candidates).\\n\\nGraph construction begins when there is at least one non-empty list of candidates\\n\\n', 'for a variable: an element is chosen (in the current implementation, it is simply\\n\\nthe first of the list), pair (Variable, Element) becomes the first node of the graph\\n\\n(constraint observed candidate/1 adds its argument to the list argument of con-\\n\\nstraint observed candidates/1), and KAC check starts from it (check candidate/2\\n\\nconstraint); during check, new nodes may be added to the graph, which will be\\n\\nchecked for support in their turn. When the construction is done, graph nodes are\\n\\ninserted into the current domains (flush candidates/0 and end flush candidates/0\\n\\nconstraints), and the procedure can start again over the rest of candidates.\\n\\nkac unlock/0 is a constraint meant simply to start the KAC procedure. If there\\n\\nare no candidates when it is imposed, then if there is a variable with empty current\\n\\ndomain an element is acquired for it which will become a candidate; otherwise, the\\n\\nprocedure reaches quiescence.\\n\\n\\n\\n16 M.Alberti et al.\\n\\n4.2.4 Support seek\\n\\nSupport seek for a (Variable, Element) pair is started by constraint\\n\\ncheck candidate((Variable,Element)). This constraint collects from the store all the\\n\\nFD constraints that involve Variable, and for each of them tries to find an assign-\\n\\nment of all the involved variables that satisfies it (i.e., that makes goal fd verify/2\\n\\n(see Section 4.2.2) succeed). Elements for the other variables are chosen following\\n\\nthe priority described in Section 3.4.1.\\n\\n4.2.5 Support seek through element acquisition\\n\\nIf no acceptable assignment is found among known, observed, and candidate ele-\\n\\nments, then:\\n\\n• if the I-Set domain of at least one of the other variables is open, a new element\\n\\nis acquired for one of the other variables;\\n\\n• if the I-Set domains of all the other variables are closed, failure is reported,\\n\\nand possibly backtracking is applied.\\n\\nWhich variable should be chosen for acquisition among those with open domain is\\n\\nnot obvious for non-binary constraints, and application specific heuristics could be\\n\\nuseful; in this implementation the first variable is simply chosen.\\n\\nIn the current system, element acquisition is obtained by asking the user for\\n\\nan element, and the I-Set is closed in case of a predefined input from the user.\\n\\nObviously, in practical applications, elements would be provided by an acquisition\\n\\nsystem, as in (Mailharro 1998), where the acquisition is done automatically by gen-\\n\\neration of new component instances, or in (Cucchiara et al. 1999b), where elements\\n\\nare provided by a low-level segmentation system.\\n\\n4.3 Constraints and rules for interaction between sorts\\n\\nOnly one CHR constraint needs to be added to the solver to link the two sorts:\\n\\niset inserted(Iset,Element), imposed when Element is inserted into the known part\\n\\nof Iset. This constraint is the implementation of the inserted/2 event described in\\n\\nSection 2.1.\\n\\n4.3.1 FD to I-Set link\\n\\nWhen a new element Element is acquired for a variable V whose definition domain\\n\\nis Iset, iset inserted(Iset,Element) is imposed. This CHR constraint implements an\\n\\nevent that triggers the I-Set constraint check. From a procedural point of view,\\n\\nthis makes control pass from the FD solver to the I-Set solver.\\n\\n4.3.2 I-Set to FD link\\n\\nWhen imposed, iset inserted(Iset,Element):\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 17\\n\\n• first, interacts with the I-Set constraints involving Iset, as shown in Sec-\\n\\ntion 4.1;\\n\\n• then, inserts Element in the list of candidates of all the variables having Iset\\n\\nas definition domain, for later support seek.\\n\\nThe interaction with the I-Set constraints may involve new insertions, which will,\\n\\nin their turn, impose further iset inserted/2 constraints.\\n\\nNew candidates are added only when I-Set propagation has been completed, for\\n\\nthe reasons explained in Section 3.2.\\n\\n5 Related work\\n\\nI-Sets can be considered as streams with a set semantics (i.e., in an I-Set there are\\n\\nno repeated elements and elements are not sorted). Streams are widely used for\\n\\ncommunication purposes in concurrent logic programming (Shapiro 1987). Various\\n\\ncommunication protocols can be implemented using this simple yet powerful data\\n\\nstructure (Shapiro 1989). An I-Set can only contain ground elements; this restric-\\n\\ntion prevents (open) I-Sets from being passed in an I-Set, but lets us achieve higher\\n\\nefficiency.\\n\\nThe first results of our research in the ICSP framework are reported by Cucchiara\\n\\net al. (1999a), where the ICSP model is proposed as an extension of the CSP model.\\n\\nIn this model, variables range on partially known domains which have a known part\\n\\nand an unknown part represented as a variable. Domain values are provided by an\\n\\nextraction module and the acquisition process is (possibly) driven by constraints.\\n\\nThe model has been proven effective in a vision system (Cucchiara et al. 1999b), in\\n\\nrandomly-generated problems (Cucchiara et al. 1999a), and in planning (Barruffi et al. 1999).\\n\\nThis work can be considered as the language extension and CHR implementation\\n\\n', 'of the ICSP framework, maintaining it as the core of the propagation engine on the\\n\\nFD side.\\n\\nOperationally, achieving KAC has some similarities with achieving Lazy Arc\\n\\nConsistency (LAC) (Schiex et al. 1996). LAC is an algorithm that finds an arc-\\n\\nconsistent sub-domain (not necessarily a maximal one) and tries to avoid the check\\n\\nfor consistency of all the elements in every domain. KAC looks for an arc-consistent\\n\\nsub-domain as well, but it is aimed at avoiding unnecessary information retrieval,\\n\\nrather than unnecessary constraint checks.\\n\\nCodognet and Diaz (1996) describe a method for compiling constraints in\\n\\nCLP(FD). There is only one primitive constraint (X in R), used to implement\\n\\nall the other constraints. R represents a collection of objects and can also be a\\n\\nuser function. Thus, in CLP(FD) domains are managed as first-class objects; our\\n\\nframework can be fruitfully implemented in systems exploiting this idea.\\n\\nSergot (1983) proposes a framework to deal with interaction with the user in a\\n\\nlogic programming environment. Our work can be used for interaction in a CLP\\n\\nframework; it lets the user interactively provide domain values.\\n\\nZweben and Eskey (1989) propose an algorithm that evaluates domain elements\\n\\nonly when necessary; domains are streams and constraints are filters on domains.\\n\\n\\n\\n18 M.Alberti et al.\\n\\nDent and Mercer (1994) show the effectiveness of such an approach when constraint\\n\\nchecks are expensive operations. In our proposal, implementation of delayed eval-\\n\\nuation is quite natural and simple, even if our work is aimed at reducing domain\\n\\nvalues extractions, not constraint checks.\\n\\nDynamic Constraint Satisfaction (DCS) (Dechter and Dechter 1988) is a promis-\\n\\ning field of AI taking into account dynamic changes of the constraint store such as\\n\\nthe addition and deletion of values and constraints. The difference between DCS\\n\\nand our approach concerns the way of handling these changes. DCS approaches\\n\\npropagate constraints as if they worked in a closed world. Basically, in a DCS one\\n\\ncan add or remove a constraint; thus, one can also add and delete domain elements\\n\\nprovided that they are all known from the beginning. In an ICSP, instead, domain\\n\\nelements that are unknown can be requested and inserted in the domain. DCS\\n\\nsolvers record dependencies between constraints and the corresponding propagation\\n\\nin proper data structures (Schiex and Verfaillie 1993) so as to tackle modifications\\n\\nof the constraint store as soon as data change. In this perspective, we also cope\\n\\nwith changes since the acquisition of new values can be seen as a modification of\\n\\nthe constraint store. However, we work in an open world where domains are left\\n\\nopen thanks to their unknown part. Unknown domain parts represent intensionally\\n\\nfuture acquisitions, i.e., future changes.\\n\\nAnother DCS framework was given for configuration prob-\\n\\nlems (Mittal and Falkenhainer 1990). This framework considers dynamicity\\n\\nin the set of variables; variables are introduced or removed during search by means\\n\\nof constraints. The aim is to find a solution where only some of the variables\\n\\nare assigned a value, while the others are inactive. However, differently from our\\n\\nframework, the set of domain values is given at the specification of the problem.\\n\\nMany systems consider implement sets, because sets have powerful description\\n\\ncapabilities. In particular, some have been described as instances of the general\\n\\nCLP(X ) framework (Jaffar et al. 1998), like {log} (Dovier and Rossi 1993; Dovier et al. 1996;\\n\\nDovier et al. 2001), CLPS (Legeard and Legros 1991), or Conjunto (Gervet 1997).\\n\\nOthers apply an object-oriented approach (Puget 1992; Puget 1994).\\n\\nIn {log}(Dovier and Rossi 1993; Dovier et al. 1996; Dovier et al. 2001), a set can\\n\\nbe either the empty set ∅, or defined by a constructor with which, given a set S\\n\\nand an element e, returns the set composed of S ∪ {e}. This language is very\\n\\npowerful, allowing sets and variables to belong to sets. However, set unification\\n\\nand the propagation of other constraints has an exponential time complexity in\\n\\nthe worst case. If we allow non-ground elements in an I-Set, we obtain a more\\n\\nexpressive (although less efficient) framework, like {log}; we are currently studying\\n\\nthis extension.\\n\\nSet variables (Puget 1992; Puget 1994) can range on set domains. Each domain is\\n\\nrepresented by its greatest lower bound and its least upper bound. Each element in\\n\\na set must be ground, sets are finite, and they cannot contain sets. These restrictions\\n\\navoid the non-deterministic unification algorithm, and give good performance re-\\n\\nsults; they are implemented in most Constraint Programming systems (Puget 1994;\\n\\nSmolka 1995; SICStus 2003; Gervet 1997; IC-Parc 2001). However, these systems\\n\\ndo not deal with problems in which some domain elements are not known; in fact,\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 19\\n\\nthe user must provide the least upper bound of each set, thus giving the universe\\n\\n', 'set at the beginning of the computation.\\n\\nILOG-Solver (Puget 1994) does not deal directly with those problems, but has an\\n\\nextension module, called ILOG-Configurator (Mailharro 1998; ILOG 1999) whose\\n\\nmain added value is to implement open domains in a way similar to our system.\\n\\nThis system is very related with ours, thus we give a more detailed comparison.\\n\\nComparison with ILOG-Configurator. In Ilog-Configurator, there are variables\\n\\ncalled “ports” whose domains are defined by the set of instances of a given compo-\\n\\nnent type. The set of instances is not known in advance and instances are generated\\n\\non demand during constraint propagation. In this way, domains of port variables are\\n\\ndynamically extended; a domain that can be extended contains an element called\\n\\n“wildcard”.\\n\\nOur system has many points in common with the one described by Mailharro\\n\\n(1998). To compare the two, the reader can refer to the following table:\\n\\nICSP ILOG-Configurator\\n\\nFD Variables Port Variables\\n\\nI-Set Component Types\\n\\nKnown Part Set of generated instances\\n\\nUnknown Part Set of not yet generated instances (Wildcard)\\n\\n::/2 Link port-type\\n\\nDefinition Domain Dd\\nX Set of instances of the target type\\n\\nCurrent Domain Dc\\nX Possible set of a port\\n\\nRemoved Elements Dr\\nX Instances set of the target type \\\\ possible set\\n\\nInserted Event Extension delta domain of ports\\n\\nThe differences that we envisage between the two systems are the following.\\n\\nILOG-Configurator is based on an object-oriented technology, while ours is based\\n\\non logic programming; this is reflected in some specific choices made in the two\\n\\nsystems. For example, both the systems reason about the possible closure of a\\n\\ndomain. This information is carried by a special element, called “wildcard” by\\n\\nMailharro (1998), while in our system it is the unknown part of the domain. In our\\n\\nsystem, if the continuation of the domain is a variable, other elements can be added,\\n\\notherwise, if it is the empty set, the insertion of other elements will be forbidden\\n\\nby unification. This has a declarative meaning from a set viewpoint; while a set\\n\\ncontaining a wildcard must be updated through some destructive assignment, our\\n\\nformalization lets the user specify the value of a logical variable: the continuation of\\n\\nthe domain will be extended, as in a stream. In other words, in the ICSP formulation\\n\\nwe keep set membership and set inclusion distinct. In fact, in (Mailharro 1998), the\\n\\nwildcard element represents a set of elements, but is also an element of the domain.\\n\\nThanks to our formalization, some future extensions are possible: for example, it\\n\\nis possible to extend the type of sets in a domain, and to have domains that can\\n\\n\\n\\n20 M.Alberti et al.\\n\\ncontain sets themselves, like in {log} (Dovier et al. 1996). The propagation of FD\\n\\nconstraints is operationally performed in a similar way (Known Arc Consistency\\n\\npropagation); however, the property of Known Arc Consistency (KAC), which was\\n\\nnot defined by Mailharro (1998), enabled us to prove properties of the algorithms\\n\\nachieving KAC (Gavanelli et al. 2004).\\n\\nFinally, in our framework it is possible to define I-Sets as the combination of\\n\\nother I-Sets with set operators.\\n\\n6 Conclusions\\n\\nIn this work, we presented the implementation of a language that performs con-\\n\\nstraint propagation on variables with finite domains when information about do-\\n\\nmains is not fully known, and its CHR implementation. Domains are channels of\\n\\ninformation, and are considered as first-class objects that can be themselves defined\\n\\nby means of constraints. The obtained language belongs to the CLP class and deals\\n\\nwith two sorts: the FD sort on finite domains and the I-Set sort for domains. We\\n\\nprovide a propagation engine for the FD sort exploiting known arc-consistency, and\\n\\none for the I-Set sort, as well as a mechanism for their interaction.\\n\\nThe source code of the system is available on request.\\n\\nAcknowledgements\\n\\nThis work is partially funded by the Information Society Technologies programme\\n\\nof the European Commission under the IST-2001-32530 project (SOCS) within the\\n\\nGlobal Computing initiative.\\n\\nWe wish to thank the anonymous reviewers for their useful comments.\\n\\nReferences\\n\\nBarruffi, R., Lamma, E., Mello, P., and Milano, M. 1999. Least commitment on\\nvariable binding in presence of incomplete knowledge. In Proceedings of the Euro-\\npean Conference on Planning (ECP99), S. Biundo and M. Fox, Eds. Lecture Notes in\\nComputer Science, vol. 1809. Springer, Durham, UK, 159–171.\\n\\nCodognet, P. and Diaz, D. 1996. Compiling constraints in clp(FD). Journal of Logic\\nProgramming 27, 3 (June), 185–226.\\n\\nCucchiara, R., Gavanelli, M., Lamma, E., Mello, P., Milano, M., and Piccardi,\\n\\nM. 1999a. Constraint propagation and value acquisition: why we should do it inter-\\nactively. In Proceedings of the Sixteenth International Joint Conference on Artificial\\nIntelligence, T. Dean, Ed. Morgan Kaufmann, Stockholm, Sweden, 468–477.\\n\\n', 'Cucchiara, R., Gavanelli, M., Lamma, E., Mello, P., Milano, M., and Piccardi,\\n\\nM. 1999b. Extending CLP(FD) with interactive data acquisition for 3D visual ob-\\nject recognition. In Proceedings of the First International Conference on the Practical\\nApplication of Constraint Technologies and Logic Programming. Practical Application\\nCompany, London, 137–155.\\n\\nCucchiara, R., Gavanelli, M., Lamma, E., Mello, P., Milano, M., and Piccardi,\\n\\nM. 2001. From eager to lazy constrained data acquisition: A general framework. New\\nGeneration Computing 19, 4 (Aug), 339–367.\\n\\n\\n\\nA CHR-based Implementation of Known Arc-Consistency 21\\n\\nDechter, R. and Dechter, A. 1988. Belief maintenance in dynamic constraint networks.\\nIn Proceedings of the 7th National Conference on Artificial Intelligence, T. M. Smith,\\nReid G.; Mitchell, Ed. Morgan Kaufmann, St. Paul, MN, 37–42.\\n\\nDent, M. and Mercer, R. 1994. Minimal forward checking. In Proceedings of the Sixth\\nInternational Conference on Tools with Artificial Intelligence. 432–438.\\n\\nDincbas, M., Van Hentenryck, P., Simonis, H., Aggoun, A., Graf, T., and\\n\\nBerthier, F. 1988. The constraint logic programming language CHIP. In Proceedings\\nof the International Conference on Fifth Generation Computer System. OHMSHA Ltd.\\nTokyo and Springer-Verlag, Tokyo, Japan, 693–702.\\n\\nDovier, A., Omodeo, E., Pontelli, E., and Rossi, G. 1996. {log}: A language for\\nprogramming in logic with finite sets. Journal of Logic Programming 28(1), 1–44.\\n\\nDovier, A., Pontelli, E., and Rossi, G. 2001. Constructive negation and constraint\\nlogic programming with sets. New Generation Computing 19, 3 (May), 209–256.\\n\\nDovier, A. and Rossi, G. 1993. Embedding extensional finite sets in CLP. In Proceed-\\nings of the 1993 International Symposium on Logic Programming. MIT Press, British\\nColumbia, Canada, 540–556.\\n\\nFaltings, B. and Macho-Gonzalez, S. 2003. Open constraint optimization. In Pro-\\nceedings of the 9th International Conference on Principles and Practice of Constraint\\nProgramming (CP-2003). Lecture Notes in Computer Science. Springer, 303–317.\\n\\nFrühwirth, T. 1998. Theory and practice of constraint handling rules. Journal of Logic\\nProgramming 37, 1-3 (Oct.), 95–138.\\n\\nGavanelli, M., Lamma, E., Mello, P., and Milano, M. 2004. Dealing with incom-\\nplete knowledge on CLP(FD) variable domains. ACM Transactions on Programming\\nLanguages and Systems. To appear.\\n\\nGervet, C. 1997. Propagation to reason about sets: Definition and implementation of a\\npractical language. Constraints 1, 191–244.\\n\\nIC-Parc. 2001. ECLiPSe User Manual, Release 5.2. IC-Parc, Imperial College, London,\\nUK.\\n\\nILOG 1999. ILOG-Configurator, user manual, 1.0 ed. ILOG.\\n\\nJaffar, J., Maher, M., Marriott, K., and Stuckey, P. 1998. The semantics of\\nconstraint logic programs. Journal of Logic Programming 37(1-3), 1–46.\\n\\nLegeard, B. and Legros, E. 1991. Short overview of the CLPS system. In Proceedings\\nof the 3rd Int. Symposium on Programming Language Implementation and Logic Pro-\\ngramming, PLILP91, J. Ma luszyński and M. Wirsing, Eds. Lecture Notes in Computer\\nScience. Springer-Verlag, Passau, Germany, 431–433.\\n\\nMackworth, A. 1977. Consistency in networks of relations. Artificial Intelligence 8,\\n99–118.\\n\\nMailharro, D. 1998. A classification and constraint-based framework for configuration.\\nArtificial Intelligence for Engineering Design, Analysis and Manufacturing 12, 383–397.\\n\\nMittal, S. and Falkenhainer, B. 1990. Dynamic constraint satisfaction problems. In\\nProc. of AAAI-90. Boston, MA, 25–32.\\n\\nPuget, J. 1992. PECOS: A high level constraint programming language. In Proceed-\\nings of the First Singapore International Conference on Intelligent Systems (SPICIS).\\nSingapore, 137–142.\\n\\nPuget, J. 1994. A C++ implementation of CLP. Tech. Rep. 94-01, ILOG Headquarters.\\n\\nSchiex, T., Régin, J., Gaspin, C., and Verfaillie, G. 1996. Lazy arc consistency.\\nIn Proceedings of the Thirteenth National Conference on Artificial Intelligence and the\\nEighth Innovative Applications of Artificial Intelligence Conference. AAAI Press / MIT\\nPress, Menlo Park, 216–221.\\n\\n\\n\\n22 M.Alberti et al.\\n\\nSchiex, T. and Verfaillie, G. 1993. Nogood recording for static and dynamic constraint\\nsatisfaction problems. In Proceedings of the 5th International Conference on Tools with\\nArtificial Intelligence. IEEE Computer Society Press, Los Alamitos, CA, USA, 48–55.\\n\\nSergot, M. 1983. A query-the-user facility for logic programming. In Integrated Inter-\\nactive Computing Systems, P. Degano and E. Sandewall, Eds. North-Holland, 27–41.\\n\\nShapiro, E., Ed. 1987. Concurrent Prolog - Vol. I. MIT Press.\\n\\nShapiro, E. 1989. The family of concurrent logic programming languages. ACM Com-\\nputing Surveys 21, 4 (Mar.), 413–510.\\n\\nSICStus 2003. SICStus Prolog user manual, release 3.11.0.\\nhttp://www.sics.se/isl/sicstus/.\\n\\nSmolka, G. 1995. The Oz programming model. In Computer Science Today, J. van\\nLeeuwen, Ed. Lecture Notes in Computer Science, vol. 1000. Springer-Verlag, Berlin,\\n324–343.\\n\\nZweben, M. and Eskey, M. 1989. ', 'Constraint satisfaction with delayed evaluation. In\\nIJCAI 89. Morgan Kaufmann, Detroit, 875–880.\\n\\nhttp://www.sics.se/isl/sicstus/\\n\\n\\tIntroduction\\n\\tSyntax and Semantics\\n\\tThe I -Set sort\\n\\tThe FD sort\\n\\tLinking the two sorts\\n\\n\\tImplementation concepts\\n\\tFD sort concepts\\n\\tI -Set sort concepts\\n\\tInteraction between sorts\\n\\tAlgorithms\\n\\n\\tCHR implementation\\n\\tI -Set variables and constraints\\n\\tFD variables and constraints\\n\\tConstraints and rules for interaction between sorts\\n\\n\\tRelated work\\n\\tConclusions\\n\\tReferences\\n\\n'], 'name': '0408056v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0408/0408056v1.pdf', 'vectorized': None}, {'@search.score': 17.829876, '@search.rerankerScore': 3.0165441036224365, '@search.captions': [{'text': 'A CLP(FD) program searches a solution for a set of variables which take values over finite domains and which must verify a set of constraints. The evolution of the domains can be viewed as a sequence of applications of reduction operators attached to the constraints.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMzEwLzAzMTAwNDJ2MS5wZGY1', 'title': '()', 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n03\\n\\n10\\n04\\n\\n2v\\n1 \\n\\n [\\ncs\\n\\n.S\\nE\\n\\n] \\n 2\\n\\n2 \\nO\\n\\nct\\n 2\\n\\n00\\n3\\n\\nAADEBUG2003 171\\n\\nRigorous design of tracers:\\nan experiment for constraint\\nlogic programming\\n\\nMireille Ducassé∗, Ludovic Langevine†, Pierre Deransart†\\n\\n∗ IRISA/INSA de Rennes, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France\\n† INRIA Rocquencourt, BP 105, 78153 Le Chesnay Cedex, France\\n\\nABSTRACT\\n\\nIn order to design and implement tracers, one must decide what exactly to trace and how to produce this\\ntrace. On the one hand, trace designs are too often guided by implementation concerns and are not as useful\\nas they should be. On the other hand, an interesting trace which cannot be produced efficiently, is not very\\nuseful either. In this article we propose a methodology which helps to efficiently produce accurate traces.\\nFirstly, design a formal specification of the trace model. Secondly, derive a prototype tracer from this spec-\\nification. Thirdly, analyze the produced traces. Fourthly, implement an efficient tracer. Lastly, compare the\\ntraces of the two tracers. At each step, problems can be found. In that case one has to iterate the process. We\\nhave successfully applied the proposed methodology to the design and implementation of a real tracer for\\nconstraint logic programming which is able to efficiently generate information required to build interesting\\ngraphical views of executions.\\n\\nKEYWORDS: AADEBUG2003; tracer design methodology, tracer formal specification, tracer efficient imple-\\n\\nmentation\\n\\n1 Introduction\\n\\nDesigning and implementing tracers is a difficult task. One must decide what exactly to trace and\\nhow to produce this trace. On the one hand, trace designs are too often guided by implementation\\nconcerns and are not as useful as they should be. On the other hand, an interesting trace which cannot\\nbe produced efficiently, is not very useful either.\\n\\nSome sort of instrumentation is required to produce the trace information. This instrumentation\\ncan be done at different levels, for example the user programs can be transformed at source or com-\\npiled levels. Another possibility is to plant trace hooks in the language interpreter or emulator. All\\nthese possibilities have their advantages and drawbacks, deciding for one is not straightforward. For\\nexample, source level transformation does not require to open the compiler sources and can be effi-\\ncient enough [DN00]. Instrumenting an interpreter is in general easier than working directly in the\\ncompiler and the loss in performance might be acceptable.\\n\\nIn M. Ronsse, K. De Bosschere (eds), proceedings of the Fifth International Workshop on Automated Debugging (AADE-\\nBUG 2003), September 2003, Ghent. COmputer Research Repository (http://www.acm.org/corr/), cs.SE/yymmnnn; whole\\nproceedings: cs.SE/0309027.\\n1E-mail: Mireille.Ducasse@irisa.fr, {Ludovic.Langevine, Pierre.Deransart}@inria.fr\\n2This work is partially supported by the French RNTL project OADymPPaC, Tools for dynamic analysis of constraint logic\\nprograms, http://contraintes.inria.fr/OADymPPaC/\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\nhttp://arxiv.org/abs/cs/0310042v1\\nhttp://www.elis.UGent.be/aadebug2003/\\nhttp://contraintes.inria.fr/OADymPPaC/\\n\\n\\n172 M. DUCASSÉ ET AL.\\n\\nHowever, in order to have at the same time a faithful and efficient enough tracer, people often\\ndecide to instrument the language emulator or the user compiled code. In both cases, they have to\\ndive deeply into non-obvious code. This is a tricky task, especially if the tracer developers have not\\nbeen involved in the development of the compiler. At this stage, it is necessary that the trace model is\\nstable. Instrumenting at low level requires a lot of tedious work, it is essential to know exactly what\\nis expected before starting.\\n\\nThe first stage of the design, namely deciding what to trace, is, therefore, critical. However, de-\\nciding what to trace out of the blue is not obvious. It is often when people see the output of a tracer\\nthat they can tell whether the information is relevant and helpful.\\n\\nTo solve this apparent contradiction, we have conceived a methodology that we have successfully\\napplied to the design and implementation of a real tracer:\\n\\n1. Design a formal specification of the trace model based on an abstraction of the operational\\nsemantics of the language.\\n\\n2. Derive a prototype tracer from this specification.\\n\\n3. Analyze the produced traces to update or validate the trace model. This analysis can be par-\\ntially automated.\\n\\n4. Implement an efficient tracer.\\n\\n5. Validate the efficient implementation using the prototype.\\n\\nAt each step, problems in the model or in implementations can be found. In that case one has to\\niterate the process.\\n\\nThe advantages of the approach are as follows. Firstly, the formal specification helps to produce a\\ntrace model which gives an accurate picture of the executions. When examining existing tracers, one\\n', 'too often has the feeling that they produce whatever information is easily available, hoping that the\\nusers will manage with the holes and the noise. While users often manage, mostly because they have\\nno other choice, we claim that tracers with clean semantics are much more helpful. Secondly, in our\\napproach the prototype is systematically derived from the trace model. It is therefore easy to produce\\nand the resulting traces are faithful to the model. The prototype can easily produce trace samples.\\nThirdly, analyzing the trace samples enables people to tune the trace model. When an automated\\ntrace analyzer is used, this analysis can be systematic and thorough. Fourthly, when the tracer devel-\\nopers reach the stage where they have to implement a low-level tracer, they know which information\\nis crucial and which one can be escaped. If implementation compromises have to be made, people\\nhave rational arguments to take their decisions. Lastly, comparing the actual output of the low-level\\nimplementation against the expected trace produced by the prototype is a good way to validate the\\nquality of the implementation.\\n\\nNote that the execution of the prototype tracer can afford to be slow. Indeed, it is used only at\\ndevelopment time for qualitative reasoning, firstly to tune the trace model, then to test the imple-\\nmentation. Furthermore it is meant to be used on small programs only. The only requirement of\\nthese programs is that they altogether exhibit all the characteristics of the traced language. In order\\nto test the performance of the final tracer, big programs have, of course, to be traced but with the\\nlow-level implementation not with the prototype.\\n\\nThe first three steps of this methodology had been applied to the retrospective design of a Prolog\\ntracer [JDR01]. The formal specification step enabled to specify a variety of existing trace models for\\nProlog which were shown to be minor variants of each others. The result was a unified view of nu-\\nmerous models which were initially proposed without much rationale to support them. Furthermore\\na number of implementation issues regarding variable identifiers were detected.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 173\\n\\nMore interestingly, we have used all the steps of the methodology to design from scratch a tracer\\nfor constraint logic programming over finite domains(CLP(FD) in the following). A detailed descrip-\\ntion of this tracer can be found in [LDD03]. The low-level tracer has been implemented inside the\\ncompiler of Gnu-Prolog [GP01] by somebody who did not previously know the implementation of\\nthe compiler. This experiment has been done within a project on visualization of constraint program\\nexecutions, with academic and industrial partners working on different platforms. Both the formal\\nspecification of the trace model and the prototyping capabilities have enabled us to discuss with all\\nthe partners of the project and to make sure that the designed trace is indeed matching the needs\\nof everybody. Some partners build graphical views [SA00], other provide explanations of failure\\nfor over-constrained problems [JB00]. They all work with parts of the specified trace. As the de-\\nsign of the trace model was not connected to a particular implementation we could design a model\\nwhich is generic enough to be specialized at low cost for two different styles of constraint satisfaction\\n(CSP [Lrg01] and CLP [Apt99]). Furthermore, some parts of the designed information, for example\\nthe list of variables and the constraint identifiers, have been proved essential for the quality of the\\nviews but they are not obvious to gather from the implementation in the emulator. Starting from the\\nformal specification and knowing that they were absolutely needed, made them not too difficult to\\nimplement. One can conjecture that, had we started to implement straightaway the low-level imple-\\nmentation, these kinds of information would probably have never been provided by the tracer. Not\\nsurprisingly, in the tracers of the CLP systems, Sicstus Prolog [ASBC02] and Ilog Solver [Ilo01], in\\norder to get the list of variables, one has to traverse a huge part of the trace. This is especially tedious\\nto do for users.\\n\\nThe contribution of this article is to propose a methodology to rigorously design and validate\\ntracer implementations. To our best knowledge, this had not been done before. This methodology\\nhas been successfully tested against the design and implementation of a real tracer.\\n\\nThe next sections present the methodology in more details and illustrate it with samples of the ex-\\nperiment done with the design, implementation and validation of a tracer for Gnu-Prolog. The expla-\\nnations are meant for readers with no previous knowledge of constraint solving. Section 2 presents\\nthe trace model formalization step. Section 3 describes how to systematically derive an instrumented\\nmeta-interpreter from the formal specification. ', 'Section 4 outlines the trace analysis step. In particular,\\nit briefly presents the connection to a trace analyzer and lists some interesting graphical views for\\nCLP(FD). Section 5 discusses the low-level implementation of tracers. Section 6 sketches the valida-\\ntion of the efficient tracer against the prototype implementation.\\n\\n2 Formal specification of a trace model\\n\\nThe first step of our methodology is to specify a trace model, namely what information about pro-\\ngram executions should be given. In our sequential language context, a trace is a sequence of events.\\nAn event represents an interesting execution step, it can be seen as an execution breakpoint to which\\ninformation is attached.\\n\\nMost specifications of trace models are informal, when they exist at all. However, an informal\\nspecification is prone to misinterpretation by both developers and users. Indeed, in order to denote\\nthe events of interest, one has first to be able to denote events, and this is not easy in an informal way.\\n\\nIn the following, we describe two ways that have been tried to provide a formal specification of\\ntrace model, firstly an existing operational semantics has been instrumented and secondly an abstract\\noperational semantics has been specified. We then give some details of the second experiment.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n174 M. DUCASSÉ ET AL.\\n\\nx y z x y z x y z x y zx y z x y z\\n\\n1\\n\\n3\\n2\\n\\nred\\nx red\\n\\ny\\nred\\n\\ny\\ny > z red\\n\\nz\\ny > z red\\n\\nx\\nx > yx > yx > y\\n\\nFigure 1: Application of reductions to the system {x > y; y > z}.\\n\\n2.1 Instrumenting an existing operational semantics\\n\\nSome programming languages have precise operational semantics which rigorously specify the com-\\nputation steps. Hence the computation events are clearly denoted. In such a case, it is relatively easy\\nto formally specify a trace model as shown by Jahier et al. with the Prolog tracer retro-specifica-\\ntion [JDR01]. There were already numerous operational semantics available for Prolog. The contin-\\nuation passing semantics of Nicholson and Foo [NF89] was used. Then instrumentations inside the\\noperational semantics were specified. Only 2 rules of one line each had to be instrumented in order\\nto get the “standard” trace of Prolog. The instrumentation itself is slightly tricky but it can be under-\\nstood without ambiguity when examining a formal specification of 10 lines. The detailed description\\nof this experiment is out of the scope of this article. Indeed, the explanations of operational semantics\\nrequires a couple of pages, understanding them requires a good knowledge of Prolog and this article\\nis not aiming at Prolog specialists.\\n\\n2.2 Specifying an abstract operational semantics\\n\\nAn operational semantics is not always available, for example we are not aware of any for the C lan-\\nguage. In such a case, starting the design of the tracer by designing a complete operational semantics\\nis certainly an overkill. An operational semantics specifies in detail the execution of a program. From\\nan operational semantics one can derive an implementation of a compiler. In order to design a tracer,\\nless information is usually needed than to implement a compiler. In that case, an abstract operational\\nsemantics is sufficient. The information given in an abstract operational semantics is correct but not\\ncomplete. It tells tracer developers what information should be provided to users and it tells users\\nhow to interpret this trace information. In the case of CLP(FD) there was no operational semantics\\nthat we could use to specify a tracer and we designed an abstract operational semantics as a set of\\nstate transition rules. .\\n\\n2.3 Informal presentation of domain reduction\\n\\nBefore we give examples of a formal specification of events we have to informally explain how vari-\\nable domains are reduced. This is an essential mechanism of constraint propagation in the case of\\nfinite domains. A CLP(FD) program searches a solution for a set of variables which take values\\nover finite domains and which must verify a set of constraints. The evolution of the domains can\\nbe viewed as a sequence of applications of reduction operators attached to the constraints. Each op-\\nerator can be applied several times until the computation reaches a fix-point [FLT00]. This fix-point\\nis the set of final domain states. An example of computation with reduction operators is shown in\\nFigure 1. There are three variables x, y and z and two constraints, x > y and y > z. A set of possi-\\nble values is associated to each variable. This set is called the domain of the variable. The domain\\nreduction consists in elementary steps that remove inconsistent values from those domains. At the\\nbeginning, the domain of x, Dx, the domain of y, Dy , and the domain of z, Dz , are all equal to {1, 2, 3}.\\nThis is represented by three columns of white squares. Considering the first constraint, it appears that\\nx cannot take the value “1”, because otherwise there would be no value for y such that x > y; ', 'this in-\\nconsistent value is withdrawn from Dx. This withdrawal is marked with a black square. In the same\\nway, the value 3 is withdrawn from the domain of y. Then, considering the constraint y > z, the sets\\n{1} and {2, 3} are respectively withdrawn from Dy and Dz . Finally, using again the first constraint to\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 175\\n\\nnewVariable\\nx 6∈ V\\n\\nV ← V ∪ {x}, D ← D ∪ {(x, Dx)}\\n{Dx : initial domain of x}\\n\\nnewConstraint\\nc 6∈ C ∧ var(c) ⊂ V\\n\\nC ← C ∪ {c}\\n\\nreject\\nA = {c} ∧ unsatisfiable(c,D) ∧ R = ∅\\n\\nA← ∅, R← {c}\\n\\nsuspend\\nA = {c} ∧ no_reduction(c,D) ∧ R = ∅\\n\\nA← ∅, S ← S ∪ {c}\\n\\nawake\\nA = ∅ ∧ wake_condition(c) ∧ R = ∅\\n\\nA← {c}\\n\\nreduce\\nA = {c} ∧ x ∈ var(c) ∧ W c\\n\\nx(D) 6= ∅ ∧ R = ∅\\n\\nDx ← Dx −W c\\nx(D)\\n\\n{\\n\\nW c\\nx(D) : inconsistent values\\n\\nof x for c wrt D\\n\\n}\\n\\nFigure 2: Six rules of the abstract operational semantics defining six event types\\n\\npropagate the previous reduction of Dy , Dx is reduced to the singleton {3}. The fix-point is reached.\\nThe final solution is {x = 3, y = 2, z = 1}.\\n\\n2.4 Samples of formal event rules for CLP(FD)\\n\\nOur abstract operational semantics is defined by a set of transition rules between observed states. An\\nobserved state is a tuple containing in particular: C, the set of constraints declared until this state;\\nV , the set of finite-domain variables declared until this state; D, the set of domains of the variables\\ndeclared until this state; A, the set of active constraints ; S, the set of sleeping constraints; and R,\\nthe set of rejected constraints which contains unsatisfiable constraints.\\n\\nFigure 2 gives six examples of transition rules specifying types of events of interest. The complete\\ntrace model contains thirteen event types. Rule newVariable specifies that a new variable x is intro-\\nduced in V and that its initial domain is Dx. Rule newConstraint specifies that the solver introduces\\na new constraint c in C, all variables involved in c are already defined. Rule reject specifies that if\\nthe active constraint (A = {c}) is unsatisfiable in the current state of the domains, it is put in the\\nset of rejected constraints, R. A constraint is unsatisfiable for example when one of its variables has\\nan empty domain. Rule suspend specifies that when an active constraint cannot reduce any domain\\nat the moment, it is suspended in S. Rule awake specifies that when the set of active constraints is\\nempty and some specific condition is fulfilled a suspended constraint can be awoken and become ac-\\ntive 3. Rule reduce specifies that if the active constraint, c, has a variable, x, with inconsistent values\\nin its domain, W c\\n\\nx(D), these values are withdrawn from its domain Dx.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n176 M. DUCASSÉ ET AL.\\n\\n1 newVariable v1 =[0-268435455]\\n2 newVariable v2 =[0-268435455]\\n3 newConstraint c1 fd_element([v1,[2,5,7],v2])\\n4 reduce c1 v1 =[1,2,3] W=[0,4-268435455]\\n5 reduce c1 v2 =[2,5,7] W=[0-1,3-4,6,8-268435455]\\n6 suspend c1\\n7 newConstraint c4 x_eq_y([v2,v1])\\n8 reduce c4 v2 =[2] W=[5,7]\\n9 reduce c4 v1 =[2] W=[1,3]\\n\\n10 suspend c4\\n11 awake c1\\n12 reject c1\\n...\\n\\nFigure 3: A portion of Trace for fd_element(I,[2,5,7],A), (A#=I ; A#=2). a-b means\\nfrom a to b and a,b means a and b\\n\\n2.5 A Trace Example\\n\\nFigure 3 presents the beginning of a trace of a toy program in order to illustrate the event types\\ndescribed above. This program, fd_element(I, [2,5,7],A), (A#=I ; A#=2), specifies that\\nA is a finite domain variable which is in {2, 5, 7} and I is the index of the value of A in this list;\\nmoreover A is either equal to I or equal to 2. The first option is infeasible; the trace shows the events\\nrelated to the failing attempt to satisfy it.\\n\\nThe trace can be read as follows. The first two events are related to the introduction of two vari-\\nables v1 and v2, corresponding respectively toI and A. In Gnu-Prolog variables are always created\\nwith the maximum domain (from 0 to 268.435.455). Then the first constraint is created: fd_element\\n(event #3). This constraint makes two domain reductions (events #4 and #5): the domain of the first\\nvariable (I) becomes {1, 2, 3} and the domain of A becomes {2, 5, 7}. After these reductions, the con-\\nstraint is suspended (event #6). The next constraint, A#=I, is added (event #7). Two reductions are\\ndone on variables A and I, the only possible value for A and I to be equal is 2 (events #8 and #9).\\nAfter these reductions, the constraint is suspended (event #10). The first constraint is awoken (event\\n#11). If A and I are both equal to 2, I cannot be the rank of A. Indeed, the rank of 2 is 1 and the value\\nat rank 2 is 5. The constraint is therefore rejected (event #12). The execution continues and find the\\nsolution A=2 and I=1. This requires 20 other events not shown here\\n\\n2.6 Discussion\\n\\nOur semantics does not specify how the rules are applied but what events are of interest and what\\ninformation is available at each event. ', 'As already mentioned, it helps tracer developers to design the\\ntracer and it helps tracer users to interpret the produced traces.\\n\\nFor example, rule reject tells the implementor that whenever the solver finds an unsatisfiable\\nconstraint, the tracer should be called with this constraint. The same rule tells users that when they\\nsee a reject event in a trace, the corresponding constraint has become unsatisfiable and there was\\npreviously no rejected constraint.\\n\\nSimilarly, rule reduce tells the implementor that, when the solver processes a reduction, the tracer\\nshould be called with information about the related constraint, the related variable and the new\\ndomain Dx. The same rule tells users that when they see a reduce event in a trace, the reduction\\nhas been achieved on one of the variables of the specified constraint, that there were inconsistent\\n\\n3Awakening conditions are solver dependent, and usually contain the “added value” of each solver. Some are therefore rather\\nreluctant to show this condition in the trace.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 177\\n\\n1 reject(St0, St) :-\\n2 St0 = ([C], S, Q, T, [], D),\\n3 get_varC(C, VarC),\\n4 member(X, VarC),\\n5 get_domain(X, D, []),\\n6 St = ( [], S, Q, T, [C], D),\\n7 trace(reject, C, St0, _, _, _).\\n8\\n\\n9 reduce(St0, St, ModOut) :-\\n10 St0 = ([C], S, Q, T, [], D0),\\n11 get_varC(C, VarC),\\n12 member(X, VarC),\\n13 reduction(C, D0, X, Wx),\\n14 update_domain(X, Wx, D0, D, ModOut),\\n15 St = ([C], S, Q, T, [], D),\\n16 trace(reduce, C, St0, X, Wx, ModOut).\\n\\nFigure 4: Translation into Prolog of the reject and reduce rules of Figure 2\\n\\nvalues to remove from this variable and that there was previously no rejected constraint. The trace\\nalso gives the inconsistent values that have been withdrawn. Incidentally, the rule also specifies that\\nthe constraint that prompted the reduction is still the active one (A is not modified).\\n\\nNote that the upper part of the rules are not shown in actual traces, this is implicit information. In\\nmost tracers, users have to guess it. In our system, it is explicit, at least in the formal specification.\\n\\n3 Implementation of a prototype tracer\\n\\nA formal specification of trace model is helpful to formally reason about a trace. However, it actually\\nspecifies many traces for many kinds of solvers. It is sometime too arid to decide whether possible\\ntraces can be of any help to users. With that respect, it is better to have samples of execution traces\\nchecked by “guinea pig users”. Producing samples by hand is very tedious. It becomes quickly un-\\ntractable since the trace model evolves according to the remarks of the guinea pigs! New samples\\nhave therefore to be produced until a trace model is validated by users. It is, thus, welcome to have\\na tracer as quickly as possible. However, a low-level implementation is not suited before the trace\\nmodel has been validated by users. As already mentioned in the introduction, we propose to use a\\nprototype tracer in order to break this deadlock.\\n\\n3.1 Derivation of a prototype tracer from the CLP(FD) trace model\\n\\nIn our CLP(FD) experiment, we derive a CLP(FD) interpreter coded in Prolog that we instrument\\nwith trace hooks. Figure 4 contains the translation of reject and reduce rules of Figure 2. Each rule is\\nencoded by a predicate with the same name as the rule.\\n\\nBefore paraphrasing the code for one rule, we give the meaning of all the (simple) predicates\\nthat are used and not defined: get_varC(C, V) takes as input a constraint C and outputs a list\\nof the constraint variables that appear in C; member(X, L) is a standard Prolog predicate which\\nchecks whether X is an element of the list L; get_domain(X, D, Dx) takes a constraint vari-\\nable X and a domain state D, and outputs the domain of X (Dx); note that in Prolog = denotes a\\nunification; trace(Port, C, St0, Att1, Att2, Att3) takes as input the different event at-\\ntributes; it calls the trace analysis system which can, for example, print a trace line; reduction(C,\\nD, X, Wx) takes as input a constraint C, a domain state D, a constraint variable X, and outputs the\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n178 M. DUCASSÉ ET AL.\\n\\nvalues to withdraw from the domain of X; it fails if Wx = ∅ (no reduction can be done);\\nupdate_domain(X, Wx, D0, D, Mod) takes as input a constraint variable X, a value set Wx (to\\nwithdraw), and a domain state D0; it outputs the state domain D such that Dx=D0 - Wx, and the\\nlist of modification types Xmod1\\n\\n, ..., Xmodn\\n, where modi ∈ {min, max, ground, any, empty}. These\\n\\nmodifications characterize the Wx value withdrawal.\\nAll the predicates implementing transition rules take as input a solver state St0 and output a new\\n\\nsolver state St. St0 and St respectively denote the state of the solver before and after the application\\nof a rule. Predicate reject(St0, St) implements the reject rule. That rule needs to fulfill 3 condi-\\n', 'tions to be allowed to be applied: firstly, there is a constraint C in the active constraint set, secondly\\nthe set of rejected constraints is empty, and thirdly there exists a variable attached to the C constraint\\nwhose domain is empty. This last condition implies the unsatisfiable(c,D) predicate of Figure 2.\\nThe first two conditions are checked line 2. The third condition is checked lines 3 to 5 using Prolog\\nbacktracking. The execution of this predicate will backtrack to member(X, VarC) until either there\\nis no more variables in VarC or one of them has an empty domain. After the application of the rule\\nthe set of active constraints is empty and the set of rejected constraints contains C (line 6). The tracer\\nis called with the relevant information (line 7). Note the use of Prolog anonymous variables for ar-\\nguments 3 to 6. This means that the values are meaningless. The other rules are implemented in the\\nsame way.\\n\\nThe rules are integrated into the underlying Prolog system in the usual meta-interpretation way\\nof Prolog. This is not detailed in this article. An introduction to meta-interpreters in Prolog can be\\nfound in [SS94].\\n\\n3.2 Discussion\\n\\nWe have been able to systematically deduce the Prolog code from the specification. Even if the pro-\\nduction of the prototype tracer was not automatic, it has been sufficiently systematic so that the\\nmodifications of the trace model could be immediately integrated. Furthermore, it has always been\\neasy to convince ourselves that the produced prototypes indeed implemented the expected trace\\nmodel.\\n\\nThe produced prototype tracer was rather slow, but as already mentioned in the introduction,\\nefficiency is not an issue at this stage. The idea is to validate the trace model, the tracer designers use\\nthe prototype on well chosen and small programs.\\n\\nThe formal specification is very useful, but if time and resources are short, and if the prototype\\ntracer is very simple and easy to implement, it can be considered to start the design of the tracer with\\nthe prototype. One will miss the formal support for verification but at least there will be some means\\nto think about the trace design.\\n\\nIn our experiments, we have used the meta-interpretation capabilities of logic programming to\\nbuild prototype tracers. Even in languages with no meta-programming capabilities, there are always\\nsome means to easily produce prototypes. For example a source-level instrumentation of a subset\\nof the language is generally possible. Not all the features and libraries of a language need to be\\ninstrumented in the prototype. If the syntax of the language is specified by a grammar, then the in-\\nstrumentation can be implemented inside this grammar, for example with an attributed grammar\\nlanguage such as Yacc.\\n\\n4 Trace analysis\\n\\nOnce a first trace model is designed and a prototype tracer exists, it is important to play with actual\\ntraces. As soon as the traces are longer than what can be printed on a page it becomes very tedious to\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 179\\n\\n    \\n\\n?− fd_element(I,[2,5,7],A),(A#=I;A#=2).\\n\\nGives control to\\n\\nRetrieves current attribute values\\n\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n\\n���\\n���\\n���\\n���\\n\\n<Execution>\\n\\n<Execution>\\n\\n<no trace info about next event>\\n\\nfirst event\\n\\n<Execution>\\n\\n...\\n\\nsecond event\\n\\n[LSD]:\\n\\nnth  event\\n\\n<retrieve current event attributes>\\n\\n<print current event attributes>\\n\\n[LSD]: fget(chrono = 4), print.\\n\\nf_get(chrono = 4)\\n\\n<current chrono is not equal to 4>\\n\\n<current chrono is equal to 4>\\n\\n[4] Reduce  c1   v1=[1,2,3]\\n\\nFigure 5: Illustration of the processing of a filtering query\\n\\nanalyze them by hand. Even toy programs can produce traces of thousands of events whose system-\\natic display would be inefficient and irrelevant. Therefore, we believe that the validation can be much\\nmore rigorous and powerful if it is automated. In our approach we connect the prototype tracer with\\nan automated trace analyzer à la Opium [Duc99b]. The first advantage is that many long traces can be\\nsystematically tested. A second advantage is that abstract and graphical views can be automatically\\nbuilt [Duc99a, Jah00]. In the case of CLP we have built a number of graphical views which helped\\nus select from the potential interesting trace information the ones that were really important and the\\nones that were not so crucial. It should be noted that, applying the methodology, the trace model that\\nwe designed varied quite a lot between the first design [LDDJ01] and the current one [LDD03].\\n\\nIn the remaining of this section we first present the generic trace querying facility. We then sketch\\none example of interesting graphical view of CLP(FD) executions which has been built with the trace\\nanalyzer.\\n\\n4.1 Analysis of the produced trace\\n\\n', 'In our trace analysis scheme, users can formulate queries in order to investigate an execution trace.\\nThe queries are formulated in the Prolog language extended by two primitives: fget/1 and\\nget_attr/2. fget/1 searches for a specific event forward in the execution trace, get_attr/2\\nretrieves data about the current event.\\n\\nEvents are searched for as the traced program is executed. There are two execution processes,\\none for the traced execution, and one for the trace analysis (called LSD in the following4). Figure 5\\nillustrates how the fget/1 primitive works. Let us assume that the programmer wants to query the\\nexecution trace of the program given in Figure 3. When the execution reaches the first event, it notifies\\nLSD which prompts the programmer for a trace query. The programmer enters a goal in order to\\n\\n4LSD stands for a “Long Story Debugger”. It is a prototype of generator of trace analyzers currently under development.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n180 M. DUCASSÉ ET AL.\\n\\n1 :- fget([port = reduce, chrono>3]),\\n2 get_attr([var, withdrawn], [X, Wx]).\\n3\\n\\n4 :- setval(nb_reject, 0),\\n5 fget(in(port, [reject, solution])),\\n6 ( get_attr(port, reject)\\n7 -> incval(nb_reject),\\n8 fail\\n9 ; true %else this is a solution, stop counting\\n\\n10 ),\\n11 getval(nb_reject, NbFailures),\\n12 writeln(NbFailures).\\n\\nFigure 6: Two examples of trace queries\\n\\nsearch forward until an event with chronological number equal to 4 is found (fget([chrono=4])).\\nThis event should then be displayed (print). At that moment, LSD can only get information about\\nthe current event. It therefore returns control to the traced execution. When the traced execution\\nreaches the next event, it locally checks whether the current chrono is equal to 4. As the current\\nchrono is not the requested one, the traced execution is resumed until the next event is reached.\\nThe chrono is again locally checked. Forward moves and checking are done in turn until the first\\nevent whose chrono is 4. LSD is notified and proceeds. The current event attributes are retrieved\\nby the print command which displays the related information. The execution of the trace query is\\ncompleted. The programmer is then prompted for another one.\\n\\nThe scheme previously described is a good compromise between efficiency and expressive power.\\nOn the one hand, the search for events is done in the traced process, and can be very efficient. On the\\nother hand, as the whole power of Prolog is available in the analyzer process, sophisticated debug-\\nging programs can be written.\\n\\nTwo examples of composed queries are given in Figure 6. The first query asks to go to the\\nfirst event whose port 5 is reduce with a chronological number (chrono) greater than 3. The re-\\nduced variable and the withdrawn domain are then retrieved and stored in the variables X and\\nWx On the trace given in Figure 3, the query would find the fourth event and return X=v1 and\\nWx=[0,4-268435455].\\n\\nThe second query of Figure 6 is an example of sophisticated query which could be integrated into\\nan analysis program. It counts the number of failures encountered before the first solution and prints\\nit. First, the counter is initialized (line 4). The fget primitive is used to find the next event whose\\nport is either reject or solution (line 5). Then the actual port is retrieved with get_attr (line 6). If it\\nis reject, then the counter is incremented (line 7) and a failure is forced (line 8). If it is not a reject, it\\nmeans that it is a solution; in that case the loop is stopped by simply executing true (line 9). In the\\ncase where the execution is made to fail, it will backtrack to the fget which will find the next event\\nwhose port is either reject or solution (line 5). If the execution does no longer contain such events,\\nthe overall query will simply fail. In the case where the loop terminates on a solution the value of the\\ncounter is retrieved (line 11) and printed (line 12).\\n\\n4.2 A CLP(FD) visualization of variable updates\\n\\nOne of our experiments is the generation of a 3D variable update view. The evolution of the do-\\nmains of the variables during the computation is displayed in three dimensions. It gives a tool à\\nla TRIFID [CH00]. The trace analyzer computes domain size each time a constraint is added to the\\n\\n5following the Prolog tradition the type of events is called “port”.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 181\\n\\nFigure 7: Comparing two search procedures for the 40-queens problem with VRML views computed\\nby trace analysis.\\n\\nstore or rejected, as well as when a solution is found. The details of reduce events allow us to assign\\ncolor to each kind of domain update (for example minimum or maximum value removed or domain\\nemptied) as made by Simonis and Aggoun in the Cosytec Search-Tree Visualizer [SA00]. The trace\\nanalysis is implemented in about 125 lines of Prolog and generates an intermediate file. A program\\n', 'implemented in 240 lines of C converts this file into the VRML format.\\n\\nFigure 7 shows the resolution of the 40-queens problem with two different enumeration strategies.\\nThere are three axes: variables, domain size and time. The first strategy is a first-fail selection of the\\nenumerated variable and the first value tried is the minimum of its domain. The second strategy is\\nalso a first-fail strategy but variable list is sorted with the middle variable first and the middle of\\ndomain is preferred to its minimum. The two graphical views allow users to compare the efficiency\\nof these two strategies by manipulating the 3D-model. With the first strategy, domain sizes on one\\nside of the chess-board quickly decrease, and the domain size on the other side oscillate at length.\\nWith the second strategy, domain sizes decrease more regularly and more symmetrically, the solution\\nis found faster. In fact, the second strategy, which consists in positioning the queens starting from the\\ncenter of the chess-board, benefits more from the symmetrical nature of the problem.\\n\\n4.3 Discussion\\n\\nThe list of all the variables attached to the problem is a relevant information because graphical views\\nsuch as the 3D-model display all the domains at a glance whereas the solver handles only a small\\nsubset of variables at a time. The above experiments made clear that the tracer must be able, if re-\\nquested, to provide the whole state at each event, namely the domains and the constraints of the\\nproblem. Furthermore, the list of variables involved in a given constraint is not straightforward to\\nget from the implementation. However, this kind of information is also crucial to build some graph-\\nical views which are helpful to users. Even if producing these types of information requires some\\nimplementation efforts and may have a cost in terms of performance, it is worth producing them.\\nThis was not possible to decide by just looking at the formal semantics.\\n\\n5 Efficient implementation\\n\\nWhen the trace designer knows what in the expected trace model is important for which debugging\\nfunctions. The actual implementation can start. The events of interest have to be located in the com-\\npiler or compiled code. It is also necessary to specify how to get the information related to each event.\\nAt this stage, the tracer implementors can decide that a piece of information is too tricky or too costly\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n Domains Variables Time \\n\\n Domains Variables Time \\n\\n\\n\\n182 M. DUCASSÉ ET AL.\\n\\nto produce. This happens all the time in tracers produced without this methodology. The essential\\ndifference here is that the tracer implementors know what is kept or not and why. This is important\\nfor users. For example, if a particular graphical view requires some information which cannot be\\ngenerated in a particular implementation, users will know straightforwardly and will not discover it\\nthe hard way.\\n\\n5.1 The Gnu-Prolog tracer implementation\\n\\nEncoding a trace model that is not derived from the actual implementation of the solver is a delicate\\ntask. The correspondence between a formalized event and the code of the solver is not obvious: some\\nevents can be almost simultaneous, or a single event can be performed in several points of the code.\\nFor example, the trace model provides a unified view of the domain reduction with the reduce rule\\nwhereas there are several places to instrument in the code. Domain reduction is a crucial point in\\na constraint solver and the corresponding code is highly optimized. In Gnu-Prolog, there are four\\ndifferent cases for the domain reduction, depending on the way the values to withdraw have been\\ncomputed. The tracer handles each case with its peculiarities in order to get a single reduction event.\\nWhatever domain reduction routine is used, the trace event will be a reduce with standard attributes.\\n\\nAnother issue is the ability to proceed through the whole sets of constraints and variables, as well\\nas to allocate them unique identifiers. The solver only handles pointers on data structures. During\\nthe execution, a given pointer can be used for several constraints and variables. Moreover, at a given\\nmoment, the solver focuses on a small subset of entities. Therefore the tracer has to maintain its own\\ndata structures to reference all the pointers the solver handles. When the solver creates a new variable\\nor a new constraint, the tracer references the pointer on this new entity in a specific table. This table\\nassociates to this pointer a new integer identifier and some debugging data that can be useful in\\nthe sequel. When the solver deletes some constraints and variables, the corresponding entries are\\nremoved from the tracer table. This table can be used to search for an identifier knowing the pointer\\non an entity or to search for a pointer knowing the identifier of an entity. Both of these uses are made\\nin logarithmic time. ', 'Another possible use is retrieving the list of all the variables or the list of all the\\nconstraints.\\n\\nThe methodology has led to a trace model that is far from the implementation of Gnu-Prolog.\\nThe trace has needed the instrumentation of critical points in the solver. Nevertheless, the imple-\\nmentation has been possible and the final model has a clear semantics that is easy to understand\\nfor a constraint programmer. Moreover, the resulting tracer is efficient: the time overhead while ex-\\necuting a program without any trace output is between 5 and 30 percents (less than 10% in most of\\nour benchmarks). While producing a very detailed trace (with almost all the attributes the model\\nprovides), the time ratio against an untraced execution is between 3 and 7.4. These performances\\nare comparable to other debuggers known to be efficient enough, for example the Mercury tracer of\\nSomogyi and Henderson [SH99] or the ML tracer of Tolmach and Appel [TA95].\\n\\nIt is worth noticing that the tracer has been implemented in such a way that only the part of the\\ntrace which is required by a specific analysis is constructed: users pay only for what they need.\\n\\n5.2 Discussion\\n\\nTwo other tracers exist for constraint programming. The first one is the trace mechanism of the Ilog\\nSolver platform. Ilog Solver is a C++ library for constraint solving. Some virtual trace functions are\\ncalled at some specific points of the solver. By default, those functions do nothing. The developer can\\nredefine them to produce his own trace. The parameters of the trace functions are the attributes of\\nthe corresponding trace events. Taking the critical example of domain reduction, we see that trace\\nevents are guided by the implementation: there are two events by special case Ilog Solver handles:\\nan event before and an event after. Their attributes depend on the case that is active. At the opposite,\\nour model and implementation provide a single unified event with all the data at a glance.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 183\\n\\nPrototype trace:\\n\\n1 newVariable v1 =[1,2,3]\\n2 newVariable v2 =[2,5,7]\\n\\nGnu-Prolog trace:\\n\\n3 newVariable v1 =[0-268435455]\\n4 newVariable v2 =[0-268435455]\\n5 newConstraint c1 fd_element([v1,[2,5,7],v2])\\n6 reduce c1 v1 =[1,2,3] W=[0,4-268435455]\\n7 reduce c1 v2 =[2,5,7] W=[0-1,3-4,6,8-268435455]\\n8 suspend c1\\n\\nFigure 8: Portions of traces, with some attributes produced by the prototype tracer and Gnu-Prolog\\ntracer for the introduction of new variables\\n\\nThe second existing tracer is an experimental tracer for Sicstus Prolog. Its trace model is dedicated\\nto Sicstus implementation. The tracer is based on a complete storage of the trace and postmortem\\ninvestigation. When a specific data on an event is asked for, the tracer has to traverse the trace back-\\nwards until the data is found or is able to be recomputed. Most of our trace model could be produced\\nthis way but it is not realistic for real-life executions.\\n\\n6 Validation\\n\\nAnother important problem when building a tracer is to validate the result. In particular, it is impor-\\ntant to be sure that the produced trace is indeed the expected one. As opposed to the prototype, the\\nefficient implementation has no obvious relation to the formal specification.\\n\\nOur methodology proposes to further take benefits of the prototype implementation in order to\\ncompare the traces produced by the actual tracer with the trace produced by the prototype. This\\ncomparison is not expected to be a bijection in the general case. Indeed, some events may not be\\nimplemented (see the discussion above), some information may not be available. In addition, the\\nactual tracer may also produce larger traces for example for the parts of the language and libraries\\nthat were not taken into account in the prototype. As a consequence, at present, the comparison\\nbetween the two types of traces has to be done by hand.\\n\\n6.1 Validation of the Gnu-Prolog tracer implementation\\n\\nFor our experiment we compared the traces of the executions of some small programs produced\\nby the prototype tracer and the Gnu-prolog tracer. Figure 8 shows portions of trace related to the\\nintroduction of a new variable. In the prototype tracer, the variables are directly introduced with\\ntheir specified domain. In the Gnu-Prolog solver, every time a new variable is introduced, its domain\\ninitially contains all the possible values and the following execution steps use the regular reduction\\nmechanism to reduce the domain to the one which was declared. In our example, the two events of\\nlines 1 and 2 produced by the prototype tracer correspond to the events of lines 3 to 8 produced by the\\nGnu-Prolog tracer. These events appear in Figure 3 and have already been explained in section 2.5.\\n\\n6.2 Discussion\\n\\nBesides the identification of some minor implementation problems, this analysis led us to refine the\\n', 'constraint identifiers to take into account the fact that in Gnu-Prolog some built-in constraints are\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n184 M. DUCASSÉ ET AL.\\n\\nsplit into several simpler constraints. The need for this refinement could probably have been detected\\nby other means, the systematic comparison of the two types of traces, however, was a good support\\nto find problems in the low-level implementation, and this quite early in the life time of the software.\\n\\n7 Conclusion\\n\\nIn this article we have presented a methodology to rigorously design and implement tracers in 5\\nsteps: 1) design a formal specification of the trace model, 2) derive a prototype tracer, 3) analyze the\\nproduced traces, 4) implement an efficient tracer, 5) compare the traces produced by the efficient\\nimplementation and the prototype.\\n\\nThe methodology has been used within the context of logic programming where there is a strong\\nbackground on semantics. We, however, believe that the state transition approach can be applied to\\nspecify formal trace models for other programming paradigms.\\n\\nEven if we advocate to follow the complete methodology, some of the steps can be useful with-\\nout the others. For example, even without a formal specification, starting with an easy to build and\\nunderstand prototype tracer is already a major improvement over starting directly by the implemen-\\ntation of a low-level tracer.\\n\\nWe have shown how this methodology has been used to design and implement a real tracer\\nfor CLP(FD) which is able to efficiently generate information required to build interesting graphical\\nviews of executions. The trace model has been designed following mainly user’s concerns whereas\\nusual tracers are designed following mainly implementation concerns. The resulting tracer has per-\\nformances comparable to efficient tracers, therefore the methodology improves the quality of the\\nproduced trace, and does not prevent efficiency.\\n\\nAcknowledgments\\n\\nThe authors would like to thank Rachid Zoumman who implemented the C code which generates\\nthe VRML used in some analyses. They are also grateful to the OADymPPaC partners for fruitful\\ncollaboration. In particular, Narendra Jussien and Jean-Daniel Fekkete helped tune the model.\\n\\nReferences\\n\\n[Apt99] K. Apt. The essence of constraint propagation. Theoretical Computer Science, 221(1-2):179–\\n210, 1999.\\n\\n[ASBC02] M. Agren, T. Szeredi, N. Beldiceanu, and M. Carlsson. Tracing and explaining execution\\nof CLP(FD) programs. In A. Tessier, editor, Proc. of the Workshop on Logic Proramming\\nEnvironmement. CoRR repository cs.SE/0207047, July 2002.\\n\\n[CH00] M. Carro and M. Hermenegildo. The VIFID/TRIFID tool. In Deransart et al. [DHM00],\\nchapter 10.\\n\\n[DHM00] P. Deransart, M. Hermenegildo, and J. Maluszynski, editors. Analysis and visualization tools\\nfor constraint programming, volume 1870 of Lecture Notes in Computer Science. Springer-\\nVerlag, 2000.\\n\\n[DN00] M. Ducassé and J. Noyé. Tracing Prolog programs by source instrumentation is efficient\\nenough. Journal of Logic Programming, 43(2):157–172, May 2000.\\n\\n[Duc99a] M. Ducassé. Abstract views of Prolog executions with Opium. In P. Brna, B. du Boulay, and\\nH. Pain, editors, Learning to Build and Comprehend Complex Information Structures: Prolog as\\na Case Study, Cognitive Science and Technology, chapter 10, pages 223–243. Ablex, 1999.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\nAADEBUG2003: RIGOROUS DESIGN OF TRACERS 185\\n\\n[Duc99b] M. Ducassé. Opium: An extendable trace analyser for Prolog. The Journal of Logic program-\\nming, 39:177–223, 1999. Special issue on Synthesis, Transformation and Analysis of Logic\\nPrograms, A. Bossi and Y. Deville (eds), Also Rapport Technique INRIA 3257.\\n\\n[FLT00] G. Ferrand, W. Lesaint, and A. Tessier. Value withdrawal explanation in CSP. In\\nM. Ducassé, editor, AADEBUG’00 (Fourth International Workshop on Automated Debugging),\\npages 188–201, 2000. The COmputer Research Repository (CORR) cs.SE/0012005.\\n\\n[GP01] GNU-Prolog. A clp(fd) system based on Standard Prolog (ISO) developed by D. Diaz,\\n2001. http://gprolog.sourceforge.net/ Distributed under the GNU license.\\n\\n[Ilo01] Ilog. SOLVER 5.1 reference manual, 2001.\\n\\n[Jah00] E. Jahier. Collecting graphical abstract views of Mercury program executions. In\\nM. Ducassé, editor, Proceedings of the International Workshop on Automated Debugging\\n(AADEBUG2000), Munich, August 2000. Refereed proceedings, the COmputer Research\\nRepository (CORR) cs.SE/0010038.\\n\\n[JB00] N. Jussien and V. Barichard. The palm system: explanation-based constraint program-\\nming. In Proceedings of TRICS: Techniques foR Implementing Constraint programming Systems,\\na post-conference workshop of CP 2000, pages 118–133, Singapore, September 2000.\\n\\n[JDR01] E. Jahier, M. Ducassé, and O. Ridoux. Specifying Prolog trace models with a continuation\\nsemantics. In K.-K. Lau, editor, Logic Based Program Synthesis and Transformation. Springer-\\nVerlag, Lecture Notes in Computer Science 2042, 2001.\\n\\n', '[LDD03] L. Langevine, M. Ducassé, and P. Deransart. A propagation tracer for Gnu-Prolog: from\\nformal definition to efficient implementation. In C. Palamidessi, editor, Proceedings of the\\n19th Int. Conf. in Logic Programming. Springer-Verlag, Lecture Notes in Computer Science,\\nDecember 2003.\\n\\n[LDDJ01] L. Langevine, P. Deransart, M. Ducassé, and E. Jahier. Tracing executions of clp(fd) pro-\\ngrams: a trace model and an experimental validation environment. Rapport de Recherche\\nRR 4342, INRIA, Novembre 2001.\\n\\n[Lrg01] F. Laburthe and the OCRE research group. CHOCO, a Constraint Programming\\nkernel for solving combinatorial optimization problems, September 2001. Available at\\nhttp://www.choco-constraints.net.\\n\\n[NF89] T. Nicholson and N. Foo. A denotational semantics for Prolog. ACM Transactions on Pro-\\ngramming Languages and Systems, 11(4):650–665, 1989.\\n\\n[SA00] H. Simonis and A. Aggoun. Search-tree visualisation. In Deransart et al. [DHM00], chap-\\nter 7.\\n\\n[SH99] Z. Somogyi and F. Henderson. The implementation technology of the Mercury\\ndebugger. In Proceedings of the Tenth Workshop on Logic Programming Environ-\\nments, volume 30(4). Elevier, Electronic Notes in Theoretical Computer Science, 1999.\\nhttp://www.elsevier.nl/cas/tree/store/tcs/free/entcs/store/tcs30/cover.sub.sht.\\n\\n[SS94] L. Sterling and E. Shapiro. The Art of Prolog, second edition. MIT Press, Cambridge, Mas-\\nsachusetts, 1994. ISBN 0-262-19338-8.\\n\\n[TA95] A. Tolmach and A.W. Appel. A debugger for Standard ML. Journal of Functional Program-\\nming, 5(2):155–200, April 1995.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\tIntroduction\\n\\tFormal specification of a trace model\\n\\tInstrumenting an existing operational semantics\\n\\tSpecifying an abstract operational semantics\\n\\tInformal presentation of domain reduction\\n\\tSamples of formal event rules for CLP(FD)\\n\\tA Trace Example\\n\\tDiscussion\\n\\n\\tImplementation of a prototype tracer\\n\\tDerivation of a prototype tracer from the CLP(FD) trace model\\n\\tDiscussion\\n\\n\\tTrace analysis\\n\\tAnalysis of the produced trace\\n\\tA CLP(FD) visualization of variable updates\\n\\tDiscussion\\n\\n\\tEfficient implementation\\n\\tThe Gnu-Prolog tracer implementation\\n\\tDiscussion\\n\\n\\tValidation \\n\\tValidation of the Gnu-Prolog tracer implementation\\n\\tDiscussion\\n\\n\\tConclusion\\n\\n'], 'name': '0310042v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0310/0310042v1.pdf', 'vectorized': None}, {'@search.score': 14.2984295, '@search.rerankerScore': 2.9659926891326904, '@search.captions': [{'text': 'A proof procedure for CLP is defined as an extension of standard resolution. A state is defined as a pair 〈← a, A || C〉 of a goal and a set of constraints. At each step of the computation, some literal a is selected from the current goal according to some selection function.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMDAzLzAwMDMwMjZ2MS5wZGY1', 'title': 'arXiv:cs/0003026v1  [cs.LO]  8 Mar 2000', 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n00\\n\\n03\\n02\\n\\n6v\\n1 \\n\\n [\\ncs\\n\\n.L\\nO\\n\\n] \\n 8\\n\\n M\\nar\\n\\n 2\\n00\\n\\n0\\n\\nA Comparison of Logic Programming Approaches for Representation\\nand Solving of Constraint Satisfaction Problems\\n\\nNikolay Pelov and Emmanuel De Mot and Maurice Bruynooghe\\n\\nDepartment of Computer Science, K.U.Leuven\\nCelestijnenlaan 200A, B-3001 Heverlee, Belgium\\n\\nE-mail: {pelov,emmanuel,maurice}@cs.kuleuven.ac.be\\n\\nAbstract\\n\\nMany logic programming based approaches can be used\\nto describe and solve combinatorial search problems.\\nOn the one hand there are definite programs and con-\\nstraint logic programs that compute a solution as an\\nanswer substitution to a query containing the variables\\nof the constraint satisfaction problem. On the other\\nhand there are approaches based on stable model se-\\nmantics, abduction, and first-order logic model gener-\\nation that compute solutions as models of some the-\\nory. This paper compares these different approaches\\nfrom point of view of knowledge representation (how\\ndeclarative are the programs) and from point of view\\nof performance (how good are they at solving typical\\nproblems).\\n\\nIntroduction\\n\\nConsistency techniques are widely used for solving finite\\nconstraint satisfaction problems (CSP). These tech-\\nniques have been integrated in logic programming, re-\\nsulting in finite domain constraint logic programming\\n(Van Hentenryck 1989). In this paradigm, a program\\ntypically creates a data structure holding the variables\\nof the CSP to be solved, sets up the constraints and\\nuses a labelling technique to assign values to the vari-\\nables. The constraint solver uses consistency techniques\\n(Tsang 1993) to prune the search. Solutions are given\\nby an answer substitution to a goal. This leads to a\\nrather procedural programming style. Moreover, the\\nproblem description is not very declarative because the\\nmapping between domain variables and their value has\\nan indirect representation in a term structure. A more\\ndetailed discussion for representing and solving CSP in\\ndifferent logical systems, following this approach, can\\nbe found in (Mackworth 1992).\\n\\nAn alternative representation of a CSP can be given\\nin a first-order logic setting, where instead of using vari-\\nables, one can define the problem in a more natural way\\nby using constant and function symbols and specify the\\nconstraints as logic formulae. A solution is then given\\nby a model of the theory, and in particular by the inter-\\npretation of the function symbols. We argue that repre-\\nsenting a problem in this way tends to be more declar-\\native. To achieve a similar declarative representation\\n\\nin a logic programming system, the functions should be\\nreplaced with predicates and then an answer of a CSP is\\ngiven by a table of facts. Abduction (Kakas, Kowalski,\\n& Toni 1992) is one framework which allows such rea-\\nsoning. The relation between the variables of the CSP\\nand their values is declared as an abducible and solu-\\ntion of the problem is given by a set of abduced atoms.\\nMore recently, a logic programming paradigm based on\\nstable model semantics (Gelfond & Lifschitz 1988) has\\nemerged and Niemelä (Niemelä 1999) proposes it as a\\nconstraint solving paradigm. In this approach a solu-\\ntion is given by a stable model of the program.\\n\\nIn this paper, we use two typical CSP problems to\\ncompare the merits of the various approaches. One\\nis graph coloring where the domain size is constant\\nbut the number of constraints increases with increasing\\nproblem size; the other is the n-queens problem where\\nboth the domain size and the number of constraints in-\\ncreases with increasing problem size. For both problems\\nwe show the representation in the various approaches1,\\ncomment on the declarativity of the representation and\\nbriefly describe the basic principles behind the imple-\\nmentation. We also compare the performance of differ-\\nent systems and show how it scales by increasing the\\nproblem size.\\n\\nFirst, we give some basic notions about constraint\\nsatisfaction and logic programming. Then we discuss\\nthe classical representation of CSP as a logic and con-\\nstraint logic program. The next section gives a different\\nrepresentation of a CSP and shows how it can be trans-\\nlated to an equivalent logic program which then can be\\nsolved by abductive reasoning or by computing stable\\nmodels of the program. Finally, we give the results of\\nsolving some well-known problems with several systems\\nand the last section gives a summary of our research and\\nsome directions for future research.\\n\\nPreliminaries\\n\\nA constraint satisfaction problem is usually defined as\\na finite set of constraint variables X = {X1, . . . , Xn},\\na finite domain Di of possible values for each vari-\\n\\n1We do not use the actual syntax of the systems but a\\nsyntax which is more uniform across the different systems.\\n\\nhttp://arxiv.org/abs/cs/0003026v1\\n\\n\\nable Xi, and a finite set of constraint relations R =\\n{rS1\\n\\n, . . . , rSt\\n}, where Si ⊆ {1, . . . , n} for i = 1, . . , t\\n\\nare the indices of the variables which are constrained\\nby rSi\\n\\n. ', 'A solution is an instantiation of the variables\\nX which satisfies all the constraints in R.\\n\\nA logic program is defined for a fixed language L\\nof function and predicate symbols and an infinite set\\nof variables X . We assume that our language always\\ncontains the equality predicate = /2. Terms and atoms\\nare defined as usual. A literal is either an atom a or a\\nnegation of an atom not a. A clause has the form\\n\\na← b1, . . . , bn.\\n\\nwhere a is an atom and is called head and bi are lit-\\nerals and b1, . . . , bn is called body. A clause is called\\ndefinite if all bi are positive. A (definite) logic program\\nP is a set of (definite) clauses. A Herbrand interpre-\\ntation and Herbrand model are again defined as usual\\n(cf. (Lloyd 1987)). A definite logic program always has\\na unique least Herbrand model which will be denoted\\nwith lm(P ).\\n\\nKnowledge Representation of CSP\\n\\nLogic Programming\\n\\nA CSP can be easily represented as a definite logic pro-\\ngram. The domains of the variables are defined by\\nunary predicates. A constraint relation r/n is defined\\nby a predicate p/n such that lm(p/n) = r/n. Then a\\nCSP can be defined by a clause of the form:\\n\\ncsp(X1, . . . , Xn)←\\nd1(X1), . . . , dn(Xn),\\np1(XS1\\n\\n), . . . , pt(XSt\\n).\\n\\nA computed answer substitution θ for the goal ←\\ncsp(X1, . . . , Xn) using SLD resolution will be a solu-\\ntion to the CSP since P |= csp(X1, . . . , Xn)θ and in\\nparticular lm(P ) |= csp(X1, . . . , Xn)θ. It is also easy\\nto see that the least model of the csp/n predicate will\\ncontain all solutions to the problem. So, to compute\\nall solutions to a given problem one can use a bottom-\\nup fix-point operator to compute the least model of a\\nprogram.\\n\\nTo give an example let us consider the problem for\\nfinding the positions of n queens on a n×n chess board\\nsuch that no two queens attack each other. One way\\nof formalizing this problem is by using n2 boolean vari-\\nables which indicate whether a queen is placed on a par-\\nticular square. However, by taking into account the fact\\nthat no two queens can be placed on the same column,\\nwe can use only n variables which give the positions of\\nthe queens for each column. Then for all pairs of queens\\nwe should state the constraint that they can not attack\\neach other by being on a same row or diagonal. This\\nconstraint can be defined with the following predicate\\nwhich is parameterized by the distance D between the\\ncolumns of the two queens:\\n\\nsafe(X1, X2, D)← X1 6= X2, abs(X1 −X2) 6= D.\\n\\nThen the 4-Queens problem can be defined as:\\n\\ncsp(X1, X2, X3, X4)←\\nd(X1), d(X2), d(X3), d(X4),\\nsafe(X1, X2, 1), safe(X2, X3, 1),\\nsafe(X1, X3, 2), safe(X1, X4, 3),\\nsafe(X2, X4, 2), safe(X3, X4, 1).\\n\\nHere we exploit another particularity of the n-Queens\\nproblem, that the safe constraint is symmetric for the\\nfirst two arguments. Hence it is enough to only check\\nqueens such that the column of the first one is less than\\nthe column of the second one. Executing the query\\n← csp(X1, X2, X3, X4) under the top-down left-to-right\\nstrategy of Prolog will result in solving the problem by a\\ngenerate and test approach. By interleaving the calls to\\nthe domain predicates d/1 and the constraint predicates\\nwill result in a standard backtracking:\\n\\ncsp(X1, X2, X3, X4)←\\nd(X1), d(X2), safe(X1, X2, 1),\\nd(X3), safe(X2, X3, 1), safe(X1, X3, 2),\\nd(X4), safe(X1, X4, 3), safe(X2, X4, 2),\\n\\nsafe(X3, X4, 1).\\n\\nA lot of research has been done to improve the ex-\\necution strategy of standard Prolog. For example, a\\ntechnique known as co-routing uses a literal selection\\nstrategy which selects a constraint as soon as all its ar-\\nguments become ground. This allows a generate and\\ntest program to be executed with standard backtrack-\\ning. Another technique known as intelligent backtrack-\\ning (Bruynooghe 1991) does a failure analysis and back-\\ntracks only to variable assignments which are actually\\nresponsible for the failure.\\n\\ncsp(N, L)←\\nmake vars(L, N),\\nconstrain all(L).\\n\\nmake vars([], 0).\\nmake vars([H |T ], N)←\\n\\nN > 0,\\nd(H),\\nN1 is N − 1,\\nmake vars(T, N1).\\n\\nconstrain all([]).\\nconstrain all([X |Xs])←\\n\\nconstrain all(Xs),\\nconstrain between(X, Xs, 1).\\n\\nconstrain between(X, [], N).\\nconstrain between(X, [Y |Y s], N)←\\n\\nsafe(X, Y, N),\\nN1 is N + 1,\\nconstrain between(X, Y s, N1).\\n\\nFigure 1: N-Queens as a Definite Logic Program\\n\\nAn important problem with this representation of\\na CSP is that it has to be defined specifically for a\\ngiven number of queens. If we want to parameterize the\\n\\n\\n\\nproblem with respect to the number of queens then we\\nshould use some data structure (usually a list) to store\\nthe constraint variables. Figure 1 shows a typical spec-\\nification of the problem. The make vars/2 predicate\\nconstructs a list of n variables and uses backtracking to\\nenumerate all possible solutions.\\n\\nHowever this way of representing the problem is even\\nless declarative than before. First of all, the column\\nnumber of each queen is implicitly defined by the po-\\nsition of the corresponding variable in the list. Then,\\n', 'in order to add constraints only between queens such\\nthat the column of the first one is less than the column\\nof the second one we have to use two nested recursive\\npredicates.\\n\\ngraph coloring(V ert, Edges, V ars)←\\nmake vars(V ert, V ars),\\nadd constr(Edges, V ars).\\n\\nmake vars([], []).\\nmake vars([V |V ert], [assoc(V, X)|V ars])←\\n\\ncolor(X),\\nmake vars(V ert, V ars).\\n\\nadd constr([], V ars).\\nadd constr([edge(V1, V2)|Edges], V ars)←\\n\\nmember(assoc(V1, X1), V ars),\\nmember(assoc(V2, X2), V ars),\\nX1 6= X2,\\nadd constr(Edges, V ars).\\n\\nFigure 2: Graph Coloring as a Definite Logic Program\\n\\nAnother typical CSP problem is that of graph col-\\noring. The goal is to color all the vertices of a graph\\nin such a way that no two adjacent vertices have the\\nsame color. The graph can be represented by a list\\nof vertices and a list of terms edge(v1, v2) describing\\nthe edges. The problem can be expressed as a CSP\\nby associating a different variable for each vertex and\\nrestricting its domain to all possible colors. Then for\\neach edge in the graph we put a disequality constraint\\nbetween the variables corresponding to the vertices of\\nthe edge. Figure 2 shows a sample formulation of this\\nproblem as a logic program. Here the correspondence\\nbetween a vertex and the color assigned to it is made\\nexplicit by means of an association list.\\n\\nConstraint Logic Programming\\n\\nConstraint logic programming (CLP) (Jaffar & Maher\\n1994) is an extension of logic programming where some\\nof the predicate and function symbols have a fixed inter-\\npretation. This interpretation is dependent on a par-\\nticular constraint domain X (e.g. finite trees or real\\nnumbers) and this allows for a much more natural rep-\\nresentation of problems from this particular domain.\\nBesides its better declarative semantics for expressing\\nproblems, an implementation of a CLP(X) system also\\n\\nincludes an efficient domain specific solver solveX for\\nchecking satisfiability of a set of constraints.\\n\\nA proof procedure for CLP is defined as an extension\\nof standard resolution. A state is defined as a pair 〈←\\na, A || C〉 of a goal and a set of constraints. At each\\nstep of the computation, some literal a is selected from\\nthe current goal according to some selection function.\\nIf a is a constraint predicate then the next state is 〈←\\nA || C ∧ a〉 if solve(C ∧ a) 6= false or 〈✷ || false〉\\notherwise. If a is a normal atom then the next state is\\n〈← ~s = ~t, B, A || C〉 for some clause b ← B where a is\\n\\nof the form p(~s) and b is of the form p(~t).\\nA well suited constraint domain for representing\\n\\nCSPs is that of finite domain integer arithmetic\\nCLP (FD) (Codognet & Diaz 1996; Van Hentenryck,\\nSaraswat, & Deville 1998). It includes standard arith-\\nmetic relations like =, 6=, < and functions +,−, ∗ with\\ntheir usual interpretation. The implementation of\\nCLP (FD) is based on consistency (Tsang 1993) algo-\\nrithms.\\n\\nA CSP represented as a logic program can be trans-\\nlated to a CLP(FD) program in a straightforward way.\\nFirst, the domains of the variables are declared by a\\nspecial CLP predicate (for example X in 1..n) and\\nthe constraints are defined using the CLP predicates\\nand functions. Then the execution of the goal ←\\ncsp(X1, . . . , Xn) by a constraint proof procedure will\\nresult in a set of constraints which are then solved effi-\\nciently by consistency techniques.\\n\\nAn Alternative Representation\\n\\nFrom the examples and the discussion in the previous\\nsection, the following general methodology can be given\\nfor representing a parameterized CSP as a (constraint)\\nlogic program. First, we create some data structure\\nwhere each value of the parameter of the problem (e.g.\\nthe number of queens, or the number of vertices) is as-\\nsociated with a different variable. Then we define some\\nrecursive predicates which iterate over this data struc-\\nture and define constraints between the variables whose\\ncorresponding parameters satisfy certain conditions.\\n\\nIt seems natural to represent the mapping between\\nparameter and variable with a function. First let us\\nintroduce a new domain Dp which includes all values of\\nthe parameter. For example, for the n-Queens problem\\nDp is the set of columns and for the graph coloring\\nproblem Dp will contain all vertices. Then a solution\\nto a CSP can be represented by a function f : Dp → D,\\nwhere D is the domain of the constraint variables.\\n\\nThe use of functions for representing CSPs can be\\nrealized in a first-order logic setting where a solution\\nof a problem can be given by an interpretation of a\\nfunction symbol in a model of the theory describing\\nthe problem. Also the constraints are expressed more\\nnaturally by using function symbols. A definition of\\nthe n-Queens problem in first-order logic could be the\\nfollowing:\\n\\n\\n\\n∀C1, C2. C1 < C2 →\\nsafe(pos(C1), pos(C2), C2 − C1).\\n\\n∀X1, X2, D. safe(X1, X2, D)↔\\nX1 6= X2, abs(X1 −X2) 6= D.\\n\\nThe function symbol pos/1 represents the mapping\\nfrom columns to rows. A model2 of this theory based\\non a domain with n elements will consist of an inter-\\n', 'pretation of the function pos/1 and will be a solution\\nof the problem with n queens.\\n\\nIf we want to work with several domains with differ-\\nent sizes then we may use a many sorted first-order logic\\nwhere the arguments of the function and predicate sym-\\nbols are assigned (possibly different) sorts. Then in an\\ninterpretation of our theory for each sort we can assign\\na domain with the appropriate size. The full specifica-\\ntion of the graph coloring problem in many sorted logic\\nis given below.\\n\\nS = {sv, sc}\\nF = {col : sv → sc}\\n\\n∀V1, V2. col(V1) 6= col(V2)← edge(V1, V2).\\n\\nedge(1, 2).\\n. . .\\n\\nHere we use two sorts - sv for vertices, and sc for\\ncolors and a function col : sv → sc which maps vertices\\nto colors. The edges of the graph are described as a set\\nof facts edge(v1, v2). An interpretation of this theory\\nshould associate the set with all vertices of the graph\\nwith the sort sv and a set with possible colors with the\\nsort sc.\\n\\nSeveral systems for generation of finite models of\\nmany sorted first-order logic theories are available (e.g.\\nFINDER (Slaney 1995) and SEM (Zhang & Zhang\\n1995)) and thus can be used for solving CSPs.\\n\\nBack to Logic Programming\\n\\nUsing functions for representing CSPs in a logic pro-\\ngramming setting is not possible. The reason is that\\nthe domain of the computation is the Herbrand do-\\nmain (or comes from the constraint domain) and that\\nthe interpretation of the function symbols is fixed. To\\novercome this restriction, one can introduce unary pred-\\nicates dp/1 and d/1 defining the domain and the range\\nof the functions and encode a unary function f(X) = Y\\nas a binary predicate pf (X, Y ) with domain defined by\\ndp/1 and range by d/1. The following axioms establish\\nthat the interpretation of pf/2 corresponds to a func-\\ntion:\\n\\n∀X. ∃Y. d(Y ) ∧ pf(X, Y )← dp(X). (1)\\n\\n∀X, Y. dp(X)← pf(X, Y ). (2)\\n\\n∀X, Y, Z. Y = Z ← pf (X, Y ), pf (X, Z). (3)\\n\\n2We assume here that the arithmetic relations and func-\\ntions have a fixed interpretation, like in CLP.\\n\\nThe formula (1) states that the predicate pf (X, Y ) is\\ndefined for all X in the domain dp(X) and that the value\\nof Y is in the range d(Y ). The formula (2) enforces\\nthat the predicate pf is false for all values of X not in\\nthe domain dp(X) and (3) ensures that the predicate\\npf(X, Y ) defines a function from X to Y . By introduc-\\ning an auxiliary predicate has p, (1) can be rewritten\\nas:\\n\\n∀X. has p(X)↔ ∃Y. d(Y ) ∧ pf (X, Y ). (1a)\\n\\n∀X. has p(X)← dp(X). (1b)\\n\\nFormula 1a is the completion of the predicate has p.\\nWriting it as a logic program clause, the only-if part can\\nbe dropped. However, the other three axioms (1b), (2),\\nand (3) do not define any predicates but are just formu-\\nlae which should be true in models of the program. In\\nlogic programming, such clauses are known as integrity\\nconstraints and we will denote them with the symbol\\n⇐3. Figure 3 shows the resulting logic program.\\n\\nhas p(X)← d(Y ), pf (X, Y ). from (1a)\\n\\nhas p(X)⇐ dp(X). from (1b)\\n\\ndp(X)⇐ pf (X, Y ). from (2)\\n\\nY = Z ⇐ pf (X, Y ), pf (X, Z). from (3)\\n\\nFigure 3: A logic program limiting a predicate to be a\\nfunction.\\n\\nA solution to a CSP problem is then given by an\\ninterpretation of the predicate pf/2 in a model of the\\nlogic program obtained by replacing the functions f/1\\nwith the predicates pf/2 and adding the theory defin-\\ning pf/2. Different models give rise to different so-\\nlutions.Applying this transformation on the n-Queens\\nproblem, one obtains the specification given in figure 4\\nwhere pos(C, R) is the predicate which gives the row R\\nof a queen at a column C.\\n\\nAbduction\\n\\nAbductive logic programming (Kakas, Kowalski, &\\nToni 1992) is a form of reasoning in which an answer to\\na query is a set of facts. More formally, an abductive\\nframework is defined as a triple 〈P, A, I〉 where P is a\\nlogic program, A is a set of predicates called abducibles\\nand I is a set of integrity constraints. A solution is a\\nset ∆ ⊆ A4 such that M |= I for some canonical model\\nM of P ∪∆. If one is interested in a query, then it can\\nbe put as part of the integrity constraints. Different\\nchoices for the type of canonical model have been con-\\nsidered in the literature. In (Kakas & Mancarella 1990),\\n\\n3The standard form to write integrity constraints is as\\nclauses with an empty head. Here we use another notation\\nfor better clarity.\\n\\n4Here and in the rest of the paper we will use the same\\nsymbol A to indicate both the set of abducible predicates\\nand the set of all their ground instances.\\n\\n\\n\\nsafe(X1, X2, D)← X1 6= X2, abs(X1 −X2) 6= D.\\n\\nhas pos(X)← drow(Y ), pos(X, Y ).\\n\\nhas pos(X)⇐ dcol(X).\\n\\ndcol(X)⇐ pos(X, Y ).\\n\\nY = Z ⇐ pos(X, Y ), pos(X, Z).\\n\\nsafe(R1, R2, C2 − C1)⇐\\n\\npos(C1, R1), pos(C2, R2), C1 < C2.\\n\\nFigure 4: N-Queens as an (Abductive) Logic Program\\n\\nM must be a stable model of P ∪∆ which is also called\\ngeneralized stable model M(A) of P . In (Denecker &\\nDe Schreye 1998) three valued models of the comple-\\ntion of the program are considered and the abductive\\npredicates must have a two-valued interpretation.\\n\\n', 'A problem defined as in figure 4 can be given directly\\nto an abductive procedure by declaring the predicate\\npos(X, Y ) as abducible.\\n\\nProof procedures for abduction are defined in a simi-\\nlar way (Eshghi & Kowalski 1989) to, or as an extension\\n(Denecker & De Schreye 1998) of SLDNF resolution. In\\neach state of the derivation they also maintain a set ∆\\nof already abduced atoms. When an abductive atom is\\nselected in the current goal, it is checked if it can be\\nresolved with an atom from ∆. If this is not the case\\nthen the selected atom is added to the set of abducibles\\nand a consistency derivation is started which checks the\\nintegrity constraints to see if this assumption does not\\nlead to a contradiction. If the abducible atoms contain\\nvariables then during an abductive step these variables\\nare replaced with skolem constants and the unification\\nalgorithm is extended to deal with them (Denecker &\\nDe Schreye 1998). We have already discussed the prob-\\nlems of the SLD resolution for efficiently solving CSPs\\nthus we can expect that the performance of such more\\ncomplex proof procedures will be even worse.\\n\\nRecently, abduction has been extended to constraint\\nlogic programs. One of the main ideas is that the skolem\\nconstants which are added as arguments of the abduced\\npredicates are in fact existentially quantified constraint\\nvariables and their values can be computed by a con-\\nstraint solver. This allows us to have a more declarative\\nrepresentation of CSPs and still use efficient techniques\\nfor computing their solution. The first such integra-\\ntion is the ACLP system of Kakas (Kakas & Michael\\n1995) which is based on the proof procedure of (Eshghi\\n& Kowalski 1989). Originally, ACLP was defined only\\nfor definite programs and integrity constraints and in\\n(Kakas, Michael, & Mourlas 2000) it was extended to\\ndeal with negation as failure through abduction in a\\nsimilar way as in (Eshghi & Kowalski 1989). A more\\nrecent integration of abduction and CLP is the SLD-\\nNFAC system (Denecker & Van Nuffelen 1999) which is\\n\\nbased on the abductive procedure SLDNFA (Denecker\\n& De Schreye 1998).\\n\\nLogic Programming with Stable Model\\nSemantics\\n\\nAnother way of using “open” predicates in a logic pro-\\ngram is to use the stable model semantics (Gelfond &\\nLifschitz 1988). A predicate p can be defined as having\\nan open interpretation by the following two rules:\\n\\np← not p.\\n\\np← not p.\\n\\nwhere p is a new predicate symbol. This program has\\ntwo stable models - {p} and {p}. If A is a set of pred-\\nicates then we define with T (A) the following set of\\nclauses\\n\\nT (A) = { p(~x)← not p(~x). | p ∈ A } ∪\\n\\n{ p(~x)← not p(~x). | p ∈ A }\\n\\nThen to compute a stable model of a CSP as repre-\\nsented in section 4, one only needs to add to the pro-\\ngram the clauses T (A), where A is the set of predicates\\nwhich are the result of the transformation of the func-\\ntion symbols5.\\n\\nIn fact, there is a very strong relation between the se-\\nmantics of an abductive framework and the stable mod-\\nels of an equivalent logic program. It has been shown\\nin (Satoh & Iwayama 1991) that M(∆) is a general-\\nized stable model of an abductive framework 〈P, A, I〉\\niff there exists a stable model M ′ of 〈P ∪ T (A), I〉 such\\nthat M ′ = M(∆)∪∇ where ∇ = { p(~x) | p(~x) ∈ A\\\\∆ }.\\n\\nThe rules declaring the open predicates can be com-\\nbined with some of the integrity constraints to obtain\\na more compact representation of the problem. For ex-\\nample, the integrity constraint stating that the open\\npredicate pf should be false for all values not in the\\ndomain dp\\n\\ndp(X)⇐ pf (X, Y )\\n\\ncan be omitted by using the rule\\n\\npf(X, Y )← dp(X), not pf (X, Y ).\\n\\nThe reason is that in the stable model semantics an\\natom can be true only if it is a head of some clause.\\nThe full specification of the n-Queens problem is given\\nin figure 5.\\n\\nAn efficient implementation of the stable model se-\\nmantics is the smodels system (Niemelä & Simons\\n1996). It works with propositional rules and a special\\npre-processing program is used for grounding function-\\nfree range-restricted logic programs. The implemen-\\ntation of the system combines bottom-up inference\\nwith backtracking search and employs powerful pruning\\nmethods.\\n\\n5In fact, exactly the same methodology for representing\\nCSPs is proposed in (Niemelä 1999)\\n\\n\\n\\npos(X, Y )← dcol(X), not pos(X, Y ).\\npos(X, Y )← not pos(X, Y ).\\n\\nsafe(X1, X2, D)← X1 6= X2, abs(X1 −X2) 6= D.\\nhas pos(X)← drow(Y ), pos(X, Y ).\\n\\nhas pos(X)⇐ dcol(X).\\nY = Z ⇐ pos(X, Y ), pos(X, Z).\\n\\nsafe(R1, R2, C2 − C1)⇐\\npos(C1, R1), pos(C2, R2), C1 < C2.\\n\\nFigure 5: N-Queens with Stable Models Semantics\\n\\nOther Formalisms\\n\\nIn (Cadoli & Palopoli 1998) is presented a language\\ncalled datalog\\n\\nCIRC which is an extension of data-\\n\\nlog where only some of the predicates are minimized\\nand the interpretation of the others is left open. The\\nsemantics of the language originates from the nonmono-\\ntonic formalism of circumscription and is defined as the\\nminimal Herbrand model of the program w.r.t. a fixed\\n', 'interpretation of the open predicates. It is proven in\\n(Cadoli & Palopoli 1998) that the data complexity of\\ndeciding whether a query is not entailed by the pro-\\ngram is NP-complete which means that one can express\\nany CSP in this formalism. However, as the language\\ndoes not contain negation, one can not use directly the\\nmethodology discussed above for representing CSPs.\\n\\nIn (Cadoli et al. 1999) is defined the language np-\\n\\nspec which is an extension of datalog\\nCIRC and allows\\n\\na more natural representation of problems. The main\\ndifference is that it supports special meta-declarations,\\ncalled tailoring predicates, restricting the domain and\\nthe interpretation of the open predicates. The most\\nsimple one is of the form Subset(domain/n, pred)\\nwhich defines pred/n to be an open predicate and\\nits interpretation should be a subset of the interpre-\\ntation of the predicate domain/n. Another declara-\\ntion is Partition(domain/n, pred, m) which states that\\nthe predicate pred/n should be partitioned in m sets\\nwhich is, in fact, equivalent to a function with domain\\ndomain/n and a range 0..m− 1. The two other tailor-\\ning predicates are Permutation(domain/n, pred) and\\nIntFunc(domain/n, pred, min..max) which express re-\\nspectively that pred/n is a bijection from domain/n\\nto 0..domain/n − 1 and pred/n is a function with a\\nrange min..max. Another extension of np-spec is the\\nsupport of a predefined arithmetic functions and pred-\\nicates.\\n\\nThe formulation of the graph coloring problem in the\\nnp-spec language is given below. The input of the\\nprogram consists of facts node/1 and edge/2 describing\\nthe graph.\\n\\nPartition(node/1, color, 4).\\n\\n⇐ edge(V1, V2), color(V1, C1), color(V2, C2).\\n\\nExperiments\\n\\nThe Systems\\n\\nThe finite domain CLP package is the one provided with\\nSICStus version 3.7. Given the reputation of SICS-\\ntus and of finite domain CLP, one can assume it offers\\nstate of the art technology for CSP solving and it is a\\ngood yardstick to judge the performance of other sys-\\ntems. The abductive system ACLP (Kakas, Michael,\\n& Mourlas 2000) is a meta interpreter written in Pro-\\nlog, runs on Eclipse version 4.2 and makes use of its fi-\\nnite domain package. The abductive system SLDNFAC\\n(Denecker & Van Nuffelen 1999) is also a meta inter-\\npreter written in Prolog but runs on SICStus version\\n3.7 and makes use of the SICStus finite domain pack-\\nage. The model generator SEM (Zhang & Zhang 1995)\\nversion 1.7 is a fine tuned package written in C. smodels\\n(Niemelä & Simons 1996) version 2.25, the system for\\ncomputing stable models is implemented in C++ and\\nthe associated program used grounding is lparse version\\n0.99.48. All experiments have been done on the same\\nhardware, namely Pentium II.\\n\\nAll systems based on a finite domain constraint solver\\nused a labeling strategy which first selects variables\\nwith the smallest domain and then the ones which par-\\nticipate in the highest number of constraints6.\\n\\nN-Queens\\n\\nFigure 6 gives the running times for the different sys-\\ntems and figure 7 gives the number of backtracks. The\\ntwo abductive systems (ACLP and SLDNFAC) do not\\nintroduce any extra choice points compared to CLP and\\nhence are not plotted in figure 7. Not surprisingly, CLP\\ngives the best results. SLDNFAC is second best and,\\nalthough meta-interpretation overhead increases with\\nproblem size, deteriorates very slowly. SEM is third\\nbut runs out of memory for large problems (it needs\\nabout 120MB for 27 queens). This is probably caused\\nby a not very good techniques for grounding the prob-\\nlem and exploring the search space. The times given\\nfor SEM do not include time spend by the operating\\nsystem in managing the memory which becomes con-\\nsiderable for the larger instances of the problem. ACLP\\nperforms substantially worse than SLDNFAC and de-\\ngrades more quickly for the larger problems. It can\\nlikely be attributed to the more experimental nature\\nof the implementation. smodels performs very poorly\\non this problem, in particular when compared with its\\nperformance on the graph coloring problem. As can be\\nseen from figure 7 the main reason seems to be the large\\nnumber of backtracks it does.\\n\\nThe CLP consistency techniques seem to be much\\nless sensitive to the domains size, and this carries over\\nto the abductive systems which reduce the problem to\\na CLP problem and then use the CLP solver to search\\nfor the solution.\\n\\n6This strategy is sometimes abbreviated to ffc.\\n\\n\\n\\n0\\n\\n20\\n\\n40\\n\\n60\\n\\n80\\n\\n100\\n\\n120\\n\\n0 10 20 30 40 50 60\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nQueens\\n\\nN-Queens\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFigure 6: N-Queens: Running times\\n\\n0\\n\\n100\\n\\n200\\n\\n300\\n\\n400\\n\\n500\\n\\n600\\n\\n700\\n\\n800\\n\\n0 10 20 30 40 50 60\\n\\nB\\nac\\n\\nkt\\nra\\n\\nck\\ns\\n\\nQueens\\n\\nN-Queens\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFigure 7: N-Queens: Number of backtracks.\\n\\n\\n\\n0.01\\n\\n0.1\\n\\n1\\n\\n10\\n\\n100\\n\\n1000\\n\\n10000\\n\\n100000\\n\\n10 100 1000 10000 100000\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nEdges\\n\\nGraph Coloring\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFigure 8: Graph Coloring\\n\\nGraph Coloring\\n\\nWe used a graph generator program which is\\n', 'available from address http://web.cs.ualberta.ca/\\n~joe/Coloring/Generators/generate.html. We did\\nour experiments with planar undirected graphs which\\nare known to be 4-colorable. The graphs were generated\\nusing a 20% probability of assigning arcs. This results\\nin dense graphs with a stable behavior. For this prob-\\nlem, the domain of the solution variables (the number\\nof colors) remained the same and we have modified only\\nthe parameter of the problem (the number of vertices)\\nand consequently the number of constraints (arcs). Fig-\\nure 8 gives the results of solving the problem with the\\ndifferent systems. Both axes are plotted in a logarith-\\nmic scale. On the x-axis we have put the number of\\narcs (constraints) instead of the number of vertices.\\n\\nNot surprisingly, CLP is the fastest system. smod-\\nels is second best on this problem. We assume it is in\\npart because of the very concise formulation. Using the\\nso called technique of rules with exceptions (Niemelä\\n1999), the two rules needed to describe the space of\\ncandidate solutions also encode the constraint that the\\ncolor is a function of the vertex. Hence there is only\\none other rule, namely the constraint that two adja-\\ncent vertices must have a different color. The differ-\\nence with CLP is almost two orders of magnitude for\\nthe largest problems. SLDNFAC is slightly worse than\\nsmodels. Although meta-interpretation overhead tends\\nto increase with problems size, the difference with smod-\\nels grows very slowly. The model generator SEM de-\\nteriorates much faster and runs out of memory for the\\n\\nlarger problems. The fact that it grounds the whole the-\\nory is a likely explanation. The difference with smod-\\nels supports the claim that smodels has better tech-\\nniques for grounding. ACLP performs substantially\\nworse than SLDNFA and also deteriorates faster.\\n\\nConclusion\\n\\nThe examples which we have considered in this paper\\nare by no ways representative. However we think that\\nthey still show some interesting features and limitations\\nof the considered systems.\\n\\nConsistency algorithms are a very efficient way for\\nsolving CSP. Constraint logic programming allows this\\ntechniques to be integrated in a natural and clear way\\nto logic programs. However, as argued parameterized\\nCSPs can not be represented in a declarative way as\\nCLP(FD) programs. Using abduction or stable mod-\\nels as the basis for logic programming allows the prob-\\nlems to be represented in a more declarative way and\\nthe recent integration of abduction with CLP allows\\nthe same consistency techniques to be used for solving\\nthe problems. At the moment, such systems are imple-\\nmented as meta-interpreters on top of Prolog and they\\nessentially reduce a problem to the same set of con-\\nstraints (in many cases without backtracking) which\\nwould be produced by the corresponding constraint\\nlogic program. Our experiments suggest that the over-\\nhead of an abductive system is small and acceptable.\\nMoreover they can also solve other classes of problems\\nwhich require non-monotonic reasoning like planning\\nproblems. We also showed that there is a very close\\n\\n\\n\\nrelation between the semantics and the problem rep-\\nresentation of abduction and logic programming with\\nstable model semantics. The only difference is in the\\nreasoning techniques - abduction is usually done by\\na top-down proof procedure, while a stable model is\\nusually computed by a bottom-up procedure. How-\\never, the techniques used to compute a stable model\\nof a program do not seem to be so well suited for\\nsolving CSPs. One reason could be that they work\\non a ground propositional programs which tend to be\\nlarge and grow fast as the parameter of the problem in-\\ncreases. This suggests that an interesting area for fur-\\nther research would be a framework for computing sta-\\nble models of constraint logic programs with the help of\\nconstraint solving techniques. Some work has already\\nbeen done in this direction (Dix & Stolzenburg 1998;\\nEiter, Lu, & Subrahmanian 1997).\\n\\nWe argued earlier in the paper that the most nat-\\nural way for representing CSPs is with functions with\\nopen interpretation. Hence it would be interesting to\\nconsider extensions of the CLP scheme which directly\\nsupport such form of reasoning. Some work in this\\narea is done in (Bruynooghe, Pelov, & Denecker 1999;\\nHickey 1993).\\n\\nAcknowledgments.\\n\\nWe want to thank the members of the DTAI group\\nat K.U.Leuven and anonymous referees for their use-\\nful comments. This research is supported by the GOA\\nproject LP+. The third author is supported by FWO-\\nVlaanderen.\\n\\nReferences\\n\\nBruynooghe, M.; Pelov, N.; and Denecker, M. 1999.\\nTowards a more declarative language for solving fi-\\nnite domain problems. In Apt, K.; Kakas, A.; Mon-\\nfroy, E.; and Rossi, F., eds., Proceedings of the\\nERCIM/COMPULOG Workshop on Constraints. Pa-\\nphos, Cyprus: University of Cyprus.\\n\\nBruynooghe, M. 1991. Intelligent backtracking revis-\\nited. In Lassez, J.-L., and Plotkin, G., eds., Computa-\\ntional Logic - Essays in Honor of Alan Robinson. MIT\\nPress. ', '166–177.\\n\\nCadoli, M., and Palopoli, L. 1998. Circumscribing\\ndatalog: expressive power and complexity. Theoret-\\nical Computer Science 193(1–2):215–244.\\n\\nCadoli, M.; Palopoli, L.; Schaerf, A.; and Vasile, D.\\n1999. np-spec: An executable specification language\\nfor solving all problems in NP. In Gupta, G., ed.,\\n1st International Workshop on Practical Aspects of\\nDeclarative Languages, volume 1551 of Lecture Notes\\nin Computer Science, 16–30. San Antonio, Texas,\\nUSA: Springer-Verlag.\\n\\nCodognet, P., and Diaz, D. 1996. Compiling con-\\nstraints in clp(FD). Journal of Logic Programming\\n27(3):185–226.\\n\\nDenecker, M., and De Schreye, D. 1998. SLDNFA:\\nan abductive procedure for abductive logic programs.\\nJournal of Logic Programming 34(2):201–226.\\n\\nDenecker, M., and Van Nuffelen, B. 1999. Experi-\\nments for integration CLP and abduction. In Apt, K.;\\nKakas, A.; Monfroy, E.; and Rossi, F., eds., Proceed-\\nings of the 1999 ERCIM/COMPULOG Workshop on\\nConstraints. Paphos, Cyprus: University of Cyprus.\\n\\nDix, J., and Stolzenburg, F. 1998. A framework to\\nincorporate non-monotonic reasoning into constraint\\nlogic programming. Journal of Logic Programming\\n37(1–3):47–76.\\n\\nEiter, T.; Lu, J. J.; and Subrahmanian, V. S. 1997.\\nComputing non-ground representations of stable mod-\\nels. In Dix, J.; Furbach, U.; and Nerode, A., eds.,\\nProceedings of the Fourth International Conference on\\nLogic Programming and Non-Monotonic Reasoning,\\nvolume 1265 of Lecture Nortes in Computer Science,\\n198–217. Dagstuhl, Germany.\\n\\nEshghi, K., and Kowalski, R. 1989. Abduction com-\\npared with negation by failure. In Levi, G., and\\nMartelli, M., eds., Proceedings of the Sixth Interna-\\ntional Conference on Logic Programming, 234–254.\\nLisbon, Portugal.\\n\\nGelfond, M., and Lifschitz, V. 1988. The stable model\\nsemantics for logic programming. In Kowalski, R. A.,\\nand Bowen, K. A., eds., Logic Programming, Proceed-\\nings of the Fifth International Conference and Sympo-\\nsium, 1070–1080. Seattle, Washington: MIT Press.\\n\\nHickey, T. J. 1993. Functional constraints in CLP\\nlanguages. In Benhamou, F., and Colmerauer, A.,\\neds., Constraint Logic Programming: Selected Re-\\nsearch. MIT Press. 355–381.\\n\\nJaffar, J., and Maher, M. 1994. Constraint logic pro-\\ngramming: A survey. Journal of Logic Programming\\n19/20:503–581.\\n\\nKakas, A. C., and Mancarella, P. 1990. Generalized\\nstable models: A semantics for abduction. In Proceed-\\nings of the 9th ECAI, 385–391.\\n\\nKakas, A. C., and Michael, A. 1995. Integrating ab-\\nductive and constraint logic programming. In Sterling,\\nL., ed., Proceedings of the 12th International Confer-\\nence on Logic Programming, 399–413. Tokyo, Japan.\\n\\nKakas, A. C.; Kowalski, R.; and Toni, F. 1992. Abduc-\\ntive logic programming. Journal of Logic and Compu-\\ntation 2(6):719–770.\\n\\nKakas, A. C.; Michael, A.; and Mourlas, C.\\n2000. ACLP: Abductive constraint logic program-\\nming. Journal of Logic Programming. To appear.\\n\\nLloyd, J. W. 1987. Foundations of Logic Programming.\\nSpringer-Verlag, second edition.\\n\\nMackworth, A. K. 1992. The logic of constraint satis-\\nfaction. Journal of Artificial Intelligence 58(1–3):3–20.\\n\\nNiemelä, I., and Simons, P. 1996. Efficient implemen-\\ntation of the well-founded and stable model semantics.\\nIn Maher, M., ed., Logic Programming, Proceedings\\n\\n\\n\\nof the 1996 Joint International Conference and Sypo-\\nsium, 289–303. Bonn, Germany: MIT Press.\\n\\nNiemelä, I. 1999. Logic programs with stable model\\nsemantics as a constraint programming paradigm.\\nAnnals of Mathematics and Artificial Intelligence\\n25(3,4):241–273.\\n\\nSatoh, K., and Iwayama, N. 1991. Computing abduc-\\ntion by using the TMS. In Furukawa, K., ed., Proceed-\\nings of the Eighth International Conference on Logic\\nProgramming, 505–518. Paris, France.\\n\\nSlaney, J. 1995. FINDER version 3.0 - notes and\\nguides. Technical report, Centre for Information Sci-\\nence Research, Australian National University.\\n\\nTsang, E. 1993. Foundations of Constraint Satisfac-\\ntion. Computation in Cognitive Science. Academic\\nPress.\\n\\nVan Hentenryck, P.; Saraswat, V. A.; and Deville, Y.\\n1998. Design, implementation, and evaluation of the\\nconstraint language cc(FD). Journal of Logic Pro-\\ngramming 37(1–3):139–164.\\n\\nVan Hentenryck, P. 1989. Constraint Satisfaction in\\nLogic Programming. MIT Press.\\n\\nZhang, J., and Zhang, H. 1995. SEM: a system for\\nenumerating models. In Mellish, C. S., ed., Proceedings\\nof the Fourteenth International Joint Conference on\\nArtificial Intelligence, 298–303. San Mateo: Morgan\\nKaufmann.\\n\\n\\n'], 'name': '0003026v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0003/0003026v1.pdf', 'vectorized': None}, {'@search.score': 12.979384, '@search.rerankerScore': 2.886335849761963, '@search.captions': [{'text': 'CLP combines the advantages of two declarative  paradigms: logic programming (Prolog) and constraint solving. In logic program-  ming, problems are stated in a declarative way using rules to define relations (predi-  cates). Problems are solved using chronological backtrack search to explore choices.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNDAyLzA0MDIwMTl2MS5wZGY1', 'title': None, 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n04\\n\\n02\\n01\\n\\n9v\\n1 \\n\\n [\\ncs\\n\\n.A\\nI]\\n\\n  1\\n0 \\n\\nFe\\nb \\n\\n20\\n04\\n\\nUnder consideration for publication in Theory and Practice of Logic Programming 1\\n\\nThe Munich Rent Advisor: A Success for Logic\\n\\nProgramming on the Internet\\n\\nTHOM FRÜHWIRTH and SLIM ABDENNADHER\\n\\nLudwig-Maximilians-Universität München (LMU), Institut für Informatik,\\nOettingenstrasse 67, D-80538 Munich, Germany\\n\\n(e-mail: {Thom.Fruehwirth,Slim.Abdennadher}@informatik.uni-muenchen.de)\\n\\nAbstract\\n\\nMost cities in Germany regularly publish a booklet called the Mietspiegel. It basically\\ncontains a verbal description of an expert system. It allows the calculation of the estimated\\nfair rent for a flat. By hand, one may need a weekend to do so. With our computerized\\nversion, the Munich Rent Advisor, the user just fills in a form in a few minutes and the\\nrent is calculated immediately. We also extended the functionality and applicability of\\nthe Mietspiegel so that the user need not answer all questions on the form. The key to\\ncomputing with partial information using high-level programming was to use constraint\\nlogic programming.\\n\\nWe rely on the internet, and more specifically the World Wide Web, to provide this\\nservice to a broad user group, the citizens of Munich and the people who are planning to\\nmove to Munich. To process the answers from the questionnaire and return its result, we\\nwrote a small simple stable special-purpose web server directly in ECLiPSe. More than\\nten thousand people have used our service in the last three years. This article describes\\nthe experiences in implementing and using the Munich Rent Advisor. Our results suggests\\nthat logic programming with constraints can be an important ingredient in intelligent\\ninternet systems.\\n\\n1 Introduction\\n\\nIn winter 1995/1996 we wanted to develop a prototypical intelligent internet ap-\\n\\nplication illustrating the power of using logic programming with constraints (CLP)\\n\\n(Wallace, 1996; Frühwirth and Abdennadher, 1997b; Marriott and Stuckey, 1998)\\n\\nas an implementation language. CLP combines the advantages of two declarative\\n\\nparadigms: logic programming (Prolog) and constraint solving. In logic program-\\n\\nming, problems are stated in a declarative way using rules to define relations (predi-\\n\\ncates). Problems are solved using chronological backtrack search to explore choices.\\n\\nIn constraint solving, efficient special-purpose algorithms are employed to solve sub-\\n\\nproblems involving distinguished relations referred to as constraints, which can be\\n\\nconsidered as pieces of partial information.\\n\\nThe Munich Rent Advisor (MRA) (Frühwirth and Abdennadher, 1996; Frühwirth and Abdennadher, 1997a)\\n\\nis the electronic version of the Mietspiegel (MS) for the city of Munich (Alles and Guder, 1994).\\n\\nSuch Mietspiegel are published every four years by most German cities. They are\\n\\nbasically a written description of an expert system for estimating the maximum\\n\\nhttp://arXiv.org/abs/cs/0402019v1\\n\\n\\n2 T. Frühwirth and S. Abdennadher\\n\\nfair rent for a flat. These estimates are legally binding, the results can be used in\\n\\ncourt cases.\\n\\nDoing it by hand, one may need a weekend to calculate the rent. Usually, the\\n\\ncalculation is performed with a pen and pocket calculator in about half an hour\\n\\nby an expert from the City of Munich or from one of the renter’s associations. The\\n\\nMRA brought the advising time down to the few minutes that the user needs to\\n\\nfill in the form – calculation time is negligible. The calculations are based on size,\\n\\nage, and location of the flat and a series of detailed questions about the flat and\\n\\nthe house it is in. Some of these questions are hard to answer. However, in order to\\n\\nbe able to calculate the rent estimate by hand, all questions must be answered.\\n\\nThe MRA extended the functionality and applicability of the MS so that the\\n\\nuser need not answer all questions of the form. The user may not want to give\\n\\ninformation away, or he does not care about the question or know the answer. He\\n\\nmay even submit a blank form. The MRA will give an estimate of the rent as an\\n\\ninterval as tight as possible. So the MRA now can be used not only for calculating\\n\\nthe estimated fair rent of a flat but also for helping house hunters which have a\\n\\nvague idea of the kind of the flat they plan to rent and are interested in the rent\\n\\nthey have to meet.\\n\\nOur approach was to first implement the tables, rules, and formulas of the paper\\n\\nversion with high-level declarative programming in ECLiPSe Prolog (Brisset et. al., 1995),\\n\\nas if the provided data was precise. Because of the declarativity of Prolog it was\\n\\neasy to express the contents of the MS. Then we added constraints to capture the\\n\\nimprecision due to the statistical method and incompleteness in case the user gives\\n\\nno or partial answers. Finally, we considered the formulas of the rent calculation as\\n\\nconstraints that refine the rent estimate by propagation from the constrained input\\n\\nvariables. ', 'The constraints are handled by a constraint solver written in Constraint\\n\\nHandling Rules (Frühwirth, 1998).\\n\\nThis implementation approach illustrates the ease of high-level modeling that\\n\\nis possible with constraints logic programming (Wallace, 1996) and that supports\\n\\nmaintenance and modification of the resulting program. This is crucial, since every\\n\\ncity and every new version of the Mietspiegel comes with different tables and rules.\\n\\nThe Munich Rent Advisor (MRA) is accessible through the internet, more specif-\\n\\nically through World Wide Web (WWW). We chose not to rely on advanced devel-\\n\\nopments like Java applets or frames so that the service is accessible for any internet\\n\\nuser. To process the answers from the questionnaire and return its result, we wrote\\n\\na simple stable special-purpose web server directly in ECLiPSe using its socket\\n\\ninterface for internet communication.\\n\\nIt took about two man weeks to write the calculation part and one week to debug\\n\\nit. The internet user interface took one man month. We think that the coding of the\\n\\ncalculation part would have dominated the implementation effort if a conventional\\n\\nprogramming language had been used.\\n\\nIn the last three years, more than ten thousand people have used our MRA service\\n\\non the World Wide Web (WWW). It is one of the winners of the best application\\n\\nprize of the JFPLC’96 conference in Clermont-Ferrand, France, and was presented\\n\\n\\n\\nThe Munich Rent Advisor 3\\n\\nat the Systems’97 Computer Show in Munich. This article is an extended and\\n\\nsubstantially revised version of the paper (Frühwirth and Abdennadher, 1996).\\n\\nThe paper is organized as follows. The next section introduces the Mietspiegel.\\n\\nSection 3 describes the World Wide Web Front End. Section 4 presents the Web\\n\\nServer in ECLiPSe. Section 5 presents the implementation of the calculation part\\n\\nof the Munich Rent Advisor. Section 6 explains that the MRA can be modified and\\n\\nadapted within minutes by cloning. Section 7 presents some user statistics derived\\n\\nfrom randomly logged requests. Finally, we conclude with a summary and directions\\n\\nfor future work.\\n\\n2 The Mietspiegel\\n\\nThe Mietspiegel (MS) is published every four years by the housing group of the de-\\n\\npartment for social issues of the city government of Munich after negotiations with\\n\\nrenter’s and landlord’s associations and lawyers. The Infratest Sozialforschung Insti-\\n\\ntute in Munich together with the Institute for Housing and Environment in Darm-\\n\\nstadt conducted about 7000 interviews to obtain the sample data which was then\\n\\nused to build the statistical model at the department of statistics of the Ludwig-\\n\\nMaximilians University in Munich (Alles and Guder, 1994).\\n\\nFor the MS, the complex data sets derived from the interview have been reduced\\n\\nand simplified so that an average person could calculate the estimated rent. As we\\n\\nhave pointed out in the introduction, the MS calculation is still too complicated to\\n\\nbe used by everybody. In addition, the paper version ignores the inherent impre-\\n\\ncision of the statistical model. The imprecision is basically the standard deviation\\n\\nobtained in the statistical model. Therefore it is higher for rare kinds of flats (very\\n\\nsmall, big or very old, new etc.). On average, the imprecision deviation amounts to\\n\\nabout ±10% of the estimated rent.\\n\\nThe scheme for calculating the rent estimate is roughly as follows:\\n\\nEstimated Rent = Size ∗ Basic Rent per SquareMeter\\n\\n∗ (Sum of Deviations as Percentage + 100) ∗ 0, 01\\n\\n∗ (Imprecision Deviation Percentage + 100) ∗ 0, 01\\n\\n+ Fixed Costs\\n\\nThe calculation starts with the average rent per square meter taken from a table\\n\\nwith about 200 entries. The deviations from the average rent are computed from\\n\\nthe answers regarding the size, location, features of the flat, as well as age and state\\n\\nof the house. There are six yes-no questions about features of the house concerning\\n\\ne.g. number of floors, optical impression, lift, etc., and 13 yes-no questions about\\n\\nfeatures of the flat concerning e.g. central heating, separate shower, dish-washer,\\n\\netc. The answers to these questions combined with the age of the house yield the\\n\\ndeviations from the average rent. The overall deviation may be up to ±60%.\\n\\nFinally one has to add fixed costs, such as community taxes, fees for garbage\\n\\ncollection, house cleaning, or cable TV. Part of them may be included in the rent,\\n\\npart of them not, part of them may not apply. Usually, the user will just ignore this\\n\\n\\n\\n4 T. Frühwirth and S. Abdennadher\\n\\nsection because of too much detail. Thus a range from minimal to maximal fixed\\n\\ncosts will be added to the estimated rent.\\n\\n3 The World Wide Web Front End\\n\\nIn our computerized version, The Munich Rent Advisor (MRA), we rely on the\\n\\ninternet, and more specifically the World Wide Web (WWW). We programmed in\\n\\nHTML version 3.0, because it is considered the current standard. We chose not to\\n\\nrely on advanced developments like Java applets or frames so that the service is\\n\\n', 'accessible for any internet user.\\n\\nFig. 1. Part of the Form\\n\\nFor users who are not familiar with the Mietspiegel (MS) we have created several\\n\\nweb pages of background information in German. This is basically plain text with\\n\\nthe possibility to go backward, upward and forward in the text. Furthermore, there\\n\\nare the additional possibilities a hypertext document provides: cross-references,\\n\\nlinks to the city of Munich and renter’s associations, and to the institutions involved\\n\\nin preparing the MS.\\n\\nAll relevant information for calculating an estimated rent will be collected in the\\n\\nquestionnaire. MRA users need to fill in only what they know and what they care\\n\\nabout. All answers are optional. There are only four questions requiring numeric\\n\\ninputs, where it is possible to give a range (editable fields) and one question about\\n\\nlocation requiring a search in a list of districts (pull-down menu). The remaining\\n\\nquestions are multiple choices, where the only possible answers are Yes, No and, in\\n\\naddition, Don’t know/care (buttons). Optional detailed questions are provided to\\n\\ncalculate the fixed costs where numeric input can be given. This form is divided in\\n\\n I. Basic Questions What is the size of your flat (in squaremeters)? at least 76 m2 not more than 85 m2 How many rooms has your flat? at least 3 room(s) not more than 4. room(s) In which year was your house built? between 1975 and 1978 II. District Please choose the district you live in from the list right next. Bogenhausen III. Questions about the House Do you live in the back premises? Yes > No \" Don\\'t know Would you say your house looks good? + Yes - No Don\\'t know E.g. old-fashioned windows, fancy balconies. \\n\\n\\n\\nThe Munich Rent Advisor 5\\n\\nfour sections, basic questions, questions about the house, questions about the flat\\n\\nitself (Figure 1), and questions about the fixed costs of the flat. These questions\\n\\nwere sorted by importance of the answer to estimate the rent. Questions at the\\n\\nbeginning of a section have more influence on the result than questions at the end\\n\\nof a section.\\n\\nTo fit the form on one web page we had to create a long document that con-\\n\\nsequently needs a lot of scrolling. We have experimented with internal anchors\\n\\nand links but users found this too complicated. Furthermore, collecting data from\\n\\ndifferent pages in the server would have been too error-prone:\\n\\n• The same page could be sent to the server more than once.\\n\\n• Some forms might not be sent at all.\\n\\n• The server has to wait for the missing forms and thus has to buffer the data.\\n\\n4 ECLiPSe as Web Server\\n\\nTo process the answers from the questionnaire and return its result, we wrote a\\n\\nsimple stable special-purpose web server directly in ECLiPSe. This is opposed to\\n\\nthe standard approach where for each user request a script is executed (usually\\n\\nwritten in Perl) via the CGI interface (or using the Unix inetd service). Since start-\\n\\ning up ECLiPSe (and ECLiPSe saved states) takes up to a second and considerable\\n\\nmemory, it would not have been feasible to start a new ECLiPSe process with each\\n\\nuser request. We also did not want to struggle with CGI scripts – but this problem\\n\\nseems to be solved in the meantime (Naish, 1999; Cabeza and Hermenegildo, 1996).\\n\\nIt was more natural that ECLiPSe is constantly running and listening to the port\\n\\nwaiting for the next user request. Moreover, this avoids the overhead of using stan-\\n\\ndard Perl scripts to communicate the data between a standard web server and\\n\\nthe ECLiPSe process. The disadvantage is that the server is not concurrent (multi-\\n\\nuser). However, since it takes considerably less than a second to serve a user request,\\n\\nwe did not encounter problems in practice. Moreover, the server proved to be quite\\n\\nrobust. Clearly writing a server is only feasible for special cases.\\n\\nIn what follows, we assume some familiarity with Prolog or similar languages with\\n\\nconstraints (Frühwirth and Abdennadher, 1997b; Marriott and Stuckey, 1998). ECLiPSe 3.5.x\\n\\noffers a number of built-in predicates for TCP/IP based communication on the in-\\n\\nternet. The complete socket library (Internet Protocol Suite) as used under SUN-OS\\n\\nis available. Therefore the basic code of a web server in ECLiPSe is just:\\n\\n% top level\\n\\ngo :-\\n\\nwriteln(’Starting MRA Server’),\\n\\n% connecting to the internet via socket library\\n\\nsocket(internet,stream,Socket),\\n\\nbind(Socket, _Hostname/4322), % 4322 is a port number\\n\\nlisten(Socket,1),\\n\\nloop(Socket),\\n\\nclose(Socket).\\n\\n\\n\\n6 T. Frühwirth and S. Abdennadher\\n\\n% get user requests\\n\\nloop(S) :-\\n\\naccept(S,_,IOStream), % get the request\\n\\nprocess(IOStream), % process the request\\n\\nclose(IOStream), % done - served the request\\n\\nloop(S). % go for next request\\n\\nWhen the user presses the submit button of the form, the connection will be\\n\\nestablished (accept) and the data will be sent to the server. During calculation the\\n\\nconnection is in stand-by mode until the result is sent back on the same stream\\n\\n(IOStream).\\n\\n', \"The processing of a user request amounts to the following code (which is similar\\n\\nto what one finds with other approaches like (Naish, 1999)):\\n\\nprocess(IOStream) :-\\n\\nreadin_request(IOStream,RequestString),\\n\\nparse(RequestString,InputVarList),\\n\\ncompute(InputVarList,OutputVarList)\\n\\n->\\n\\nsendback_result(IOStream,OutputVarList)\\n\\n;\\n\\nsendback_error(IOStream).\\n\\nIn the Prolog predicate readin request the data is received as an HTML doc-\\n\\nument page (the RequestString) consisting of a header and a body (similar to an\\n\\ne-mail message):\\n\\nPOST / HTTP/1.0\\n\\n...\\n\\nContent-type: application/x-www-form-urlencoded\\n\\nContent-length: 654\\n\\nLanguage=English&M2_min=22&M2_max=160&ZI_min=1&ZI_max=9&\\n\\nBJ_min=1800&BJ_max=1992&District=Schwabing&BackPremises=%3F&\\n\\n...\\n\\nThe message body contains the answers of the user as fieldname=value entries\\n\\nseparated by &. To make the server robust, there are timeouts and readin request\\n\\nwill fail as soon as the received message does not have the expected format. There-\\n\\nfore it is almost impossible to break the server.\\n\\nThe difficulty in parsing (predicate parse) is that different browsers may use\\n\\ndifferent syntactic conventions and different encodings for characters. Using Definite\\n\\nClause Grammars (DCGs), that are available in Prolog, greatly simplified this task.\\n\\nThe field names of the form are associated with Prolog variables which will be used\\n\\nto constrain the input variables:\\n\\nLanguage=’English’, M2_min=22, M2_max=160,...\\n\\nDistrict=’Schwabing’, BackPremises=’?’,...\\n\\n\\n\\nThe Munich Rent Advisor 7\\n\\nThen with the predicate compute the estimated rent is computed from the con-\\n\\nstrained input variables (see next section). This takes far less than a second. This\\n\\nmeans that the Web user gets the reply as fast as loading a medium-sized text-only\\n\\nweb page and therefore the pure calculation time is negligible.\\n\\nFinally, from the OutputVarList containing the constrained output variables\\n\\n(the main one being the estimated rent), a web page is assembled and sent back to\\n\\nthe user (sendback result) (Figure 2).\\n\\nFig. 2. Partial result of a sample query\\n\\nIf any failure occurs during the processing (e.g., connection times out, parsing\\n\\nnot possible due to wrong user input in editable fields, computation unexpectedly\\n\\nfails), a generic error message with some hints about typical errors is sent back to\\n\\nthe user (sendback error). Of course, this primitive error handling is only sufficient\\n\\nfor a prototype. Ironically, the success of the MRA means that there is not enough\\n\\npressure to improve on it.\\n\\n Netscape: Results Munich Rent Advisor File Edit View Go Bookmarks Options Directory Window Help Back Forward Home Reload Images Open Print Find The Calculation Derived the Following Result: Type Result in DM Rent between 877.73 and 1086.15 Rent without 'Nebenkosten' between 581.46 and 768.08 'Nebenkosten' between 296.26 and 318.06 Even if you have answered all questions, there will still be some imprecission due to the statistical model used. We used the following information you gave us: Basic Information Your Input Size of the flat in squaremeters between 65 and 70 Year, in which the house was built between 1950 and 1960 Number of rooms between 2 and 3 \\n\\n\\n\\n8 T. Frühwirth and S. Abdennadher\\n\\n5 Implementing the Rent Calculation\\n\\nOur approach was first to implement the tables, rules, and formulas of the Miet-\\n\\nspiegel in ECLiPSe Prolog (Brisset et. al., 1995), as if the provided data was precise\\n\\nand completely known. Because of the declarativity of Prolog it was easy to express\\n\\nthe contents of the MS. Then we added interval constraints to capture the impreci-\\n\\nsion due to the statistical approach and incompleteness due to partial user answers.\\n\\nFinally, we considered the formulas of the rent calculation as constraints that refine\\n\\nthe rent estimate by propagation from the constraints on the input variables which\\n\\nare constrained due to partial answers of the user.\\n\\nWhile it would have been difficult to achieve exactly the required constraint\\n\\npropagation with a given, built-in black-box constraints solver, it was relatively\\n\\nstraightforward using Constraint Handling Rules (CHR) (Frühwirth, 1998). It suf-\\n\\nficed to modify an existing constraint solver written in CHR that is part of the CHR\\n\\nECLiPSe library. The solver takes just a few pages of code as will be exemplified\\n\\nin the following.\\n\\n5.1 Interval Arithmetic\\n\\nIn the MRA, dealing with imprecise numerical information involves non-linear arith-\\n\\nmetic computations with intervals (Cleary, 1987; Davis, 1987; Benhamou, 1995).\\n\\nAll variables are initialized to their allowed range (e.g., the flats covered by the\\n\\nMS are between 22 and 160 square meters, i.e. Size::22:160). The fieldname\\n\\nvariables are used to constrain the input variables of the MS:\\n\\nFlatSize::M2_min:M2_max\\n\\nWe could have used a CLP language with off-the-shelf interval arithmetic as e.g.\\n\\navailable in CLP(BNR) (Benhamou, 1995) to express the required interval con-\\n\\nstraints. \", 'However, it would have been quite difficult to tailor the amount and di-\\n\\nrection of constraint propagation to the needs of the application at hand. Without\\n\\nsuch tailoring, the performance suffers, since the general algorithms have higher\\n\\ncomplexity than the simple forward propagation that is all that we need. In our\\n\\ncase it sufficed to modify an existing constraint solver written in CHR that is part\\n\\nof the CHR library of ECLiPSe.\\n\\nCHR is a high-level language extension to write constraint systems. Basically,\\n\\nCHR consists of multi-headed guarded rules. There are two kinds of rules: Simplifi-\\n\\ncation rules rewrite constraints to simpler constraints while preserving logical equiv-\\n\\nalence (e.g., X>Y,Y>X <=> false). Propagation rules add new constraints which are\\n\\nlogically redundant but may cause further simplification (e.g., X>Y,Y>Z ==> X>Z).\\n\\nRepeatedly applying the rules incrementally solves constraints (e.g., A>B,B>C,C>A\\n\\nleads to false). With multiple heads and propagation rules, CHR provides two\\n\\nfeatures which are essential for implementing non-trivial constraint reasoning.\\n\\nThe original CHR solver for finite domains already includes the basic interval\\n\\nconstraint that restricts a variable to be in an interval between the numbers Max and\\n\\nMin, written X::Min:Max, and simple equations between two variables or numbers,\\n\\ne.g. X=Y, X<Y, X=<Y,... The solver contains rules like:\\n\\n\\n\\nThe Munich Rent Advisor 9\\n\\nX::A:A <=> X=A.\\n\\nX::A:B, X::C:D <=> Min is max(A,C), Max is min(B,D), X::Min:Max.\\n\\nX=<Y, X::A:B, Y::C:D ==> X::A:D, Y::A:D.\\n\\nA rule of the form Head <=> Guard | Body (where the guard is optional) is used\\n\\nto simplify the head constraints into the body, provided the guard is satisfied. Sim-\\n\\nilarly, a rule of the form Head ==> Guard | Body is used to propagate from the\\n\\nhead by adding the body. The first rule removes a domain that consists only of\\n\\na single value and unifies its variable with that value. The second rule intersects\\n\\ntwo intervals for the same variable, thus tightening the interval. The interval con-\\n\\nstraints X::A:B and X::C:D are simplified into (replaced by) the single constraint\\n\\nX::max(A,C):min(B,D). The last rule propagates new intervals for the variables X\\n\\nand Y when X=<Y. The constraints from the left hand side of the rule are kept in\\n\\nthis case, the constraints from the right hand side are added. For example, from the\\n\\nconstraints U::2:3, V::1:2, U=<V we get U=2,V=2 by applying the above three\\n\\nrules from bottom to top.\\n\\nWe extended this solver by allowing linear and non-linear equations reducing to\\n\\nthe normal forms\\n\\nc0 + c1 ∗ x1 + c2 ∗ x2 + ... + cn ∗ xn = y and c ∗ x1 ∗ x2 ∗ ... ∗ xn = y\\n\\nwhere the ci and c are numbers and the xi and y are different variables and n ≥ 0.\\n\\nThese equations are needed to express the formulas appearing in the MS.\\n\\nThe implementation for linear equations is straightforward. In the solver, the\\n\\nequation c0 + c1 ∗ x1 + c2 ∗ x2 + ... + cn ∗ xn = y is represented by the constraint\\n\\nsum(C0:C0+C1*X1+C2*X2+...+Cn*Xn+0=Y). The constant c0 is replaced by the in-\\n\\nterval C0:C0 and the summand 0 is introduced to end the summation. A constraint\\n\\nof the form sum(Min:Max+Rest=Y) means that the interval Min:Max plus the sum\\n\\nof the polynomial Rest gives an interval for the variable Y. The rules below define\\n\\nforward propagation: From the intervals associated with the variables Xi in the\\n\\npolynomial they compute an interval for Y:\\n\\nsum(Min:Max+C*X+Rest=Y), X::A:B ==>\\n\\nNewMin is Min + min(C*A,C*B),\\n\\nNewMax is Max + max(C*A,C*B),\\n\\nsum(NewMin:NewMax+Rest=Y).\\n\\nsum(Min:Max+0=Y) <=> Y::Min:Max.\\n\\nThe first rule reads: If we have the constraint sum(Min:Max+C*X+Rest=Y) and we\\n\\nknow that the variable X is between A and B by constraint X::A:B, then C*X is\\n\\nbetween min(C*A,C*B) and max(C*A,C*B). We can remove C*X from the sum and\\n\\nreplace it by this interval. Added to the already existing interval Min:Max this en-\\n\\nables us to conclude (propagate) the new constraint sum(NewMin:NewMax+Rest=Y).\\n\\n\\n\\n10 T. Frühwirth and S. Abdennadher\\n\\nAfter we have eliminated all variables this way, we are left with sum(Min:Max+0=Y),\\n\\nwhich means Y::Min:Max, as is expressed by the second rule.\\n\\nSince we do not need backpropagation in our application, these two rules suffice.\\n\\nThe implementation for non-linear equations is analogous. c ∗ x1 ∗ x2 ∗ ... ∗ xn = y\\n\\nis represented by mlt(C:C*X1*X2*...*Xn*1=Y).\\n\\nmlt(Min:Max*X*Rest=Y), X::A:B ==>\\n\\nNewMin is min(Min*A,Max*B,Max*A,Min*B),\\n\\nNewMax is max(Min*A,Max*B,Max*A,Min*B),\\n\\nmlt(NewMin:NewMax*Rest=Y).\\n\\nmlt(Min:Max*1=Y) <=> Y::Min:Max.\\n\\n5.2 Deductive Database for Tables\\n\\nThe Mietspiegel contains several tables that relate features of the flat to changes\\n\\nof the estimated rent. For example, the rent depends on the age of the flat and its\\n\\nnumber of rooms. The table to describe this function as found in the MS is:\\n\\nYear of construction 1 room 2–3 rooms ≥ 4 rooms\\n...\\n\\n...\\n...\\n\\n...\\n\\n1966–1977 -3.5 -2.0 -3.0\\n\\n1978–1983 2.0 10.0 3.0\\n\\n', '1984–1986 6.0 18.0 7.0\\n...\\n\\n...\\n...\\n\\n...\\n\\nThe implementation uses a simple constraint database (Kuper and Wallace, 1995)\\n\\nwith intervals. In Prolog, the table is easily represented declaratively as a list of facts\\n\\nof the form table(YearInterval,RoomsInterval,Percentage). Such a shorthand\\n\\nmaintains readability and is compact:\\n\\n...\\n\\ntable(1966:1977, 1:1, -3.5).\\n\\ntable(1966:1977, 2:3, -2.0).\\n\\n...\\n\\ntable(1984:1986, 2:3, 18.0).\\n\\ntable(1984:1986, 4:9, 7.0).\\n\\n...\\n\\nThe table facts are translated at compile time by macro expansion into rules to\\n\\nmake the interval constraints explicit\\n\\n...\\n\\ntable(Year, Rooms, -3.5) :-\\n\\nYear::1966:1977, Rooms::1:1.\\n\\ntable(Year, Rooms, -2.0) :-\\n\\n\\n\\nThe Munich Rent Advisor 11\\n\\nYear::1966:1977, Rooms::2:3.\\n\\n...\\n\\nThe Prolog query Year=1980, Rooms=2, table(Year,Rooms,Percentage), for ex-\\n\\nample, yields as an answer Percentage=10.0.\\n\\nIn the general case, when we use the tables with constrained variables in the\\n\\nqueries for Year and Rooms, we are only interested in the smallest interval that con-\\n\\ntains all the answers, not in all answers as such. For example, with the constraints\\n\\nYear::1980:1985, Rooms::1:3we want the single answer Percentage::2.0:18.0\\n\\nand not the multiple answers Percentage=2.0, Percentage=10.0,...This means\\n\\nthat we have to collect all the answers and compute minima and maxima of the\\n\\npercentages returned to find the smallest interval that contains all answers. This\\n\\nmeta-programming task can be easily accomplished by a built-in predicate of Pro-\\n\\nlog, setof(Variable,Query,List) that collects all bindings of the variable in all\\n\\nthe answers to the query in a sorted list:\\n\\nsetof(Percentage,Year^Rooms^table(Year,Rooms,Percentage),List),\\n\\nfirst(List,Min), last(List,Max),\\n\\nPercentage::Min:Max.\\n\\nA similar procedure was used for all tables. The running time is satisfactory for\\n\\ntables with a few hundred constrained tuples.\\n\\n6 Cloning\\n\\nAn advantage of internet applications using Prolog with constraints is that they\\n\\ncan be modified and adapted within minutes, since the MRA can be cloned: Any\\n\\npart of the form used as the interface to this application may be reused in another\\n\\nweb page simply by cut-and-paste.\\n\\nOne may drop questions, one may set default values, one may fix the answer\\n\\nto questions and hide them from the user in order to specialize the application.\\n\\nFurthermore, everything on the web page can be rearranged at will, only the form\\n\\ndeclaration has to be kept as is.\\n\\nThe resulting web page will still work, i.e. produce a result page when submitted,\\n\\nsince the missing information is dealt with by constraints. For example, the minimal\\n\\nclone is simply:\\n\\n<HTML>\\n\\n<HEAD>\\n\\n<TITLE>Minimal Clone</TITLE>\\n\\n</HEAD>\\n\\n<BODY>\\n\\n<FORM METHOD=\"POST\"\\n\\nACTION=\"\\\\protect\\\\vrule width0pt\\\\protect\\\\href{http://sol.pst.informatik.uni-muenchen.de\\n\\n<INPUT TYPE=\"submit\" VALUE=\"Submit\">\\n\\n</BODY>\\n\\n</HTML>\\n\\n\\n\\n12 T. Frühwirth and S. Abdennadher\\n\\nThe form just consists of a submit button. When pressed, it will just return the\\n\\nsmallest and highest allowed rent of flats up to 160m2 in Munich.\\n\\nA more realistic clone simplifies the interface to the basic questions as can be\\n\\nseen on top of Figure 1.\\n\\n...\\n\\n<BODY>\\n\\n<FORM METHOD=\"POST\"\\n\\nACTION=\"\\\\protect\\\\vrule width0pt\\\\protect\\\\href{http://sol.pst.informatik.uni-muenchen.de\\n\\n<H1>Munich Rent Advisor - Clone</H1>\\n\\nWhat is the size of your flat (in square meters)?<BR>\\n\\nAt least <INPUT MAXLENGTH=3 SIZE=3 NAME=\"M2_low\" Value=\"22\"> ...\\n\\n<P>\\n\\nHow many rooms has your flat?<BR>\\n\\nAt least <INPUT MAXLENGTH=1 SIZE=1 NAME=\"ZI_low\" Value=\"1\"> ...\\n\\n<P>\\n\\nIn which year was your house built?<BR>\\n\\nBetween <INPUT MAXLENGTH=4 SIZE=4 NAME=\"BJ_low\" VALUE=\"1800\"> ...\\n\\n<P>\\n\\n<INPUT TYPE=\"submit\" VALUE=\"Submit\">\\n\\n</BODY>\\n\\n</HTML>\\n\\n7 User Statistics\\n\\nWe have logged about 7200 headers of user requests to the MRA for almost two\\n\\nyears in the three years since February 1996, when the MRA went online. On\\n\\naverage, there are 10 requests per day. Our findings can be summarized as follows\\n\\n(the figures related to the findings in this section can be found at the end of the\\n\\narticle).\\n\\nCorrect Requests (see Fig. 3).\\n\\n• From the 7188 requests received, only 1% can be attributed to trying to access\\n\\nthe MRA web server improperly, without using the form.\\n\\n• Due to timeout, 9% of the requests were cancelled.\\n\\n• Due to syntax errors (typos, using floats instead of integers, wrong intervals),\\n\\nanother 12% were cancelled.\\n\\n• Thus, only 4 in 5 requests (78%) were in time, correct and lead to a rent\\n\\nestimate.\\n\\nThe large number of syntax errors can be attributed to users that did not read the\\n\\ninstructions carefully or had typing problems. Most of these errors can be caught\\n\\nbefore the form is sent to the server. We have implemented such a version of the\\n\\nMRA in a recent student project (Herzog, 1998): JavaScript is used to provide help\\n\\ntexts and syntax checks for each input field as soon as the user enters something.\\n\\n\\n\\nThe Munich Rent Advisor 13\\n\\n', 'Less than 2% of the requests did not come from the original form but from a\\n\\nversion that was stored locally with the user. The German version of the MRA was\\n\\nused almost all the time, the English version accounts only for 6% of the requests.\\n\\nUser Origin. If the user establishes a connection to a web server by sending\\n\\nthe contents of a form as a request, he usually gives away the symbolic internet\\n\\naddress of his machine, e.g. borabora.pms.informatik.uni-muenchen.de. In Fig.\\n\\n3, header field Accept-from, we give some statistics about the user origin. In the\\n\\nfigure, each of the addresses subsumed in entries named Other have considerably\\n\\nless than 1% contribution each.\\n\\n• Only 1 in 7 requests were anonymous.\\n\\n• 2 in 3 requests came from German domains (.de).\\n\\n• In Germany, not surprisingly, most requests came form local, Munich uni-\\n\\nversities (Uni) and large IT and car companies (Com). These two groups\\n\\ncontribute each about one fifth to the overall requests. Many requests also\\n\\ncame from users of large internet providers (Pro) (7%). Together, these three\\n\\ngroups of frequent requests from the same domain make up about half of all\\n\\nrequests.\\n\\nUser Software. Each browser also tells its name and the operating system it\\n\\nis running on in the header (see Fig. 3, User-Agent). The figure shows that Unix-\\n\\nbased operating systems make up for one third. The majority goes to Windows\\n\\n(slightly over 60%), and there are some other operating systems (less than 5%).\\n\\nBoth Netscape and Explorer browsers call themselves Mozilla, however the latter\\n\\nadds the qualifier Compatible. Netscape dominates on both Unix- and Windows-\\n\\nbased machines, overall 80%. Explorer has 11%, the rest (9%) is shared by other\\n\\nbrowsers.\\n\\nAccess Times (see Fig. 4). We analyzed user access times per month, weekday,\\n\\nand hour. Since we did not cover all months in all years logged, we had to extrapolate\\n\\nsome figures to get figures for complete months, resulting in an overhead of about\\n\\n10% over the actual number of requests (7890 instead of 7073).\\n\\n• The monthly figures are somewhat irregular, with a low in May that we cannot\\n\\nexplain. The high in November (and December) maybe comes from the fact\\n\\nthat rents are usually raised at the end of the year. The high in February\\n\\ndefinitely comes from 1996, when the MRA was introduced and featured in\\n\\nthe media.\\n\\n• The weekday figures strictly decrease from Monday to Sunday, with little\\n\\nactivity on the weekend. Almost a quarter of all requests happen on Monday,\\n\\nonly 7% on Saturday.\\n\\n• The figures for the hours show that the MRA is used mostly during working\\n\\ntime (in the 6 hours from 11 am to 5 pm), mainly around lunch break. Not\\n\\nsurprisingly, the figures for the 6 hours from 1 am to 7 am are extremely low\\n\\n(about 2% of all requests).\\n\\n\\n\\n14 T. Frühwirth and S. Abdennadher\\n\\n8 Conclusions\\n\\nThe MRA indicates that logic programming with constraints can be essential for\\n\\nintelligent internet applications for several reasons.\\n\\n• Logic programming languages have declarative rules and powerful deductive\\n\\ndatabase facilities already built-in, that are needed to encode expert knowl-\\n\\nedge.\\n\\n• Such a high-level state-of-the-art approach also means that a program can\\n\\nbe easily written, maintained, and modified (Wallace, 1996). For the MRA,\\n\\nease of modification is crucial, since every city and every new version of the\\n\\nMietspiegel comes with different tables and rules.\\n\\n• Constraint logic programming languages can deal with imprecise knowledge\\n\\nand partial information that characterizes communication on the internet in\\n\\nan elegant, correct, and efficient way (Frühwirth et. al., 1997).\\n\\nOne direction for future work is to integrate integrity constraints (e.g., if a house is\\n\\nbuilt after 1949, its flats have a bathroom) that have been directly derived from the\\n\\nstatistical raw data of the Mietspiegel. The other direction is to create electronic\\n\\nversions of the Mietspiegel for more cities. Many of the now 500 Mietspiegel of\\n\\nGermany are currently available as tables and text on the internet. To facilitate\\n\\ntheir processing we already have developed a tool that can automatically generate\\n\\nforms, with help texts and syntax checks built in, together with their handlers\\n\\n(Herzog, 1998).\\n\\nThe Munich Rent Advisor Home Page is at\\n\\nhttp://www.informatik.uni-muenchen.de/∼fruehwir/miet-demo.html\\n\\nAcknowledgements. We would like to thank Peter Blenninger who imple-\\n\\nmented a first prototype of the MRA. We are also grateful to the City of Munich\\n\\nfor letting us use their Mietspiegel data and to Norbert Eisinger and Tim Geisler\\n\\nfor comments and proof-reading.\\n\\nReferences\\n\\nR. Alles and R. Guder, Gutachten zur Erstellung des Mietspiegels für München (in Ger-\\nman), Sozialreferat der Stadt München, Amt für Wohnungswesen, City of Munich, Ger-\\nmany, 1994.\\n\\nF. Benhamou, Interval Constraint Logic Programming, in: A. Podelski, ed., Constraint\\nProgramming: Basics and Trends, LNCS 910, pp. 1–21, Springer-Verlag, 1995.\\n\\n', 'P. Brisset, T. Frühwirth, P. Lim, M. Meier, T. Le Provost, J. Schimpf and M. Wallace,\\nECLiPSe 3.5 User Manual, ECRC, Munich, Germany, 1995.\\n\\nD. Cabeza and M. Hermenegildo, WWW Programming using Logic Programming Systems\\nand the CIAO PiLLoW Library, this issue.\\n\\nJ. C. Cleary, Logical Arithmetic, Future Computing Systems 2(2):125–149, 1987.\\n\\nE. Davis, Constraint Propagation with Interval Labels, Artificial Intelligence 32:281–331,\\n1987.\\n\\nT. Frühwirth and S. Abdennadher, The Munich Rent Advisor, in: P. Tarau, A. Davi-\\nson, K. De Bosschere and M. Hermenegildo, eds., 1st Workshop on Logic Program-\\n\\nhttp://www.informatik.uni-muenchen.de/~fruehwir/miet-demo.html\\n\\n\\nThe Munich Rent Advisor 15\\n\\nming Tools for Internet Applications, JICSLP’96, Bonn, Germany, September 1996,\\nwww.pst.informatik.uni-muenchen.de/∼fruehwir/wcicp97.html.\\n\\nT. Frühwirth and S. Abdennadher, Der Mietspiegel im Internet – Ein Fall für Constraint-\\nLogikprogrammierung (in German), in: H. W. Güsgen and J. Hertzberg, eds., Themen-\\nheft Constraints, Künstliche Intelligenz 1/97:33–36, Interdata Verlag, Germany, April\\n1997.\\n\\nT. Frühwirth and S. Abdennadher, Constraint-Programmierung (in German), Textbook,\\nSpringer-Verlag, September 1997.\\n\\nT. Frühwirth, M. Hermenegildo, P. Tarau, P. Codognet and F. Rossi, eds., Workshop\\non Constraint Reasoning on the Internet, at the Third International Conference on\\nPrinciples and Practice of Constraint Programming (CP97), Schloss Hagenberg, Linz,\\nAustria, November 1997.\\n\\nT. Frühwirth, Theory and Practice of Constraint Handling Rules, in: P. Stuckey and\\nK. Marriot, eds., Special Issue on Constraint Logic Programming, Journal of Logic\\nProgramming 37(1-3):95–138, 1998.\\n\\nC. Herzog, A Table- and Form Generator and Handler for HTML, Student project report,\\nLMU Munich, January 1998.\\n\\nG. Kuper and M. Wallace, eds., First Workshop on Constraint Databases and their Ap-\\nplications, LNCS 1034, Springer-Verlag, 1995.\\n\\nK. Marriott and P. J. Stuckey, Programming with Constraints, MIT Press, 1998.\\n\\nL. Naish, HTML Web Forms Interface to NU-Prolog, Department of Computer Science,\\nUniversity of Melbourne, Australia, 1999, www.cs.mu.oz.au/∼lee/src/forms/.\\n\\nM. Wallace, Survey: Practical Applications of Constraint Programming, Constraints Jour-\\nnal 1(1):139–168, Kluwer, 1996.\\n\\n\\n\\n16 T. Frühwirth and S. Abdennadher\\n\\nFieldname Value Frequency\\nRequests 7188\\n\\nwrong request 70\\ntimeout header 316\\ntimeout body 327\\nsyntax error 864\\ncorrect requests 5611\\n\\nAccept-from: 7073\\n.de 4667\\n\\nuni-muenchen (Uni) 815\\nlrz-muenchen (Uni) 440\\nsni (Com) 421\\nsiemens (Com) 364\\ndtag (Com) 360\\ntu-muenchen (Uni) 299\\nt-online (Pro) 266\\nmpg (Com) 97\\nsdm (Com) 87\\nbmw (Com) 82\\ngsf (Com) 80\\neunet (Pro) 78\\nmetronet (Pro) 73\\nuunet (Pro) 60\\nOther 1145\\n\\n.com 731\\n\\n.net 319\\nOther 261\\nanonymous 987\\nself test 108\\n\\nUser-Agent: 6875\\nMozilla 6606\\n\\nWin 3514\\nWin95 1570\\nWin16 933\\nWinNT 652\\nWindows 359\\n\\nX11 1989\\nSunOS 805\\nHP-UX 713\\nLinux 254\\nIrix 125\\nOther 102\\n\\nCompatible 762\\nMSIE 95 466\\nMSIE NT 114\\nAOL 78\\nMSIE Win32 76\\n\\nMacintosh 226\\nOS/2 111\\n\\nMosaic 164\\nOther 167\\n\\nFig. 3. Information from the Header\\n\\n\\n\\nThe Munich Rent Advisor 17\\n\\nFieldname Value Frequency\\nAccept-time: 7890\\n\\nJan 386\\nFeb 1023\\nMar 599\\nApr 600\\nMay 304\\nJun 619\\nJul 458\\nAug 481\\nSep 520\\nOct 751\\nNov 1282\\nDec 867\\n\\nby week-day 7073\\nMon 1658\\nTue 1346\\nWed 1037\\nThu 1014\\nFri 1008\\nSat 479\\nSun 531\\n\\nby hour 7073\\n00 119\\n01 64\\n02 22\\n03 20\\n04 10\\n05 15\\n06 12\\n07 111\\n08 225\\n09 404\\n10 441\\n11 607\\n12 571\\n13 655\\n14 561\\n15 665\\n16 562\\n17 447\\n18 373\\n19 289\\n20 250\\n21 271\\n22 211\\n23 168\\n\\nFig. 4. Temporal Information from the Header\\n\\n\\n\\tIntroduction\\n\\tThe Mietspiegel\\n\\tThe World Wide Web Front End\\n\\tECLiPSe as Web Server\\n\\tImplementing the Rent Calculation\\n\\tInterval Arithmetic\\n\\tDeductive Database for Tables\\n\\n\\tCloning\\n\\tUser Statistics\\n\\tConclusions\\n\\tReferences\\n\\n'], 'name': '0402019v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0402/0402019v1.pdf', 'vectorized': None}, {'@search.score': 13.312914, '@search.rerankerScore': 2.767233371734619, '@search.captions': [{'text': 'We will define an amalgamated proof system that combines  inference rules from intuitionistic sequent calculus with constraint entailment, in  such a way that the key property of an abstract logic programming language is  preserved.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNDA0LzA0MDQwNTN2MS5wZGY1', 'title': None, 'chunks': ['\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n04\\n\\n04\\n05\\n\\n3v\\n1 \\n\\n [\\ncs\\n\\n.P\\nL\\n\\n] \\n 2\\n\\n6 \\nA\\n\\npr\\n 2\\n\\n00\\n4\\n\\nUnder consideration for publication in Theory and Practice of Logic Programming 1\\n\\nConstraint Logic Programming with\\n\\nHereditary Harrop Formulas\\n\\nJavier Leach, Susana Nieva, Mario Rodŕıguez-Artalejo ∗\\n\\nDpto. Sistemas Informáticos y Programación\\n\\nAv. Complutense s/n, Universidad Complutense de Madrid,\\n\\nE-28040 Madrid, Spain\\n\\n(e-mail: {leach,nieva,mario}@sip.ucm.es)\\n\\nAbstract\\n\\nConstraint Logic Programming (CLP) and Hereditary Harrop Formulas (HH )are two well\\n\\nknown ways to enhance the expressivity of Horn clauses. In this paper, we present a novel\\n\\ncombination of these two approaches. We show how to enrich the syntax and proof theory\\n\\nof HH with the help of a given constraint system, in such a way that the key property of HH\\n\\nas a logic programming language (namely, the existence of uniform proofs) is preserved.\\n\\nWe also present a procedure for goal solving, showing its soundness and completeness for\\n\\ncomputing answer constraints. As a consequence of this result, we obtain a new strong\\n\\ncompleteness theorem for CLP that avoids the need to build disjunctions of computed\\n\\nanswers, as well as a more abstract formulation of a known completeness theorem for HH.\\n\\nkeywords: constraint systems, hereditary Harrop formulas, uniform proofs, goal solving.\\n\\n1 Introduction\\n\\nTraditionally, the logic of Horn clauses has been considered as the basis for logic\\n\\nprogramming (Van Emden and Kowalski, 1976). In spite of its Turing completeness\\n\\n(Andréka and Németi, 1978), the lack of expressivity of Horn clauses for program-\\n\\nming purposes is widely acknowledged. During the last decade, different extensions\\n\\nof Horn clauses have been proposed, with the aim of increasing expressivity with-\\n\\nout sacrificing the declarative character of pure logic programming. Among such\\n\\nextensions, two important approaches are Constraint Logic Programming (CLP)\\n\\nand Hereditary Harrop Formulas (HH ).\\n\\n∗ This is a substantially revised and extended version of\\n\\n(Leach, Nieva and Rodŕıguez-Artalejo, 1997). The authors have been partially supported\\n\\nby the Spanish National Project TIC 98-0445-C03-02 TREND and the Esprit BRA Working\\n\\nGroup EP-22457 CCLII.\\n\\nhttp://arXiv.org/abs/cs/0404053v1\\n\\n\\n2 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nThe CLP scheme (Jaffar and Lassez, 1987) goes beyond the limitations of the\\n\\nHerbrand universe by providing the ability to program with Horn clauses over\\n\\ndifferent computation domains, whose logical behaviour is given by constraint sys-\\n\\ntems. CLP languages keep all the good semantic properties of pure logic program-\\n\\nming, including soundness and completeness results (Jaffar et al., 1996). Their im-\\n\\nplementation relies on the combination of SLD resolution with dedicated algorithms\\n\\nfor constraint entailment, solving and simplification. Therefore, efficient and yet\\n\\ndeclarative programs can be written to solve complex combinatorial problems. See\\n\\n(Jaffar and Maher, 1994) for a survey of the foundations, implementation issues\\n\\nand applications of CLP languages.\\n\\nOn the other hand, the HH approach (Miller, Nadathur and Scedrov, 1987) over-\\n\\ncomes the inability of Horn clauses to provide a logical basis for several constructions\\n\\ncommonly found in modern programming languages, such as scoping, abstraction\\n\\nand modularity. This is achieved by extending Horn clauses to a richer fragment of\\n\\nintuitionistic logic that allows us to use disjunctions, implications and quantifiers in\\n\\ngoals. In fact, HH is a typical example of an abstract logic programming language, in\\n\\nthe sense of (Miller et al., 1991). Abstract logic programming languages are charac-\\n\\nterized by the fact that the declarative meaning of a program, given by provability\\n\\nin a deduction system, can be interpreted operationally as goal-oriented search for\\n\\nsolutions. Technically, the existence of uniform proofs for all provable goal formu-\\n\\nlas permits the search interpretation of provability. The implementation of pro-\\n\\ngramming languages based on HH, such as λ-Prolog (Miller and Nadathur, 1986;\\n\\nNadathur and Miller, 1988), requires the resolution of the problem of unifying terms\\n\\noccurring under the scope of arbitrary quantifier prefixes. Correct unification al-\\n\\ngorithms for such problems have been studied in (Miller, 1992; Nadathur, 1993).\\n\\nMoreover, (Nadathur, 1993) shows in detail the soundness and completeness of a\\n\\ngoal solving procedure for the first-order HH language.\\n\\nThe aim of this paper is to present a framework for the combination of the CLP\\n\\nand HH approaches, that incorporates the benefits of expressivity and efficiency\\n\\nthat HH and CLP bring to logic programming, respectively. We will enrich the\\n\\nsyntax of first-order HH with constraints coming from a given constraint system.\\n\\nThe resulting language is such that all constructions and results are valid for any\\n\\nconstraint system C, therefore we can speak of a scheme HH(X) with instances\\n\\nHH(C), as in CLP. ', 'We will define an amalgamated proof system that combines\\n\\ninference rules from intuitionistic sequent calculus with constraint entailment, in\\n\\nsuch a way that the key property of an abstract logic programming language is\\n\\npreserved. Moreover, we will also present a sound and complete procedure for goal\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 3\\n\\nx2 ≤ 1/2, y2 ≤ 1/2 ⊢R ∃u∃v(x ≈ u ∧ y ≈ v ∧ u2 + v2 ≤ 1)\\n\\n(CR)\\n\\n∆; x2 ≤ 1/2, y2 ≤ 1/2 |— ∃u∃v(x ≈ u ∧ y ≈ v ∧ u2 + v2 ≤ 1)\\n\\n(Clause)\\n\\n∆; x2 ≤ 1/2, y2 ≤ 1/2 |— disc (x, y)\\n\\n(⇒CR)\\n\\n∆; x2 ≤ 1/2 |— y2 ≤ 1/2 ⇒ disc (x, y)\\n\\n(∀R)\\n\\n∆; x2 ≤ 1/2 |— ∀y(y2 ≤ 1/2 ⇒ disc (x, y))\\n\\nFig. 1\\n\\nsolving. As in CLP , the result of solving a goal using a program will be an answer\\n\\nconstraint.\\n\\nThe following simple program ∆, goal G and constraint R belong to the instance\\n\\nHH(R) given by the constraint system R for real numbers. We will refer to this as\\n\\nthe disc example in the sequel.\\n\\n∆ ≡ {∀x∀y(x2 + y2 ≤ 1 ⇒ disc (x, y))}\\n\\nG ≡ ∀y(y2 ≤ 1/2 ⇒ disc (x, y))\\n\\nR ≡ x2 ≤ 1/2\\n\\nIn the example, the formula R turns out to be a correct and computable answer\\n\\nconstraint in the resolution of G from ∆. Due to the soundness and completeness\\n\\nof the goal solving procedure, G can be deduced from ∆ and R in the amalgamated\\n\\nproof system. In Figure 1 a uniform proof is presented of the sequent ∆; R |— G,\\n\\nusing the inferences rules of the calculus UC which will be presented in Section 4.\\n\\nFrom a technical point of view, for the particular case of the Herbrand constraint\\n\\nsystem, our completeness result boils down to a more abstract formulation of the\\n\\ncompleteness theorem in (Nadathur, 1993). In the case of CLP programs using only\\n\\nHorn clauses with constraints, our goal solving procedure reduces to constrained\\n\\nresolution, and our completeness theorem yields a form of strong completeness for\\n\\nsuccess that avoids the need to build disjunctions of computed answers, in contrast\\n\\nto (Maher, 1987), Th. 2 (see also (Jaffar et al., 1996), Th. 4.12). The reason for this\\n\\ndiscrepancy is that our amalgamated proof system uses more constructive inference\\n\\nmechanisms to deduce goals from program clauses, as we will see.\\n\\nThe rest of this paper is organized as follows: Section 2 shows some programming\\n\\nexamples, that illustrate the specific benefits of the combination of CLP and HH .\\n\\nIn Section 3 we recall the notion of a constraint system and we define the syntax of\\n\\n\\n\\n4 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nHH with constraints. In Section 4 we present an intuitionistic proof system for HH\\n\\nwith constraints, and we show the existence of uniform proofs, then an equivalent\\n\\nproof system allowing only uniform proofs is defined. Based on this second calculus,\\n\\na sound and complete procedure for goal solving is presented as a transformation\\n\\nsystem in Section 5. In Section 6 we summarize conclusions and possible lines for\\n\\nfuture research. In order to improve readability of the paper, some proofs have been\\n\\nomitted or compressed in the main text. Full proofs appear in the Appendix.\\n\\n2 Examples\\n\\nAlthough simple, the programs of this section exemplify the programming style\\n\\nin HH(X) languages, combining the characteristic utilities of HH –such as to add\\n\\ntemporarily facts to the program or to limit the scope of the names– with the ad-\\n\\nvantages of using constraint solvers, instead of syntactical unification. The syntax\\n\\nused in the examples is basically that of HH languages, with the addition of con-\\n\\nstraints in clause bodies and goals. In particular, the notation t ≈ t′ will be used\\n\\nfor equality constraints. More formal explanations will follow in Section 3.\\n\\nThe programs below are based on a constraint system which is defined as a com-\\n\\nbination of R (real numbers) and H (Herbrand universe). This constraint system\\n\\nunderlies the well known language CLP(R) (Jaffar et al., 1992). The elements in\\n\\nthe intended computation domain can be represented as trees whose internal nodes\\n\\nare labeled by constructors, and whose leaves are labeled either by constant con-\\n\\nstructors or by real numbers. In particular this includes the representation of lists,\\n\\npossibly with real numbers as members. We will use Prolog’s syntax for the list\\n\\nconstructors.\\n\\nExample 2.1 (Hypothetical queries in a data base system)\\n\\nThe following program keeps record of the marks of different students in two exer-\\n\\ncises they have to do to pass an exam.\\n\\nexercise1(bob, 4).\\n\\nexercise1(fran, 3).\\n\\nexercise2(fran, 6).\\n\\nexercise1(pep, 5).\\n\\nexercise2(pep, 6).\\n\\npass(X) ⇐ exercise1(X, N1)∧exercise2(X, N2) ∧ (N1 + N2)/2 > 5.\\n\\nWhile the goal G ≡ pass(bob) fails, G′ ≡ exercise2(bob, 6.5) ⇒ pass(bob) succeeds.\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 5\\n\\nTo resolve this last goal, the fact exercise2(bob, 6.5) is added to the program, but\\n\\nnot permanently. If we would put again the query G ≡ pass(bob) it would fail again.\\n\\nSuppose now we want to know the requirements a student has to fulfil to pass,\\n\\nthen we add to the program the clauses:\\n\\nneed-to-pass(A, []) ⇐ pass(A).\\n\\n', 'need-to-pass(A, [ex1(X)|L]) ⇐ (exercise1(A, X) ⇒ need-to-pass(A, L)).\\n\\nneed-to-pass(A, [ex2(X)|L]) ⇐ (exercise2(A, X) ⇒ need-to-pass(A, L)).\\n\\nThe goal G ≡ need-to-pass(bob, L) will produce an answer equivalent in the con-\\n\\nstraint system to ∃N(L ≈ [ex2(N)] ∧ N > 6).\\n\\nTo get this answer, the intermediate goal exercise2(A, X) ⇒ need-to-pass(A, L1)\\n\\nshould be solved with the constraint A ≈ bob. This would require:\\n\\ni) To introduce the fact exercise2(A, X) in the base. Note that the effect is dif-\\n\\nferent to adding a clause in Prolog with assert, since this implies the universal\\n\\nquantification of A and X.\\n\\nii) Try to solve the goal need-to-pass(A, []) with the first clause of this predicate,\\n\\nso to solving pass(A), with the constraint A ≈ bob and L1 ≈ []. This will add the\\n\\nconstraints X ≈ N, (4 + N)/2 > 5.\\n\\nA similar example is shown in (Hodas, 1994), here the benefit is in the use of\\n\\nconstraints allowing to write conditions about the real numbers that help to solve\\n\\nthe goal more efficiently. 2\\n\\nExample 2.2 (Fibonacci numbers)\\n\\n(Cohen, 1990) uses the computation of Fibonacci numbers as a simple example to\\n\\nillustrate the advantages of constraint solving w.r.t. built-in arithmetic (as available\\n\\nin Prolog). The recursive definition of Fibonacci sequence gives rise immediately to\\n\\nthe following CLP(R) program:\\n\\nfib(0, 1).\\n\\nfib(1, 1).\\n\\nfib(N, F1 + F2) ⇐ N ≥ 2 ∧ fib(N − 1, F1)) ∧ fib(N − 2, F2).\\n\\nThanks to the abilities of the constraint solver, this program is reversible. In ad-\\n\\ndition to goals such as fib(10, X), with answer X ≈ 89, we can also solve goals as\\n\\nfib(N, 89) with answer N ≈ 10. However, the program is based on an extremely\\n\\ninefficient double recursion. As a consequence, it runs in exponential time, and\\n\\nmultiple recomputations of the same Fibonacci number occur.\\n\\nIn HH(R) we can avoid this problem by using implications in goals to achieve\\n\\nthe effect of tabulation. At the same time, the program remains reversible and close\\n\\nto the mathematical specification of the Fibonacci sequence.\\n\\n\\n\\n6 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nfib(N, X) ⇐ (memfib(0, 1) ⇒ (memfib(1, 1) ⇒ getfib(N, X, 1))).\\n\\ngetfib(N, X, M) ⇐ 0 ≤ N ∧ N ≤ M ∧ memfib(N, X).\\n\\ngetfib(N, X, M) ⇐ N > M ∧ memfib(M − 1, F1) ∧ memfib(M, F2) ∧\\n\\n(memfib(M + 1, F1 + F2) ⇒ getfib(N, X, M + 1)).\\n\\nA predicate call of the form getfib(N, X, M) assumes that the Fibonacci numbers\\n\\nfibi, with 0 ≤ i ≤ M , are memorized as atomic clauses for memfib in the local\\n\\nprogram. The call computes the N -th Fibonacci number in X ; at the same time, the\\n\\nFibonacci numbers fibi, with M < i ≤ N are memorized during the computation.\\n\\nLet us consider two simple goals for this program:\\n\\ni) G1 ≡ fib(2, X). In order to solve G1, memfib(0, 1) and memfib(1, 1) are added\\n\\nto the local program, and the goal getfib(2, X, 1) is solved. Since 2 > 1, the first\\n\\nclause for getfib fails. The second clause for getfib puts memfib(2, 2) into the local\\n\\nprogram and produces the new goal getfib(2, X, 2), which is solved with answer\\n\\nX ≈ 2 by means of the first clause.\\n\\nii) G2 ≡ fib(N, 2). Analogously, G2 is solved by solving getfib(N, 2, 1) after adding\\n\\nmemfib(0, 1) and memfib(1, 1) into the local program. The first clause for getfib fails.\\n\\nTherefore, the constraint N > 1 is assumed and the new goal getfib(N, 2, 2) must\\n\\nbe solved, after putting the atom memfib(2, 2) into the local program. Now, the\\n\\nfirst clause for getfib leads easily to the answer N ≈ 2.\\n\\nIn general, all goals of the two forms:\\n\\ni) fib(n, X), n given,\\n\\nii) fib(N, f), f a given Fibonacci number\\n\\ncan be solved by our goal solving procedure. Moreover, goals of the form i) can be\\n\\nsolved in O(n) steps. In (Miller, 1989), Miller showed that implicational goals can\\n\\nbe used to store previously computed Fibonacci numbers, thus leading to an HH\\n\\nprogram that runs in time O(n). Later Hodas (1994) gave another memorized ver-\\n\\nsion of the computation of Fibonacci numbers, closer to the naive doubly recursive\\n\\nalgorithm. Hodas’ version combines implicational goals with a continuation-passing\\n\\nprogramming style which relies on higher-order predicate variables. The benefit of\\n\\nour version w.r.t. (Miller, 1989; Hodas, 1994) is the reversibility of the predicate fib\\n\\nthat is enabled by constraint solving. 2\\n\\nExample 2.3 (Relating some simple parameters in a mortgage)\\n\\nThe following program ∆ is presented by Jaffar and Michaylov (1987) as an appli-\\n\\ncation of CLP(R).1\\n\\n1 This example is considered anew in (Jaffar et al., 1992).\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 7\\n\\nmortgage(P, T, I, M, B) ⇐ 0 ≤ T ∧ T ≤ 3 ∧ TotalInt ≈ T ∗ (P ∗ I/1200)∧\\n\\nB ≈ P + TotalInt − (T ∗ M).\\n\\nmortgage(P, T, I, M, B) ⇐ T > 3 ∧ QuartInt ≈ 3 ∗ (P ∗ I/1200)∧\\n\\nmortgage(P + QuartInt − 3 ∗ M, T − 3, I, M, B).\\n\\nWhere P stands for principal Payment, T for Time in months, I for Interest rate,\\n\\nM for Monthly payment, and B for outstanding Balance.\\n\\nIn CLP(R) the goal G ≡ mortgage(P, 6, 10, M, 0), produces the answer 0 ≈\\n\\n1.050625 ∗ P − 6.075 ∗ M . ', 'From this answer we can deduce that P/(T ∗ M) ≈\\n\\nP/(6 ∗ M) ≈ 0.9637 (the number 0.9637 is calculated as an approximation), where\\n\\nP/(T ∗ M) represents the quotient of loss for delayed payment.\\n\\nWe consider now a more complicated problem, namely to find Imin, Imax (with\\n\\n0 ≤ Imin ≤ Imax) such that any mortgage whose quotient of loss lies in the interval\\n\\n[0.9637 . . 0.97] can be balanced in 6 months with some interest rate I lying in the\\n\\ninterval [Imin . . Imax]. This problem can be formulated in HH(R) by the goal:\\n\\nG ≡ ∀M∀P (0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒\\n\\n∃I(0 ≤ Imin ≤ I ≤ Imax ∧ mortgage(P, 6, I, M, 0))).\\n\\nUsing the goal transformation rules i) – viii) of Section 5, we can show a resolution\\n\\nof G from ∆ that computes the answer constraint:\\n\\nImax ≈ 10 ∧ Imin ≈ 8.219559 (approx.).\\n\\nMore details on the resolution of this goal will be given in Example 5.3 at the end\\n\\nof Section 5. 2\\n\\n3 Hereditary Harrop Formulas with Constraints\\n\\nAs explained in the Introduction, the framework presented in this paper requires the\\n\\nenrichement of the syntax of Hereditary Harrop Formulas (shortly, HH ) (Miller, Nadathur and Scedrov, 1987;\\n\\nMiller et al., 1991) with constraints coming from a given constraint system. Follow-\\n\\ning (Saraswat, 1992), we view a constraint system as a pair C = (LC ,⊢C), where LC\\n\\nis the set of formulas allowed as constraints and ⊢C ⊆ P(LC)×LC is an entailment\\n\\nrelation. We use C and Γ to represent a constraint and a finite set of constraints,\\n\\nrespectively. Therefore, Γ ⊢C C means that the constraint C is entailed by the set\\n\\nof constraints Γ. We write just ⊢C C if Γ is empty. In (Saraswat, 1992), LC and ⊢C\\n\\nare required to satisfy certain minimal assumptions, mainly related to the logical\\n\\nbehaviour of ∧ and ∃. Since we have to work with other logical symbols, our as-\\n\\nsumptions must be extended to account for their proper behaviour. Therefore, we\\n\\nassume:\\n\\n\\n\\n8 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\ni) LC is a set of formulas including ⊤ (true), ⊥ (false) and all the equations\\n\\nt ≈ t′ between terms over some fixed signature, and closed under ∧,⇒, ∃, ∀\\n\\nand the application of substitutions of terms for variables.\\n\\nii) ⊢C is compact, i.e., Γ ⊢C C holds iff Γ0 ⊢C C for some finite Γ0 ⊆ Γ. ⊢C is also\\n\\ngeneric, i.e., Γ ⊢C C implies Γσ ⊢C Cσ for every substitution σ.\\n\\niii) All the inference rules related to ∧,⇒, ∃, ∀ and ≈ valid in the intuitionistic\\n\\nfragment of first-order logic are also valid to infer entailments in the sense of\\n\\n⊢C .\\n\\nThe notation Cσ used above means application to a constraint C of a substitution\\n\\nσ = [t1/x1, . . . , tn/xn], using proper renaming of the variables bound in C to avoid\\n\\ncapturing free variables from the terms ti, 1 ≤ i ≤ n. Γσ represents the application\\n\\nof σ to every constraint of the set Γ. In the sequel, the notation Fσ will also be\\n\\nused for other formulas F , not necessarily constraints.\\n\\nNote that the three conditions i), ii), iii) are meant as minimal requirements. In\\n\\nparticular, the availability of the equality symbol ≈ is granted in any constraint\\n\\nsystem, and it will always stand for a congruence. However, other specific axioms\\n\\nfor equality may be different in different constraint systems.\\n\\nObserve also that item iii) above, does not mean that ⊢C is restricted to represent\\n\\ndeducibility in some intuitionistic theory. On the contrary, our assumptions allow\\n\\nus to consider constraint systems C such that LC is a full first-order language with\\n\\nclassical negation, and Γ ⊢C C holds iff AxC ∪ Γ ⊢ C, where AxC is a suitable set\\n\\nof first-order axioms and ⊢ is the entailment relation of classical first-order logic\\n\\nwith equality. In particular, three important constraint systems of this form are: H,\\n\\nwhere AxH is Clark’s axiomatization of the Herbrand universe (Clark, 1978); CFT ,\\n\\nwhere AxCFT is Smolka and Treinen’s axiomatization of the domain of feature trees\\n\\n(Smolka and Treinen, 1994); and R, where AxR is Tarski’s axiomatization of the\\n\\nreal numbers (Tarski, 1951). In these three cases, the constraint system is known\\n\\nto be effective, in the sense that the validity of entailments Γ ⊢C C, with finite Γ,\\n\\ncan be decided by an effective procedure.\\n\\nThe previous systems include the use of disjunctions. In CLP there is a well\\n\\nknown completeness theorem due to Maher (1987), which relies on the possibility\\n\\nof building finite disjunctions of computed answer constraints. As we will see in\\n\\nSection 5, disjunctions are not needed in order to prove completeness of goal solving\\n\\nin our setting. This is the reason why we do not enforce LC to be closed under ∨\\n\\nin the general case.\\n\\nIn the sequel, we assume an arbitrarily fixed effective constraint system C. By\\n\\nconvention, the notation Γ ⊢C Γ′ will mean that Γ ⊢C C holds for all C ∈ Γ′, and\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 9\\n\\nC ⊢⊣C C′ will abbreviate that C ⊢C C′ and C′ ⊢C C hold. Also, we will say that a\\n\\nconstraint C with free variables x1, . . . , xn is C-satisfiable iff ⊢C ∃x1 . . . ∃xnC.\\n\\n', 'In order to define the syntax of the first-order formulas of HH(C), we assume a set\\n\\nPS =\\n⋃\\n\\nn∈IN PSn of ranked predicate symbols (disjoint from the symbols occurring\\n\\nin LC) which are used to build atomic formulas A of the form P (t1, . . . , tn), with\\n\\nP ∈ PSn.\\n\\nDefinition 3.1\\n\\nThe set of definite clauses, with elements noted D, and the set of goals, with ele-\\n\\nments noted G, are defined by the following syntactic rules:\\n\\nD := A |D1 ∧ D2 |G ⇒ A | ∀xD\\n\\nG := A |C |G1 ∧ G2 |G1 ∨ G2 |D ⇒ G |C ⇒ G | ∃xG | ∀xG\\n\\nThis syntax is the natural extension of first-order HH as presented in (Nadathur, 1993).\\n\\nThe novelty is that constraints can occur in goals of the forms C and C ⇒ G, and\\n\\ntherefore also in definite clauses of the form G ⇒ A. Some variants could be con-\\n\\nsidered, as e.g. dropping D1∧D2 or replacing G ⇒ A by G ⇒ D, but these changes\\n\\nwould render a logically equivalent system. In the rest of the paper, by a program we\\n\\nunderstand any finite set ∆ of definite clauses. This includes both CLP programs\\n\\nand first-order HH programs as particular cases.\\n\\nAs usual in the HH framework, see e.g. (Nadathur, 1993), we will work with\\n\\na technical device (so-called elaboration) for decomposing the clauses of a given\\n\\nprogram into a simple form. This is useful for a natural formulation of goal solving\\n\\nprocedures.\\n\\nDefinition 3.2\\n\\nWe define the elaboration of a program ∆ as the set elab(∆) =\\n⋃\\n\\nD∈∆ elab(D),\\n\\nwhere elab(D) is defined by case analysis in the following way:\\n\\n– elab(A) = {⊤ ⇒ A}.\\n\\n– elab(D1 ∧ D2) = elab(D1) ∪ elab(D2).\\n\\n– elab(G ⇒ A) = {G ⇒ A}.\\n\\n– elab(∀xD) = {∀xD′ |D′ ∈ elab(D)}.\\n\\nNote that all clauses in elab(∆) have the form ∀x1 . . .∀xn(G ⇒ A), n ≥ 0. We\\n\\nstill need another technicality. A variant of such a clause is any clause of the form\\n\\n∀y1 . . .∀yn(Gσ ⇒ Aσ) where y1, . . . , yn are new variables not occurring free in the\\n\\noriginal clause, and σ = [y1/x1, . . . , yn/xn].\\n\\n\\n\\n10 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\n4 Proof Systems\\n\\nIn this section we present an amalgamated proof system IC that combines the\\n\\nusual inference rules from intuitionistic logic with the entailment relation ⊢C of a\\n\\nconstraint system C. We will derive sequents of the form ∆; Γ |— G where ∆ is a\\n\\nprogram, Γ represents a finite set of constraints and G is an arbitrary goal. We also\\n\\nshow that IC enjoys completeness of uniform proofs, and we present a second proof\\n\\nsystem UC which is equivalent to IC in deductive power, but is tailored to build\\n\\nuniform proofs only.\\n\\n4.1 The calculus IC\\n\\nIC stands for an Intuitionistic sequent calculus for HH(C) that allows to deduce a\\n\\ngoal from defined clauses in the presence of Constraints.\\n\\nThe intuitionistic calculus with constraints ⊢IC is defined as follows. ∆; Γ ⊢IC\\n\\nG if and only if the sequent ∆; Γ |— G has a proof using the rules of the proof\\n\\nsystem IC that we introduce in the following. A proof of a sequent is a tree whose\\n\\nnodes are sequents, the root is the sequent to be proved and the leaves match\\n\\naxioms of the calculus. The rules regulate relationship between child nodes and\\n\\nparent nodes. In the representation of the rules, we have added to the premises the\\n\\nside conditions relating to the existence of proofs in the constraint system; these\\n\\nentailment relations are not considered as nodes of the proofs seen as trees. This\\n\\nnotation simplifies the reading of both inference rules and proof trees.\\n\\n• Axioms to deal with atomic goals or constraints:\\n\\nΓ ⊢C C\\n\\n∆; Γ |— C\\n(CR)\\n\\nΓ ⊢C A ≈ A′\\n\\n∆, A; Γ |—A′\\n(Atom)\\n\\nIn (Atom), A, A′ are assumed to begin with the same predicate symbol.\\n\\nA ≈ A′ abbreviates t1 ≈ t′1 ∧ . . . ∧ tn ≈ t′n, where A ≡ P (t1, . . . , tn),\\n\\nA′ ≡ P (t′1, . . . , t\\n′\\nn).\\n\\n• Rules introducing the connectives and quantifiers of the Hereditary Harrop\\n\\nformulas:\\n\\n∆; Γ |— Gi\\n\\n∆; Γ |— G1 ∨ G2\\n(∨R) (i = 1, 2)\\n\\n∆, D1, D2; Γ |— G\\n\\n∆, D1 ∧ D2; Γ |—G\\n(∧L)\\n\\n∆; Γ |—G1 ∆; Γ |— G2\\n\\n∆; Γ |— G1 ∧ G2\\n(∧R)\\n\\n∆; Γ |— G1 ∆, A; Γ |— G\\n\\n∆, G1 ⇒ A; Γ |— G\\n(⇒L)\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 11\\n\\n∆, D; Γ |— G\\n\\n∆; Γ |— D ⇒ G\\n(⇒R)\\n\\n∆; Γ, C |— G\\n\\n∆; Γ |— C ⇒ G\\n(⇒CR)\\n\\n∆; Γ, C |— G[y/x] Γ ⊢C ∃yC\\n\\n∆; Γ |— ∃xG\\n(∃R)\\n\\ny does not appear free in the sequent of the conclusion.\\n\\n∆, D[y/x]; Γ, C |— G Γ ⊢C ∃yC\\n\\n∆, ∀xD; Γ |— G\\n(∀L)\\n\\n∆; Γ |— G[y/x]\\n\\n∆; Γ |— ∀xG\\n(∀R)\\n\\nin both, y does not appear free in the sequent of the conclusion.\\n\\nNote that the rule of contraction seems to be absent from this system, but in fact\\n\\nit is implicitly present because ∆ and Γ are viewed as sets (rather than sequences)\\n\\nin any sequent ∆; Γ |— G. In many respects, the inference rules of UC are similar to\\n\\nthose used for HH in the literature; see e.g. (Miller et al., 1991; Nadathur, 1993).\\n\\nHowever, the presence of constraints induces some modifications. Of particular im-\\n\\nportance are the modifications introduced to (∃R) and (∀L). A simple reformulation\\n\\nof the traditional version of (∃R), using a constraint y ≈ t instead of a substitution\\n\\n[t/x], representing an instance of x, could be:\\n\\n∆; Γ, y ≈ t |— G[y/x]\\n\\n∆; ', 'Γ |— ∃xG\\n\\nif y does not occur in t, and it does not appear free in the conclusion.\\n\\nIn our constraint-oriented formulation of (∃R) we allow any satisfiable constraint\\n\\nC (not necessary of the form y ≈ t) instead of the substitution, in order to guess\\n\\nan instance of x. The next example shows that this extra generality is necessary.\\n\\nExample 4.1\\n\\nThis example is based on HH(R). Consider\\n\\n∆ ≡ {∀x(x2 ≈ 2 ⇒ r(x))},\\n\\nG ≡ ∃x r(x).\\n\\nThe sequent ∆; |— G is expected to be derivable. However, the traditional formula-\\n\\ntion of (∃R) does not work, because no term t in the language LR denotes a square\\n\\nroot of 2. With our (∃R), choosing the R-satisfiable constraint C ≡ x2 ≈ 2, the\\n\\nproblem is reduced to the easy derivation of the sequent ∆;x2 ≈ 2 |— r(x). 2\\n\\nOur definition of (∀L) is dual to (∃R) and follows the same idea, since (∀L) also\\n\\nrelies on guessing an instance for x. On the other hand, rule (∀R) has a universal\\n\\ncharacter. Therefore, the traditional formulation by means of a new variable has\\n\\nbeen kept in this case.\\n\\n\\n\\n12 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nFor technical reasons we need to measure the size of proofs. We formalize this\\n\\nnotion as the number of sequents in it, that coincides with the number of nodes of\\n\\nthe proof seen as a tree.\\n\\nIn the sequel we will use some technical properties of IC-provability. Let us state\\n\\nthem in the next lemmas, whose proofs can be found in the Appendix.\\n\\nThe first lemma guarantees that substitution of a term for a variable in a sequent,\\n\\npreserves IC-provability.\\n\\nLemma 4.1\\n\\nFor any ∆, Γ, G, x and t, if ∆; Γ ⊢IC G, then there is a proof of the same size of\\n\\n∆[t/x]; Γ[t/x] |— G[t/x].\\n\\nThe next lemma shows that a sequent continues to be provable if we strengthen the\\n\\nset of constraints.\\n\\nLemma 4.2\\n\\nFor any ∆, Γ, G, if Γ′ is a set of constraints such that Γ′ ⊢C Γ, and ∆; Γ ⊢IC G,\\n\\nthen ∆; Γ′ |— G has a proof of the same size.\\n\\nCorollary 4.3\\n\\nFor any ∆, Γ, G, x and u, if ∆; Γ ⊢IC G, then ∆[u/x]; Γ, x ≈ u |— G[u/x] has a\\n\\nproof of the same size.\\n\\nProof\\n\\nBy Lemma 4.1, ∆[u/x]; Γ[u/x] |— G[u/x] has a proof of the same size as ∆; Γ |— G.\\n\\nHence, applying Lemma 4.2, ∆[u/x]; Γ, x ≈ u |—G[u/x] has a proof of the same\\n\\nsize, because Γ, x ≈ u ⊢C Γ[u/x].\\n\\nThe next lemma assures that free variables that appear only in the set of con-\\n\\nstraints of a sequent can be considered as existentially quantified in the proof of\\n\\nthe sequent.\\n\\nLemma 4.4\\n\\nFor any ∆, Γ, C, G, if ∆; Γ, C ⊢IC G and x is a variable that does not appear free\\n\\nin ∆, Γ, G, then ∆; Γ, ∃xC |— G has a proof of the same size.\\n\\n4.2 Uniform proofs\\n\\nWe are aiming at an abstract logic programming language in the sense of (Miller et al., 1991).\\n\\nThis means that uniform proofs must exist for all provable sequents. In our setting\\n\\nthe idea of uniform proof consists in breaking down a goal into its components until\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 13\\n\\nobtaining an atomic formula or a constraint, before using the rules for introduction\\n\\nof connectives on the left or resorting to constraint entailment.\\n\\nMore formally, the notion of uniform proof is as follows.\\n\\nDefinition 4.1\\n\\nAn IC-proof is called uniform proof when each internal node in the proof tree is\\n\\na sequent whose right-hand side G is neither a constraint nor an atomic formula.\\n\\nMoreover the inference rule relating this node to its children must be one of the\\n\\nright-introduction rules (∨R), (∧R), (⇒R), (⇒ CR), (∃R), (∀R), according to the\\n\\noutermost logical symbol of G.\\n\\nIn order to prove that uniform proofs exist for all IC-provable sequents, we follow\\n\\nthe same approach that in (Miller et al., 1991), showing that any given IC-proof\\n\\ncan be transformed into a uniform proof. This is achieved by the next lemma.\\n\\nLemma 4.5 (Proof Transformation)\\n\\nIf G is a goal, ∆ a program and Γ a set of constraint formulas, such that ∆; Γ |— G\\n\\nhas a proof of size l, then:\\n\\n1. For G ≡ A, there are n constraint formulas C1, . . . , Cn (n ≥ 0) and a formula\\n\\n∀x1 . . . ∀xn (G′ ⇒ A′) that is a variant of some formula in elab(∆) such that\\n\\nx1, . . .,xn are new distinct variables not appearing free in ∆, Γ, A, where xi\\n\\ndoes not appear free in C1, . . .,Ci−1, for 1 < i ≤ n, and A′ begins with the\\n\\nsame predicate symbol as A. In addition it holds:\\n\\n(a) Γ ⊢C ∃x1C1; Γ, C1 ⊢C ∃x2C2; . . . ; Γ, C1, . . . , Cn−1 ⊢C ∃xnCn.\\n\\n(b) Γ, C1, . . . , Cn ⊢C A′ ≈ A.\\n\\n(c) ∆; Γ, C1, . . . , Cn |— G′ has a proof of size less than l, or G′ ≡ ⊤.\\n\\n2. If G ≡ C, then Γ ⊢C C.\\n\\n3. If G ≡ G1 ∧ G2, then ∆; Γ |— G1 and ∆; Γ |— G2 have proofs of size less than\\n\\nl.\\n\\n4. If G ≡ G1 ∨ G2, then ∆; Γ |— Gi has a proof of size less than l for i = 1 or 2.\\n\\n5. If G ≡ D ⇒ G1, then ∆, D; Γ |— G1 has a proof of size less than l.\\n\\n6. If G ≡ C ⇒ G1, then ∆; Γ, C |— G1 has a proof of size less than l.\\n\\n7. For G ≡ ∃xG1, if y is a variable not appearing free in ∆, Γ, G, then there is\\n\\na constraint formula C such that:\\n\\n(a) Γ ⊢C ∃yC.\\n\\n(b) ∆; Γ, C |— G1[y/x] has a proof of size less than l.\\n\\n8. If G ≡ ∀xG1, then ∆; ', 'Γ |— G1[y/x] has a proof of size less than l, where y is\\n\\na variable that does not appear free in ∆, Γ, G.\\n\\n\\n\\n14 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nProof\\n\\nWe reason by induction on the size l of the proof of ∆; Γ |— G, analyzing cases\\n\\naccording to the last inference rule applied in the proof of the sequent ∆; Γ |— G. A\\n\\ndetailed proof can be found in the Appendix. As novelties w.r.t. (Miller et al., 1991),\\n\\nwe must deal with constraints and with the new formulation of rules (∃R), (∀L).\\n\\nHere we only sketch the case where (∀L) is the last inference rule applied and\\n\\nG ≡ ∃wG1. Let us show graphically the proof transformation, in which we will\\n\\nessentially switch the applications of (∀L) and (∃R). By the induction hypothesis,\\n\\nthe initial proof has the form:\\n\\n∆′, D[u/x]; Γ, C′ ∧ C, u ≈ y |— G1[z/w]\\n\\n↑ Cor. 4.3, Lem. 4.2\\n\\n∆′, D[y/x]; Γ, C′, C |— G1[z/w] Γ, C′ ⊢C ∃zC\\n\\n(∃R)\\n\\n∆′, D[y/x]; Γ, C′ |— ∃wG1 Γ ⊢C ∃yC′\\n\\n(∀L)\\n\\n∆′, ∀xD; Γ |— ∃wG1\\n\\nwhere:\\n\\n– y is not free in ∆′, ∀xD, Γ, ∃wG1.\\n\\n– z is not free in ∆′, D[y/x], Γ, C′, ∃wG1.\\n\\n– u is a new variable.\\n\\nWe can transform this into the following proof:\\n\\n∆′, D[u/x]; Γ, C′ ∧ C, u ≈ y |— G1[z/w] Γ, C′ ∧ C ⊢C ∃u(u ≈ y)\\n\\n(∀L)\\n\\n∆′, ∀xD; Γ, C′ ∧ C |— G1[z/w]\\n\\n↓ Lem. 4.4\\n\\n∆′, ∀xD; Γ, ∃y(C′ ∧ C) |— G1[z/w] Γ ⊢C ∃z∃y(C′ ∧ C)\\n\\n(∃R)\\n\\n∆′, ∀xD; Γ |— ∃wG1\\n\\nwhere:\\n\\n– z is not free in ∆′, ∀xD, Γ, ∃wG1.\\n\\n– u is not free in ∆′, ∀xD, Γ, C′ ∧ C, G1[z/w].\\n\\nThe next main theorem follows now as a straightforward consequence of the Proof\\n\\nTransformation Lemma 4.5.\\n\\nTheorem 4.6 (Uniform Proofs)\\n\\nEvery IC-provable sequent has a uniform proof.\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 15\\n\\nProof\\n\\nGiven an IC-provable sequent with a proof of size l, the existence of a uniform\\n\\nproof is established reasoning by induction on l, using Lemma 4.5.\\n\\n4.3 The calculus UC\\n\\nNow we know that uniform proofs are complete for IC, and their goal-oriented\\n\\nformat renders them close to the goal solving procedure we are looking for. However,\\n\\nas an intermediate step we will present a second proof system UC for HH(C), which\\n\\nwill enjoy three properties:\\n\\na) UC and IC have the same provable sequents.\\n\\nb) UC builds only Uniform proofs, and it is parameterized by a given Constraint\\n\\nsystem.\\n\\nc) ⊢UC replaces the left-introduction rules by a backchaining mechanism.\\n\\nUC-derivations are very close to our intended computations. Therefore, the UC\\n\\nsystem will be very useful for designing a sound and complete goal solving procedure\\n\\nin the next section.\\n\\nProvability in UC is defined as follows. ∆; Γ ⊢UC G if and only if the sequent\\n\\n∆; Γ |—G has a proof using the following rules:\\n\\n• Axiom to deal with constraints:\\n\\nΓ ⊢C C\\n\\n∆; Γ |— C\\n(CR)\\n\\n• Backchaining rule for atomic goals:\\n\\n∆; Γ |— ∃x1 . . .∃xn((A ≈ A′) ∧ G)\\n\\n∆; Γ |— A′\\n(Clause)\\n\\nwhere A, A′ begin with the same predicate symbol and ∀x1 . . . ∀xn(G ⇒ A)\\n\\nis a variant of a formula of elab(∆), where x1, . . . , xn do not appear free in\\n\\nthe sequent of the conclusion.\\n\\n• Rules introducing the connectives and quantifiers of the goals:\\n\\n(∨R), (∧R), (⇒R), (⇒CR), (∃R), (∀R).\\n\\nDefined as in the system IC.\\n\\nThe structure of the rule (Clause), that encapsulates a backchaining mechanism,\\n\\ncorresponds to the method by which atomic goals, A′, will be solved by the goal\\n\\nsolving procedure to be presented in Section 5. As usual in logic programming, an\\n\\n“instance” of a clause with head A and body G is searched, in such a way that\\n\\n\\n\\n16 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nA ≈ A′ and G can be proved. By the definition of UC, the existential quantification\\n\\non the right hand side of the premise sequent forces a search for this “instance”\\n\\n(managed by means of constraints in our system). Note that a similar behaviour\\n\\nwould result from the application of (∀L) if we would make use of IC.\\n\\nThe next auxiliary lemma is needed to show that UC and IC have the same\\n\\ndeductive power. It can be viewed as a particular kind of cut elimination for IC,\\n\\nwhere the cut formula is taken from the elaboration of the program in the left\\n\\nside of the sequent. We cannot apply directly any classical cut elimination result,\\n\\nbecause constraint entailment is embedded into our proof system.\\n\\nLemma 4.7 (Elaboration)\\n\\nFor any ∆, Γ, A and F ∈ elab(∆): if ∆, F ; Γ ⊢IC A, then ∆; Γ ⊢IC A.\\n\\nProof\\n\\nIt appears in the Appendix.\\n\\nNow we can prove the promised equivalence between UC and IC.\\n\\nTheorem 4.8\\n\\nThe proof systems IC and UC are equivalent. That means, for any program ∆, for\\n\\nany set of constraints Γ, and for any goal G it holds:\\n\\n∆; Γ ⊢IC G if and only if ∆; Γ ⊢UC G.\\n\\nProof\\n\\nWe prove both implications by induction on the size of proofs.\\n\\n⇒) Assuming ∆; Γ ⊢IC G, we prove ∆; Γ ⊢UC G by case analysis on the structure\\n\\nof G.\\n\\nIf G ≡ A, by the Proof Transformation Lemma (4.5) there are n (n ≥ 0)\\n\\nconstraints C1, . . . , Cn, a variant ∀x1 . . . ∀xn(G′ ⇒ A′) of some formula of\\n\\nelab(∆), with x1, . . . , xn new distinct variables, xi not appearing free in\\n\\n', 'C1,. . . , Ci−1, for 1 < i ≤ n, and A, A′ beginning with the same predicate\\n\\nsymbol, such that:\\n\\n(a) Γ ⊢C ∃x1C1; Γ, C1 ⊢C ∃x2C2; . . . ; Γ, C1, . . . , Cn−1 ⊢C ∃xnCn.\\n\\n(b) Γ, C1, . . . , Cn ⊢C A′ ≈ A.\\n\\n(c) ∆; Γ, C1, . . . , Cn ⊢IC G′, with a shorter proof, or G′ ≡ ⊤.\\n\\nBy (b) and (CR), ∆; Γ, C1, . . . , Cn ⊢UC A′ ≈ A. By (c) and the induction\\n\\nhypothesis, ∆; Γ, C1, . . . , Cn ⊢UC G′. Note that if G′ ≡ ⊤, the proof of\\n\\nthis sequent is a direct consequence of the rule (CR). So applying (∧R),\\n\\n∆, Γ, C1, . . . , Cn ⊢UC (A′ ≈ A) ∧ G′. Now, in accordance with (a) and\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 17\\n\\nthe conditions on x1, . . . , xn, it is possible to apply (∃R) n times obtaining\\n\\n∆; Γ ⊢UC ∃x1 . . . ∃xn((A′ ≈ A)∧G′). Therefore, using (Clause), ∆; Γ ⊢UC A.\\n\\nThe cases for non atomic formulas are immediate due to the Proof Transfor-\\n\\nmation Lemma (4.5), the definition of UC and the induction hypothesis.\\n\\n⇐) Let us also prove only the atomic case, the others are proved using the induc-\\n\\ntion hypothesis and the definition of the calculi UC, IC.\\n\\nAssume ∆; Γ ⊢UC A, then by the definition of UC the rule (Clause) has been\\n\\napplied and ∆; Γ ⊢UC ∃x1 . . . ∃xn((A′ ≈ A)∧G′), with a shorter proof, where\\n\\n∀x1 . . . ∀xn(G′ ⇒ A′) is a variant of a formula of elab(∆) with x1, . . . , xn new\\n\\nvariables and A, A′ beginning with the same predicate symbol. Because of\\n\\nthe form of UC’s inference rules, the only way to derive this sequent is by n\\n\\nsuccessive applications of (∃R). Since x1, . . . , xn are new2, we can assume:\\n\\n(a) Γ ⊢C ∃x1C1; Γ, C1 ⊢C ∃x2C2; . . . ; Γ, C1, . . . , Cn−1 ⊢C ∃xnCn.\\n\\n(b) ∆; Γ, C1, . . . , Cn ⊢UC (A′ ≈ A) ∧ G′, with a shorter proof.\\n\\nThen by (b) and according to the definition of UC, ∆; Γ, C1, . . . , Cn ⊢UC\\n\\nA′ ≈ A and ∆; Γ, C1, . . . , Cn ⊢UC G′ with shorter proofs. Therefore, by the\\n\\ninduction hypothesis,\\n\\n∆; Γ, C1, . . . , Cn ⊢IC A′ ≈ A (†) and\\n\\n∆; Γ, C1, . . . , Cn ⊢IC G′ (‡).\\n\\n(†) implies Γ, C1, . . . , Cn ⊢C A′ ≈ A, by the Proof Transformation Lemma\\n\\n(4.5). Then, by (Atom),\\n\\n∆, A′; Γ, C1, . . . , Cn ⊢IC A (⋄),\\n\\nso applying (⇒L) to (‡) and (⋄),\\n\\n∆, G′ ⇒ A′; Γ, C1, . . . , Cn ⊢IC A.\\n\\nNow by n applications of (∀L), using (a) and the conditions on x1 . . . , xn, we\\n\\nobtain\\n\\n∆, ∀x1 . . . ∀xn(G′ ⇒ A′); Γ ⊢IC A.\\n\\nTherefore by the Elaboration Lemma (4.7) ∆; Γ ⊢IC A.\\n\\nThe properties stated in Lemma 4.2 and Lemma 4.4 hold also for UC-derivability.\\n\\nThis is ensured by the next two lemmas that are proved in the Appendix.\\n\\n2 Without loss of generality we can consider that xi does not appear free in C1, . . . , Ci−1, for\\n\\n1 < i ≤ n.\\n\\n\\n\\n18 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nLemma 4.9\\n\\nFor any ∆, Γ, G, if Γ′ is a set of constraints such that Γ′ ⊢C Γ, and ∆; Γ ⊢UC G,\\n\\nthen ∆; Γ′ |— G has a UC-proof of the same size.\\n\\nLemma 4.10\\n\\nFor any ∆, Γ, C, G, if ∆; Γ, C ⊢UC G and x is a variable that does not appear free\\n\\nin ∆, Γ, G, then ∆; Γ, ∃xC |— G has a UC-proof of the same size.\\n\\nFrom now on we will work only with the calculus UC.\\n\\n5 A Goal Solving Procedure\\n\\nWe now turn to the view of HH(C) as a logic programming language. Solving a goal\\n\\nG using a program ∆ means finding a C-satisfiable constraint R such that\\n\\n∆; R ⊢UC G.\\n\\nAny constraint R with this property is called a correct answer constraint. For in-\\n\\nstance, R ≡ x2 ≤ 1/2 is a correct answer constraint for the disc example, as shown\\n\\nin the introduction.\\n\\nWe will present a goal solving procedure as a transition system. Goal solving will\\n\\nproceed by transforming an initial state through a sequence of intermediate states,\\n\\nending in a final state. Each state will conserve the goals that remain to be solved\\n\\nand a partially calculated answer constraint. The final state will not have any goal\\n\\nto be solved. In the following we will formalize these ideas and show soundness and\\n\\ncompleteness of the proposed procedure.\\n\\nDefinition 5.1\\n\\nA state w.r.t. a finite set of variables V , written S, has the form Π[S2G] where:\\n\\nG is a multiset of triples 〈∆, C, G〉 (∆ local program, C local constraint formula\\n\\nand G local goal). Π is a quantifier prefix Q1x1. . .Qkxk where x1, . . . , xk are distinct\\n\\nvariables not belonging to V , and every Qi, 1 ≤ i ≤ k, is the quantifier ∀ or ∃. S is\\n\\na global constraint formula.\\n\\nThis complex notion of state is needed because the goal solving transformations,\\n\\npresented below, introduce local clauses and local constraints. Of course, local\\n\\nclauses also arise in HH, see (Nadathur, 1993). Initial states are quite simple as\\n\\ncan be seen in Definition 5.3.\\n\\nWe say that a state Π[S2G] is satisfiable iff the associated constraint formula ΠS,\\n\\nalso called partially calculated answer constraint, is C-satisfiable.\\n\\nIf Π′, Π are quantifier prefixes such that Π′ coincides with the first k elements of\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 19\\n\\nΠ, 0 ≤ k ≤ n, where n is the number of elements of Π, then Π − Π′ represents the\\n\\nresult of eliminating Π′ of Π. For instance ∀x∀y∃z∀u∃v − ∀x∀y∃z ≡ ∀u∃v.\\n\\n', 'To represent a multiset G, we will simply write its elements separated by commas,\\n\\nassuming that repetitions are relevant but ordering is not. In particular, the notation\\n\\nG, 〈∆, C, G〉 stands for any multiset which includes at least one occurrence of the\\n\\ntriple 〈∆, C, G〉.\\n\\nDefinition 5.2 (Rules for transformation of states)\\n\\nThe transformations permitting to pass from a state S w.r.t. a set of variables V ,\\n\\nto another state S′ w.r.t. V , written as S‖—S′, are the following:\\n\\ni) Conjunction.\\n\\nΠ[S2G, 〈∆, C, G1 ∧ G2〉] ‖— Π[S2G, 〈∆, C, G1〉, 〈∆, C, G2〉].\\n\\nii) Disjunction.\\n\\nΠ[S2G, 〈∆, C, G1 ∨ G2〉] ‖— Π[S2G, 〈∆, C, Gi〉], for i = 1 or 2\\n\\n(don’t know choice).\\n\\niii) Implication with local clause.\\n\\nΠ[S2G, 〈∆, C, D ⇒ G〉] ‖— Π[S2G, 〈∆ ∪ {D}, C, G〉].\\n\\niv) Implication with local constraint.\\n\\nΠ[S2G, 〈∆, C, C′ ⇒ G〉] ‖— Π[S2G, 〈∆, C ∧ C′, G〉].\\n\\nv) Existential quantification.\\n\\nΠ[S2G, 〈∆, C, ∃xG〉] ‖— Π∃w[S2G, 〈∆, C, G[w/x]〉],\\n\\nwhere w does not appear in Π nor in V .\\n\\nvi) Universal quantification.\\n\\nΠ[S2G, 〈∆, C, ∀xG〉] ‖— Π∀w[S2G, 〈∆, C, G[w/x]〉],\\n\\nwhere w does not appear in Π nor in V .\\n\\nvii) Constraint.\\n\\nΠ[S2G, 〈∆, C, C′〉] ‖— Π[S ∧ (C ⇒ C′)2G].\\n\\nIf Π(S ∧ (C ⇒ C′)) is C-satisfiable.\\n\\nviii) Clause of the program.\\n\\nΠ[S2G, 〈∆, C, A〉] ‖— Π[S2G, 〈∆, C, ∃x1 . . . ∃xn((A′ ≈ A) ∧ G)〉].\\n\\nProvided that ∀x1 . . .∀xn(G ⇒ A′) is a variant of some clause in elab(∆)\\n\\n(don’t know choice), x1, . . . , xn do not appear in Π nor in V , and A′, A begin\\n\\nwith the same predicate symbol.\\n\\nNote that every transformation can be applied to an arbitrary triple 〈∆, C, G〉\\n\\nwithin the state, since G is viewed as a multiset. Moreover, all choices involved\\n\\nin carrying out a sequence of state transformations are don’t care, except those\\n\\nexplicitly labeled as don’t know in transformations ii) and viii) above. One can\\n\\n\\n\\n20 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\ncommit to don’t care choices without compromising completeness. In other words:\\n\\nat the implementation level, backtracking is needed only for don’t know choices.\\n\\nThe following definition formalizes the setting needed for goal solving.\\n\\nDefinition 5.3\\n\\nThe initial state for a program ∆ and a goal G is a state w.r.t. the set of free\\n\\nvariables of ∆ and G consisting in S0 ≡ [⊤2〈∆,⊤, G〉].\\n\\nA resolution of a goal G from a program ∆ is a finite sequence of states w.r.t. the\\n\\nfree variables of ∆ and G, S0, . . . ,Sn, such that:\\n\\n• S0 is the initial state for ∆ and G.\\n\\n• Si−1‖—Si, 1 ≤ i ≤ n, by means of any of the transformation rules.\\n\\n• The final state Sn has the form Πn[Sn2∅].\\n\\nThe constraint ΠnSn is called the answer constraint of this resolution.\\n\\nExample 5.1\\n\\nUsing ∆, G and R as given in the disc example (see the Introduction) it is possible\\n\\nto build a resolution of G from ∆ with answer constraint R as follows:\\n\\n[⊤2〈∆,⊤, ∀y(y2 ≤ 1/2 ⇒ disc (x, y))〉] ‖—vi)\\n\\n∀y[⊤2〈∆,⊤, y2 ≤ 1/2 ⇒ disc (x, y)〉] ‖—iv)\\n\\n∀y[⊤2〈∆, y2 ≤ 1/2, disc (x, y)〉] ‖—viii)\\n\\n∀y[⊤2〈∆, y2 ≤ 1/2, ∃u∃v(x ≈ u ∧ y ≈ v ∧ u2 + v2 ≤ 1/2)〉] ‖—vii)\\n\\n∀y[y2 ≤ 1/2 ⇒ ∃u∃v(x ≈ u ∧ y ≈ v ∧ u2 + v2 ≤ 1)2∅]\\n\\nsince ∀y(y2 ≤ 1/2 ⇒ ∃u∃v(x ≈ u ∧ y ≈ v ∧ u2 + v2 ≤ 1)) is R-satisfiable.\\n\\nSo the answer constraint is\\n\\n∀y(y2 ≤ 1/2 ⇒ ∃u∃v(x ≈ u ∧ y ≈ v ∧ u2 + v2 ≤ 1)) ⊢⊣R\\n\\n∀y(y2 ≤ 1/2 ⇒ x2 + y2 ≤ 1) ⊢⊣R x2 ≤ 1/2. 2\\n\\nFor CLP programs, the goal transformations ii), iii), iv) and vi) can never be\\n\\napplied. Therefore, the state remains of the form Π[S2G], where Π includes only ex-\\n\\nistential quantifiers and G is a multiset of triples 〈∆, C, G〉 such that ∆ is the global\\n\\nprogram. For states of this kind, the goal transformations i), v), vii) and viii) spec-\\n\\nify constrained SLD resolution, as used in CLP; see e.g. (Jaffar and Maher, 1994;\\n\\nJaffar et al., 1996). On the other hand, traditional HH programs can be emulated\\n\\nin our framework by using the Herbrand constraint system H and avoiding con-\\n\\nstraints in programs and initial goals. Then transformation iv) becomes useless,\\n\\nand the remaining goal transformations can be viewed as a more abstract formu-\\n\\nlation of the goal solving procedure from (Nadathur, 1993). Transformation viii)\\n\\nintroduces equational constraints in intermediate goals, and in transformation vii)\\n\\nthe local constraint C is simply ⊤. Therefore, Π(S ∧ (C ⇒ C′)) is equivalent to\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 21\\n\\nΠ(S∧C′), where S∧C′ can be assumed to be a conjunction of equations. Checking\\n\\nH-satisfiability of Π(S ∧ C′) corresponds to solving a unification problem under a\\n\\nmixed prefix in (Nadathur, 1993).\\n\\nAdmittedly, the labeled unification algorithm presented in (Nadathur, 1993) is\\n\\ncloser to an actual implementation, while our description of goal solving is more\\n\\nabstract. Note, however, that the goal solving transformations are open to efficient\\n\\nimplementation techniques. In particular, when vii) adds a new constraint to the\\n\\nglobal constraint S, the satisfiability of the new partially calculated answer con-\\n\\nstraint should be checked incrementally, without repeating all the work previously\\n\\ndone for ΠS. ', 'Of course, delaying the constraint satisfiability checks until the end\\n\\nis neither necessary nor convenient.\\n\\n5.1 Soundness\\n\\nSoundness of the goal solving procedure means that if R is the answer constraint\\n\\nof a resolution of a goal G from a program ∆, then the sequent ∆;R |— G has a\\n\\nUC-proof.\\n\\nThe soundness theorem is based on two auxiliary results. The first one ensures\\n\\nthat states remain satisfiable along any resolution.\\n\\nLemma 5.1\\n\\nLet S0, . . . ,Sn be a resolution of a goal G from a program ∆, and V the set of\\n\\nfree variables of ∆ and G. Then, for any i, 0 ≤ i ≤ n, if Si ≡ Πi[Si2Gi], then the\\n\\nfollowing properties are satisfied:\\n\\n1. The free variables of the formulas of Gi, and Si are in Πi or in V .\\n\\n2. Si is satisfiable.\\n\\nProof\\n\\nThe first property is a consequence of the procedure used to build the prefix of a\\n\\nstate. The initial state satisfies it by definition, and when passing from state Si−1\\n\\nto state Si, 1 ≤ i ≤ n, if we include new free variables, these will be quantified\\n\\nuniversally or existentially by Πi.\\n\\nFor the second property, note that S0 ≡ ⊤ by definition. Moreover, for each\\n\\ntransformation step Si−1‖—Si, one of the three following cases applies:\\n\\n• Si ≡/ Si−1. Then the transition must correspond to the transformation vii)\\n\\nwhich requires C-satisfiability of Πi(Si).\\n\\n• Si ≡ Si−1 and Πi ≡ Πi−1. This case is trivial.\\n\\n\\n\\n22 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\n• Si ≡ Si−1 and Πi ≡ Πi−1Qw, where Q is ∀ or ∃ and w is a new variable not\\n\\nfree in Si−1, and not occurring in Πi−1. Under these conditions,\\n\\nΠiSi ≡ Πi−1QwSi−1 ⊢⊣C Πi−1Si−1,\\n\\nand C-satisfiability propagates from Πi−1Si−1 to ΠiSi.\\n\\nThe second auxiliary lemma means that correct answer constraints are preserved\\n\\nby any resolution step.\\n\\nLemma 5.2\\n\\nAssume S ≡ Π[S2G] and S′ ≡ ΠΠ′[S′\\n2G′] are two states w.r.t. a set of variables\\n\\nV , such that S‖—S′. If R′ is a constraint with its free variables in ΠΠ′ or in V , and\\n\\nsuch that R′ ⊢C S′ and for any 〈∆′, C′, G′〉 ∈ G′, ∆′; R′, C′ ⊢UC G′, then Π′R′ ⊢C S\\n\\nand for any 〈∆, C, G〉 ∈ G, ∆; Π′R′, C ⊢UC G.\\n\\nProof\\n\\nWe analyze the different cases, according to the transformation applied. We show\\n\\nhere the first case, the other cases appear in the Appendix.\\n\\ni) Conjunction. Π′ is empty and S ≡ S′, so Π′R′ ⊢C S obviously. On the other\\n\\nhand, let 〈∆, C, G〉 ∈ G:\\n\\nIf 〈∆, C, G〉 ∈ G′, then ∆; Π′R′, C ⊢UC G by hypothesis, since Π′R′ ≡ R′.\\n\\nIf 〈∆, C, G〉 /∈ G′, then G ≡ G1∧G2 and 〈∆, C, G1〉, 〈∆, C, G2〉 ∈ G′. Therefore\\n\\n∆; Π′R′, C ⊢UC G1 and ∆; Π′R′, C ⊢UC G2, by hypothesis, since Π′R′ ≡ R′,\\n\\nand consequently ∆; Π′R′, C ⊢UC G, by applying (∧R).\\n\\nTheorem 5.3 (Soundness)\\n\\nLet ∆ be any program. If G is a goal such that there is a resolution S0, . . . ,Sn of G\\n\\nfrom ∆ with answer constraint R ≡ ΠnSn, then R is C-satisfiable and ∆; R ⊢UC G.\\n\\nProof\\n\\nThe proof is direct from the previous lemmas. C-satisfiability of R is a consequence\\n\\nof item 2 of Lemma 5.1. Besides using Lemma 5.2 we can prove, that for 0 ≤ i ≤ n,\\n\\n∆; (Πn − Πi)Sn, C ⊢UC G, for any 〈∆, C, G〉 ∈ Gi, and (Πn − Πi)Sn ⊢C Si.\\n\\nThe case i = 0 of this result assures the theorem. Let us prove it by induction\\n\\non the construction of S0, . . . ,Sn, but beginning from the last state. The base\\n\\ncase is obvious because Gn = ∅ and (Πn − Πn)Sn ⊢C Sn holds trivially. For the\\n\\ninduction step, we suppose the result for Si+1, . . . ,Sn, and we prove it for Si. Taking\\n\\n(Πn − Πi+1)Sn as the constraint R′ of Lemma 5.2, the induction hypothesis for\\n\\ni + 1 indicates that the conditions of Lemma 5.2 are satisfied for S′ ≡ Si+1, then\\n\\nthis lemma affirms that the result is true for Si as we wanted to prove.\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 23\\n\\n5.2 Completeness\\n\\nCompleteness of the goal solving procedure states that given a program ∆, and a\\n\\ngoal G such that ∆; R0 ⊢UC G for a C-satisfiable constraint R0, there is a resolution\\n\\nof G from ∆ with answer constraint R that is entailed by R0 in the constraint system\\n\\nC, i.e. R0 ⊢C R. Of course this entailment means that the computed answer R is\\n\\nat least as general as the given correct answer R0.\\n\\nIn order to prove this result, we introduce a well-founded ordering which measures\\n\\nthe complexity of proving that a given constraint is a correct answer for a given\\n\\nstate. The ordering is based on multisets.\\n\\nDefinition 5.4\\n\\nLet ∆ be a program, G a goal, and C, R, constraints such that ∆; R, C ⊢UC G,\\n\\nthen we define τR(∆, C, G) as the size of the shortest UC-proof of the sequent\\n\\n∆; R, C |— G.\\n\\nLet G be a multiset of triples 〈∆, C, G〉. We define MGR as the multiset of sizes\\n\\nτR(∆, C, G), where the multiplicity of τR(∆, C, G) in MGR coincides with the mul-\\n\\ntiplicity of 〈∆, C, G〉 in G.\\n\\nWe use the notation << for the well-founded multiset ordering (Dershowitz and Manna, 1979)\\n\\ninduced by the ordering < over the natural numbers.\\n\\nNext, we show that as long as a state can be transformed, the transformation\\n\\ncan be chosen to yield a smaller state with respect to <<, while essentially keeping\\n\\na given answer constraint R.\\n\\nLemma 5.4\\n\\n', 'Let S ≡ Π[S2G] be a non-final state w.r.t. a set of variables V , and let R be a\\n\\nconstraint such that ΠR is C-satisfiable and R ⊢C S. If ∆; R, C ⊢UC G for all\\n\\n〈∆, C, G〉 ∈ G, then we can find a rule transforming S in a state S′ ≡ Π′[S′\\n2G′]\\n\\n(S‖—S′) and a constraint R′ such that:\\n\\n1. ΠR ⊢C Π′R′ and R′ ⊢C S′.\\n\\n2. ∆′; R′, C′ ⊢UC G′ for all 〈∆′, C′, G′〉 ∈ G′. Moreover MG′R′ << MGR.\\n\\nProof\\n\\nBy induction on the structure of G, where 〈∆, C, G〉 ∈ G, analyzing cases. We show\\n\\nhere an illustrative case, the proof for the other cases appears in the Appendix.\\n\\nIf G has the form ∃xG1, applying the transformation v) we obtain S′. Let w be the\\n\\nvariable used in the substitution involved in this transformation. w does not appear\\n\\nin Π, V , and we can choose it also not free in R. By hypothesis ∆; R, C |— ∃xG1\\n\\nhas a proof of size l, then by the definition of UC, there is a constraint formula C1\\n\\n\\n\\n24 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nsuch that ∆; R, C, C1 |— G1[w/x] has a proof of size less than l and R, C ⊢C ∃wC1.\\n\\nLet R′ ≡ R ∧ (C ⇒ C1).\\n\\n1. R ⊢C ∃w(R ∧ (C ⇒ C1)), since w is not free in R, C, and R, C ⊢C ∃wC1,\\n\\ntherefore ΠR ⊢C Π∃w(R ∧ (C ⇒ C1)) ≡ Π′R′. Moreover, S′ ≡ S, R′ ⊢C R and\\n\\nR ⊢C S implies R′ ⊢C S′.\\n\\n2. Let 〈∆′, C′, G′〉 ∈ G′. If 〈∆′, C′, G′〉 ∈ G, then ∆′; R, C′ ⊢UC G′ by hy-\\n\\npothesis, and therefore, using R′ ⊢C R and Lemma 4.9, ∆′; R′, C′ ⊢UC G′ and\\n\\nτR′(∆′, C′, G′) ≤ τR(∆′, C′, G′).\\n\\nIf 〈∆′, C′, G′〉 /∈ G, then G′≡G1[w/x], ∆′≡∆ and C′≡C. ∆; R′, C |— G1[w/x] will\\n\\nalso have a proof of size less than l, since ∆;R,C,C1|— G1[w/x] has such a proof, due\\n\\nto R′, C ⊢C R, C, C1 and Lemma 4.9. So ∆′; R′, C′ ⊢UC G′ for all 〈∆′, C′, G′〉 ∈ G′,\\n\\nτR′(∆′, C′, G′) < τR(∆, C, G), and MG′R′ << MGR.\\n\\nTheorem 5.5 (Completeness)\\n\\nLet ∆ be a program, G a goal and R0 a C-satisfiable constraint such that ∆; R0 ⊢UC\\n\\nG. Then there is a resolution of G from ∆ with answer constraint R such that\\n\\nR0 ⊢C R.\\n\\nProof\\n\\nUsing Lemma 5.4, we can build a sequence S0‖—S1‖— . . . ‖—Sn of state transfor-\\n\\nmations, (Si ≡ Πi[Si2Gi], 0 ≤ i ≤ n), that is a a resolution of G from ∆, and a\\n\\nsequence of constraints R0, . . . , Rn satisfying that for all i, 1 ≤ i ≤ n:\\n\\n• R0 ⊢C ΠiRi,\\n\\n• Ri ⊢C Si,\\n\\n• ∆′; Ri, C\\n′ ⊢UC G′, for all 〈∆′, C′, G′〉 ∈ Gi.\\n\\nWe use an inductive construction that is guaranteed to terminate thanks to the\\n\\nwell-founded ordering <<. Let S0 ≡ [⊤2〈∆,⊤, G〉] be the initial state for ∆ and\\n\\nG, which we know is not final, if we take R0 as the constraint given by the theorem’s\\n\\nhypothesis, we obtain R0 ⊢C Π0R0 and R0 ⊢C S0, since Π0 is empty and S0 ≡ ⊤.\\n\\nMoreover, by hypothesis, ∆;R0 ⊢UC G is satisfied, and then also ∆; R0,⊤ ⊢UC G\\n\\nbecause of R0,⊤ ⊢C R0 and Lemma 4.9.\\n\\nAssume the result true for S0, . . . ,Si, if the state Si is not final, then Si and Ri\\n\\nfulfill the hypothesis of Lemma 5.4, thus there will be a state Si+1 (Si‖—Si+1) and\\n\\na constraint Ri+1 such that Ri+1 ⊢C Si+1 and ΠiRi ⊢C Πi+1Ri+1 (†) Further-\\n\\nmore, for all 〈∆′, C′, G′〉 ∈ Gi+1, ∆′; Ri+1, C\\n′ ⊢UC G′ and MGi+1Ri+1\\n\\n<< MGiRi\\n.\\n\\nTherefore, by the induction hypothesis, R0 ⊢C ΠiRi, and with (†) we obtain\\n\\nR0 ⊢C Πi+1Ri+1. By successive iteration, as << is well-founded, we must eventu-\\n\\nally get a final state Sn that will in fact satisfy R0 ⊢C ΠnRn and Rn ⊢C Sn and\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 25\\n\\nso R0 ⊢C ΠnSn, where ΠnSn ≡ R is the answer constraint of S0, . . . ,Sn. In this\\n\\nway we conclude R0 ⊢C R.\\n\\nFor HH(H) programs such that constraints appear neither in the left-hand side\\n\\nof implications nor in initial goals, Theorem 5.5 implies an alternative formulation\\n\\nof the completeness theorem given in (Nadathur, 1993) for a goal solving procedure\\n\\nfor first-order HH. In our opinion, using constraints and constraint satisfiability\\n\\ninstead of substitutions and unification under a mixed prefix, that requires low\\n\\nlevel representation details, we gain a more abstract presentation. For CLP pro-\\n\\ngrams, Theorem 5.5 becomes a stronger form of completeness, in comparison to\\n\\nthe strong completeness theorem for success given in (Maher, 1987), Th. 2 (see also\\n\\n(Jaffar et al., 1996), Th. 4.12). There, assuming ∆; R |=C G, the conclusion is that\\n\\nR ⊢C\\n\\n∨m\\n\\ni=1 Ri where R1, . . . , Rm are answer constraints computed in m different\\n\\nresolutions of G from ∆. Example 5.2 below was used in (Maher, 1987) to illustrate\\n\\nthe need of considering disjunctions of computed answers. In fact, there is no single\\n\\ncomputed answer R0 such that R ⊢H R0. However, this fact doesn’t contradict\\n\\nTheorem 5.5, because ∆; R|—G is not UC-derivable, as we will see immediately.\\n\\nExample 5.2\\n\\nThis example is borrowed from (Maher, 1987). It belongs to the instance HH(H)\\n\\ngiven by the Herbrand constraint system. Consider\\n\\n∆ ≡ {D1, D2}, with D1 ≡ p(a, b), D2 ≡ ∀x(x ≈/ a ⇒ p(x, b)),\\n\\nG ≡ p(x, y),\\n\\nR ≡ y ≈ b.\\n\\nUp to trivial syntactic variants, this is a CLP(H)-program. According to the model\\n\\ntheoretic semantics of CLP(H), we get ∆; R |=H G, because either x ≈ a or x ≈/ a\\n\\nwill hold in each H-model of ∆∪{R}. ', 'In contrast to this, in UC we only can derive\\n\\n∆; R ∧ x ≈ a |— G (using D1) and ∆; R ∧ x ≈/ a |— G (using D2). And it is easy to\\n\\ncheck that both answers R ∧ x ≈ a and R ∧ x ≈/ a can be computed by the goal\\n\\nsolving transformations. But we do not obtain ∆;R ⊢UC G. Since R ⊢/H x ≈ a,\\n\\nR ⊢/H x ≈/ a, neither D1 nor D2 can be used to build a UC-proof. 2\\n\\nThe example shows a difference between the model-theoretic semantics used in\\n\\nCLP (Maher, 1987) and our proof-theoretical semantics, based on provability in the\\n\\ncalculus UC. The latter deals with the logical symbols in goals and clauses according\\n\\nto the inference rules of intuitionistic logic. Therefore UC-provability turns out to\\n\\nbe more constructive than CLP’s model-theoretic semantics, and thus closer to\\n\\nconstrained resolution. This is the ultimate reason why our completeness Theorem\\n\\n5.5 involves no disjunction of computed answers.\\n\\n\\n\\n26 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nAs an illustration of the goal solving procedure, we show next the detailed reso-\\n\\nlution of the second goal from Example 2.3.\\n\\nExample 5.3\\n\\nLet us recall the program and goal from Example 2.3. As usual in programming\\n\\npractice, we write program clauses ∀x1 . . . ∀xn(G ⇒ A) in the form A ⇐ G3.\\n\\n∆ ≡ { mortgage(P, T, I, M, B) ⇐ 0 ≤ T ∧ T ≤ 3 ∧\\n\\nTotalInt ≈ T ∗ (P ∗ I/1200) ∧ B ≈ P + TotalInt − (T ∗ M),\\n\\nmortgage(P, T, I, M, B) ⇐ T > 3 ∧ QuartInt ≈ 3 ∗ (P ∗ I/1200)∧\\n\\nmortgage(P + QuartInt − 3 ∗ M, T − 3, I, M, B)\\n\\n}\\n\\nG ≡ ∀M∀P (0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒\\n\\n∃I(0 ≤ Imin ≤ I ≤ Imax ∧ mortgage(P, 6, I, M, 0))).\\n\\nWe present a resolution of G from ∆, using the state transformation rules i) to\\n\\nviii) from Definition 5.2:\\n\\n[⊤2〈∆,⊤, G〉]\\n\\n‖—vi)\\n\\n∀M∀P [⊤2〈∆,⊤, 0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ ∃I(0 ≤ Imin ≤ I ≤ Imax ∧\\n\\nmortgage(P, 6, I, M, 0))〉]\\n\\n‖—iv)\\n\\n∀M∀P [⊤2〈∆, 0.9637 ≤ P/(6 ∗ M) ≤ 0.97,\\n\\n∃I(0 ≤ Imin ≤ I ≤ Imax ∧ mortgage(P, 6, I, M, 0))〉]\\n\\n‖—v)\\n\\n∀M∀P∃I[⊤2 〈∆, 0.9637 ≤ P/(6 ∗ M) ≤ 0.97,\\n\\n0 ≤ Imin ≤ I ≤ Imax ∧ mortgage(P, 6, I, M, 0)〉]\\n\\n‖—i),vii)\\n\\n∀M∀P∃I[0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax2\\n\\n〈∆, 0.9637 ≤ P/(6 ∗ M) ≤ 0.97,mortgage(P, 6, I, M, 0)〉]\\n\\n‖—viii)\\n\\n∀M∀P∃I[0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax2\\n\\n〈∆, 0.9637 ≤ P/(6 ∗ M) ≤ 0.97,\\n\\n∃P ′∃T ′∃I ′∃M ′∃B′∃QuartInt(P ≈ P ′ ∧ 6 ≈ T ′ ∧ I ≈ I ′\\n︸ ︷︷ ︸\\n\\n∧M ≈ M ′ ∧ 0 ≈ B′ ∧ T ′ > 3 ∧QuartInt≈3∗(P ′∗I ′/1200)\\n︸ ︷︷ ︸\\n\\n∧mortgage(P ′+QuartInt−3 ∗ M ′, T ′−3, I ′, M ′, B′))\\n︸ ︷︷ ︸\\n\\n〉]\\n\\n3 In fact, we have already followed this convention in Section 2.\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 27\\n\\nSimplifying the underbraced formula in the constraint system R, we obtain:\\n\\n∀M∀P∃I[0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax2\\n\\n〈∆, 0.9637 ≤ P/(6 ∗ M) ≤ 0.97,\\n\\nmortgage(P + 3 ∗ (P ∗ I/1200)− 3 ∗ M, 3, I, M, 0)〉]\\n\\n‖—viii)\\n\\n∀M∀P∃I[0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax2\\n\\n〈∆, 0.9637 ≤ P/(6 ∗ M) ≤ 0.97,\\n\\n∃P ′′∃T ′′∃I ′′∃M ′′∃B′′∃TotalInt(P ′′ ≈ P + 3 ∗ (P ∗ I/1200)− 3 ∗ M\\n︸ ︷︷ ︸\\n\\n∧ T ′′ ≈ 3 ∧ I ′′ ≈ I ∧ M ′′ ≈ M ∧ B′′ ≈ 0 ∧ 0 ≤ T ′′ ∧ T ′′ ≤ 3\\n︸ ︷︷ ︸\\n\\n∧ TotalInt ≈ T ′′ ∗ (P ′′ ∗ I ′′/1200) ∧ B′′ ≈ P ′′ + TotalInt− (T ′′ ∗ M ′′))\\n︸ ︷︷ ︸\\n\\n〉]\\n\\nAnd simplifying anew the underbraced formula in R:\\n\\n∀M∀P∃I[0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax2\\n\\n〈∆, 0.9637 ≤ P/(6 ∗ M) ≤ 0.97,\\n\\n0 ≈ P + 3 ∗ (P ∗ I/1200)− 3 ∗ M+\\n\\n3 ∗ (P + 3 ∗ (P ∗ I/1200)− 3 ∗ M) ∗ I/1200 − 3 ∗ M〉]\\n\\nApplying now transformation vii), we obtain the following answer constraint:\\n\\n∀M∀P∃I((0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax)) ∧\\n\\n(0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≈ P + 3 ∗ P ∗ I/1200− 3 ∗ M+\\n\\n3 ∗ (P + 3 ∗ P ∗ I/1200− 3 ∗ M) ∗ I/1200− 3 ∗ M))\\n\\n⊢⊣R\\n\\n∀M∀P∃I(0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax∧\\n\\n0 ≈ P ∗ (1 + 3 ∗ I\\n1200 + 3 ∗ I\\n\\n1200 + 9 ∗ I2\\n\\n12002 ) − M ∗ (6 + 9 ∗ I\\n1200 ))\\n\\n⊢⊣R\\n\\n∀M∀P∃I(0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax∧\\n\\n0 ≈ P ∗ (1 + I\\n200 + I2\\n\\n4002 ) − M ∗ (6 + 3 ∗ I\\n400 ))\\n\\n⊢⊣R\\n\\n∀M∀P∃I(0.9637 ≤ P/(6 ∗ M) ≤ 0.97 ⇒ 0 ≤ Imin ≤ I ≤ Imax∧\\nP\\n\\n6∗M\\n≈\\n\\n1+ I\\n\\n800\\n\\n1+ I\\n\\n200\\n+ I2\\n\\n4002\\n\\n) ≡ C1\\n\\nWe prove C1 ⊢⊣R Imin ≈ 8.219559 (approx.) ∧ Imax ≈ 10. In effect, let\\n\\nf(I) =\\n1 + I\\n\\n800\\n\\n1 + I\\n200 + I2\\n\\n4002\\n\\n,\\n\\n\\n\\n28 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nwe observe that f(I) is a strictly decreasing continuous function of I for any I ≥ 0,\\n\\nand also that\\n\\nf(I) ≈ 0.9637(approx.) ⊢⊣R I ≈ 10, and\\n\\nf(I) ≈ 0.97 ⊢⊣R I ≈ 8.219559 (approx.).\\n\\nThen, C1 is true iff for any M and P such that\\n\\nP/(6 ∗ M) ∈ [0.97..0.9637 (approx.)],\\n\\nthere exists I ∈ [Imax..Imin] such that f(I) ≈ P/(6 ∗ M) (f strictly decreasing\\n\\ncontinuous function), and this is true iff I has its maximum value for f(I) ≈\\n\\n0.9637 (approx.) and its minimum for f(I) ≈ 0.97, or equivalently Imax ≈ 10 ∧\\n\\nImin ≈ 8.219559 (approx.). 2\\n\\n6 Conclusions and Future Work\\n\\nWe have proposed a novel combination of Constraint Logic Programming (CLP)\\n\\nwith first-order Hereditary Harrop Formulas (HH ). Our framework includes a proof\\n\\nsystem with the uniform proofs property and a sound and complete goal solving\\n\\nprocedure. Our results are parametric w.r.t. a given constraint system C, and they\\n\\n', 'can be related to previously known results for CLP and HH. Therefore, we can\\n\\nspeak of a scheme whose expressivity sums the advantages of CLP and HH.\\n\\nAs far as we know, our work is the first attempt to combine the full expres-\\n\\nsivity of HH and CLP. A related, but more limited approach, can be found in\\n\\n(Darlington and Guo, 1994). This paper presents an amalgamated logic that com-\\n\\nbines the Horn fragment of intuitionistic logic with the entailment relation of a\\n\\ngiven constraint system, showing the existence of uniform proofs as well as sound-\\n\\nness and completeness of constrained SLD resolution w.r.t. the proof system. The\\n\\nmore general case of HH is not studied. Moreover, the presentation of constrained\\n\\nSLD resolution is not fully satisfactory, because the backchaining transition rule,\\n\\nsee (Darlington and Guo, 1994), guesses an arbitrary instance of a program clause,\\n\\ninstead of adding unification constraints to the new goal, as done in our state tran-\\n\\nsition rule viii).\\n\\nSeveral interesting issues remain for future research. Firstly, more concrete ev-\\n\\nidence on potential application areas should be found. We are currently looking\\n\\nfor CLP applications where greater HH expressivity may be useful, as well as for\\n\\ntypical HH applications that can benefit from the use of numeric and/or sym-\\n\\nbolic constraints. Secondly, tractable fragments of our formalism (other than CLP\\n\\nand HH separately) should be discovered. Otherwise, constraint satisfiability and\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 29\\n\\nconstraint entailment may become intractable or even undecidable. Our broad no-\\n\\ntion of constraint system includes any first-order theory based on arbitrary equa-\\n\\ntional axiomatization. Such theories are sometimes decidable, see (Comon, 1993;\\n\\nComon, Haberstrau and Jouannaud, 1994), but most often restricted fragments must\\n\\nbe chosen to ensure decidability. Last but not least, our framework should be ex-\\n\\ntended to higher-order HH as used in many λ-Prolog applications.\\n\\nAcknowledgement We are grateful to the anonymous referees for their construc-\\n\\ntive criticisms.\\n\\nAppendix\\n\\nProofs of results from Section 4.1\\n\\nLemma 4.1\\n\\nFor any ∆, Γ, G, x and t, if ∆; Γ ⊢IC G, then there is a proof of the same size of\\n\\n∆[t/x]; Γ[t/x] |— G[t/x].\\n\\nProof\\n\\nBy induction on the size l of the proof of the sequent ∆; Γ |— G.\\n\\nIf l = 1, then (CR) or (Atom) have been applied. In the first case, G ≡ C for some\\n\\nconstraint C and Γ ⊢C C. Hence Γ[t/x] ⊢C C[t/x], by the properties of ⊢C . There-\\n\\nfore the sequent ∆[t/x]; Γ[t/x] |— C[t/x] has a proof of size 1, by applying (CR). In\\n\\nthe second case, G ≡ A, for some predicate formula A, ∆ = ∆′ ∪ {A′}, with A′ be-\\n\\nginning with the same predicate symbol as A, and Γ ⊢C A′ ≈ A. Hence Γ[t/x] ⊢C\\n\\n(A′ ≈ A)[t/x]. Therefore, applying (Atom), ∆′[t/x], A′[t/x]; Γ[t/x] |— A[t/x] has a\\n\\nproof of size 1, and ∆[t/x] = ∆′[t/x] ∪ {A′[t/x]}.\\n\\nIf l > 1, we distinguish cases in accordance with the last rule applied in the\\n\\ndeduction of ∆; Γ |— G. Let us analyze some cases (the omitted ones are similar).\\n\\n(⇒CR) In this case G ≡ C ⇒ G′, and the last step of the proof has the form:\\n\\n∆; Γ, C |— G′\\n\\n∆; Γ |— C ⇒ G′\\n(⇒CR)\\n\\nBy the induction hypothesis, ∆[t/x]; Γ[t/x], C[t/x] |— G′[t/x] has a proof of size\\n\\nl−1. Then, applying (⇒CR), we obtain that ∆[t/x]; Γ[t/x] |— (C ⇒ G′)[t/x] has\\n\\na proof of size l.\\n\\n(∀R) In this case G ≡ ∀zG′ and the last step of the proof has the form:\\n\\n∆; Γ |— G′[y/z]\\n\\n∆; Γ |— ∀zG′\\n(∀R)\\n\\n\\n\\n30 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nwhere y does not appear free in the sequent of the conclusion. We can assume,\\n\\nwithout loss of generality, that z 6= x and z does not appear in t. If this were not\\n\\nthe case, the induction hypothesis could be applied another time, in order to re-\\n\\nname coincident variables. Also we can assume that y is different from x and that\\n\\ny does not occur in t. By the induction hypothesis, ∆[t/x]; Γ[t/x] |— G′[t/x][y/z]\\n\\nhas a proof of size l−1, because under our hypothesis, G′[y/z][t/x] ≡ G′[t/x][y/z].\\n\\nNow, applying (∀R), ∆[t/x]; Γ[t/x] |— ∀z(G′[t/x]) has a proof of size l, but this\\n\\nis the expected result because ∀z(G′[t/x]) ≡ (∀zG′)[t/x].\\n\\n(∀L) In this case ∆ = ∆′ ∪ {∀zD}. As before, we can assume that z 6= x and does\\n\\nnot appear in t, and the last step of the proof has the form:\\n\\n∆′, D[y/z]; Γ, C |— G Γ ⊢C ∃yC\\n\\n∆, ∀zD; Γ |—G\\n(∀L)\\n\\nwhere y does not appear free in the sequent of the conclusion. We can assume\\n\\nwithout loss of generality that y is different from x and that y does not occur in\\n\\nt. Then, by the induction hypothesis,\\n\\n∆′[t/x], D[t/x][y/z]; Γ[t/x], C[t/x] |—G[t/x] (†)\\n\\nhas a proof of size l−1, because under our hypothesis, D[y/z][t/x] ≡ D[t/x][y/z].\\n\\nNow Γ ⊢C ∃yC implies\\n\\nΓ[t/x] ⊢C ∃y(C[t/x]) (‡),\\n\\nby the properties of ⊢C and the fact that (∃yC)[t/x] ≡ ∃y(C[t/x]). Then applying\\n\\n(∀L) to (†) and (‡), ∆[t/x]; Γ[t/x] |— G[t/x] has a proof of size l, because\\n\\n∀z(D[t/x]) ≡ (∀zD)[t/x] and ∆[t/x] = ∆′[t/x] ∪ {(∀zD)[t/x]}.\\n\\nLemma 4.2\\n\\n', 'For any ∆, Γ, G, if Γ′ is a set of constraints such that Γ′ ⊢C Γ, and ∆; Γ ⊢IC G,\\n\\nthen ∆; Γ′ |— G has a proof of the same size.\\n\\nProof\\n\\nBy induction on the size of the proof of the sequent ∆; Γ |— G, by case analysis on\\n\\nthe last rule applied, and using the properties of entailment in constraint systems.\\n\\nIt is obvious for proofs of size 1. For proofs of size l > 1, let us analyze the case\\n\\n(∀L) (the others are similar). In this case, the last step of the proof is of the form:\\n\\n∆′, D[y/x]; Γ, C |— G Γ ⊢C ∃yC\\n\\n∆′, ∀xD; Γ |— G\\n(∀L)\\n\\nwhere y does not appear free in the sequent of the conclusion, and ∆ = ∆′∪{∀xD}.\\n\\nBy the induction hypothesis\\n\\n∆′, D[y/x]; Γ′, C |— G (†)\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 31\\n\\nhas a proof of size l− 1. We know that Γ ⊢C ∃yC, and by the hypothesis Γ′ ⊢C Γ,\\n\\nso\\n\\nΓ′ ⊢C ∃yC (‡).\\n\\nWe can assume that y does not appear free in Γ′, in other case, by Lemma 4.1,\\n\\nwe can work with ∆′, D[y′/x]; Γ′, C[y′/y] |—G (y′ new), instead of (†), and with\\n\\nΓ′ ⊢C ∃y′C[y′/y], instead of (‡), by the properties of ⊢C . Then we finish by applying\\n\\n(∀L) to (†) and (‡).\\n\\nLemma 4.4\\n\\nFor any ∆, Γ, C, G, if ∆; Γ, C ⊢IC G and x is a variable that does not appear free\\n\\nin ∆, Γ, G, then ∆; Γ, ∃xC |— G has a proof of the same size.\\n\\nProof\\n\\nBy induction on the size of the proof. We will assume that x appears free in C, if\\n\\nnot ∃xC ⊢C C, and the proof is immediate due to Lemma 4.2.\\n\\nIf ∆; Γ, C |— G has a proof of size 1, (Atom) or (CR) has been applied. In both\\n\\ncases Γ, C ⊢C C′ for certain constraint C′. Both C′ and Γ do not contain free\\n\\noccurrences of x, hence Γ, ∃xC ⊢C C′, and therefore ∆; Γ, ∃xC |— G has a proof of\\n\\nsize 1. If ∆; Γ, C |— G has a proof of size l > 1, let us discuss some of the possible\\n\\ncases.\\n\\n(∃R) Then G ≡ ∃zG′ and the last step of the proof is of the form:\\n\\n∆; Γ, C, C′ |— G′[y/z] Γ, C ⊢C ∃yC′\\n\\n∆; Γ, C |— ∃zG′\\n(∃R)\\n\\nwhere y does not appear free in the sequent of the conclusion. Hence, by Lemma\\n\\n4.2, ∆; Γ, C ∧ C′ |— G′[y/z] has a proof of size l − 1. Now, the conditions on y\\n\\nimply that x 6= y, so x is not free in G′[y/z], because it is not free in ∃zG′. Then,\\n\\nby the induction hypothesis and again using Lemma 4.2,\\n\\n∆; Γ, ∃xC, ∃x(C ∧ C′) |— G′[y/z] (†)\\n\\nhas a proof of size l − 1. On the other hand, Γ, C ⊢C ∃yC′ implies that Γ, C ⊢C\\n\\nC ∧ ∃yC′ so Γ, ∃xC ⊢C ∃x(C ∧ ∃yC′), since x is not free in Γ, thus\\n\\nΓ, ∃xC ⊢C ∃y∃x(C ∧ C′) (‡),\\n\\nsince y is not free in C. Therefore the desired result is obtained by applying (∃R)\\n\\nto (†) and (‡).\\n\\n(∀R) Then G ≡ ∀zG′, and the last step of the proof has the form:\\n\\n∆; Γ, C |— G′[y/z]\\n\\n∆; Γ, C |— ∀zG′\\n(∀R)\\n\\n\\n\\n32 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nwhere y does not appear free in the sequent of the conclusion. Then y does not\\n\\noccur free in C, so it is different from x. Applying the induction hypothesis to\\n\\nthe sequent ∆; Γ, C |— G′[y/z], we obtain that ∆; Γ, ∃xC |— G′[y/z] has a proof\\n\\nof size l − 1. Then ∆; Γ, ∃xC |— G has a proof\\n\\nof size l by (∀R).\\n\\nProofs of results from Section 4.2\\n\\nLemma 4.5 (Proof Transformation)\\n\\nIf G is a goal, ∆ a program and Γ a set of constraint formulas, such that ∆; Γ |— G\\n\\nhas a proof of size l, then:\\n\\n1. For G ≡ A, there are n constraint formulas C1, . . . , Cn (n ≥ 0) and a formula\\n\\n∀x1 . . . ∀xn (G′ ⇒ A′) that is a variant of some formula in elab(∆) such that\\n\\nx1, . . .,xn are new distinct variables not appearing free in ∆, Γ, A, where xi\\n\\ndoes not appear free in C1, . . .,Ci−1, for 1 < i ≤ n, and A′ begins with the\\n\\nsame predicate symbol as A. In addition it holds:\\n\\n(a) Γ ⊢C ∃x1C1; Γ, C1 ⊢C ∃x2C2; . . . ; Γ, C1, . . . , Cn−1 ⊢C ∃xnCn.\\n\\n(b) Γ, C1, . . . , Cn ⊢C A′ ≈ A.\\n\\n(c) ∆; Γ, C1, . . . , Cn |— G′ has a proof of size less than l, or G′ ≡ ⊤.\\n\\n2. If G ≡ C, then Γ ⊢C C.\\n\\n3. If G ≡ G1 ∧ G2, then ∆; Γ |— G1 and ∆; Γ |— G2 have proofs of size less than\\n\\nl.\\n\\n4. If G ≡ G1 ∨ G2, then ∆; Γ |— Gi has a proof of size less than l for i = 1 or 2.\\n\\n5. If G ≡ D ⇒ G1, then ∆, D; Γ |— G1 has a proof of size less than l.\\n\\n6. If G ≡ C ⇒ G1, then ∆; Γ, C |— G1 has a proof of size less than l.\\n\\n7. For G ≡ ∃xG1, if y is a variable not appearing free in ∆, Γ, G, then there is\\n\\na constraint formula C such that:\\n\\n(a) Γ ⊢C ∃yC.\\n\\n(b) ∆; Γ, C |— G1[y/x] has a proof of size less than l.\\n\\n8. If G ≡ ∀xG1, then ∆; Γ |— G1[y/x] has a proof of size less than l, where y is\\n\\na variable that does not appear free in ∆, Γ, G.\\n\\nProof\\n\\nWe reason by induction on the size l of a given IC-proof of ∆; Γ |— G.\\n\\nIf l is 1, then G has been proved by a single application of axiom (CR) or axiom\\n\\n(Atom). In the former case, G is a constraint and item 2 of the lemma holds. In\\n\\nthe latter case G is an atomic formula A and there is A′ ∈ ∆, beginning with\\n\\nthe same predicate symbol that A such that Γ ⊢C A′ ≈ A. But A′ ∈ ∆ implies\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 33\\n\\n⊤ ⇒ A′ ∈ elab(∆), then conditions (a), (b) and (c) of item 1 are satisfied with\\n\\nn = 0, G′ ≡ ⊤.\\n\\nIf l > 1, let us analyze cases according to the last inference rule applied in the\\n\\nproof of the sequent ∆; ', 'Γ |— G. The lemma is obviously true by induction hypothesis\\n\\nif the last inference rule introduces on the right the main connective or quantifier\\n\\nof the goal. So the problem is reduced to the rules (∧L), (⇒L) and (∀L). For each\\n\\nof these three rules, we must analyze cases according to the structure of G. In each\\n\\ncase, it is possible to transform the proof by permuting the application of right and\\n\\nleft-introduction rules, in the same way as in (Miller et al., 1991). In our setting,\\n\\nhowever, the treatment of (∀L) gives rise to some new situations. We analyze the\\n\\nmost interesting cases; the ones we omit can be treated analogously.\\n\\n(∧L) Then we can decompose ∆ as ∆ = ∆′ ∪ {D1 ∧ D2}, and the last step of the\\n\\nproof is of the form:\\n\\n∆′, D1, D2; Γ |— G\\n\\n∆′, D1 ∧ D2; Γ |—G\\n(∧L)\\n\\n• If G ≡ G1 ∨G2, then by the induction hypothesis, there is a proof of size less\\n\\nthan l− 1 of ∆′, D1, D2; Γ |— Gi. Applying (∧L) we obtain a proof of size less\\n\\nor equal l − 1, so less than l, of ∆′, D1 ∧ D2; Γ |— Gi for i = 1 or 2.\\n\\n(⇒L) Then we can decompose ∆ as ∆ = ∆′ ∪ {G′ ⇒ A}, and the last step of the\\n\\nproof is of the form:\\n\\n∆′; Γ |— G′ ∆′, A; Γ |— G\\n\\n∆′, G′ ⇒ A; Γ |— G\\n(⇒L)\\n\\n• If G ≡ ∀xG1, then ∆′, A; Γ |— ∀xG1 has a proof of size l1 < l, and by the\\n\\ninduction hypothesis there is a proof of size less than l1 of ∆′, A; Γ |— G1[y/x],\\n\\nwhere y is a new variable. Then, using that ∆′; Γ |—G′ has a proof of size l2,\\n\\nl1 + l2 = l − 1, and applying (⇒L), ∆′, G′ ⇒ A; Γ |— G1[y/x] has a proof of\\n\\nsize less or equal l1 + l2 so less than l, as we wanted to prove.\\n\\n• If G ≡ D ⇒ G1, then ∆′, A; Γ |— D ⇒ G1 has a proof of size l1 < l, so by the\\n\\ninduction hypothesis there is a proof of size less than l1 of ∆′, A, D; Γ |— G1.\\n\\nThen, since ∆′; Γ |— G′ has a proof of size l2, obviously ∆′, D; Γ |— G′ also\\n\\nhas a proof of size l2, and l1 + l2 < l. Therefore, using (⇒L), we obtain that\\n\\n∆′, G′ ⇒ A, D; Γ |— G1 has a proof of size less or equal l1 + l2, so less than l,\\n\\nas we wanted to prove.\\n\\n(∀L) Then we can decompose ∆ as ∆ = ∆′ ∪{∀xD}, and the last step of the proof\\n\\nis of the form:\\n\\n∆′, D[y/x]; Γ, C′ |— G Γ ⊢C ∃yC′\\n\\n∆′, ∀xD; Γ |— G\\n(∀L)\\n\\n\\n\\n34 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nwhere y is not free in the sequent of the conclusion, and the sequent\\n\\nQ ≡ ∆′, D[y/x]; Γ, C′ |— G\\n\\nhas a proof of size l − 1.\\n\\n• If G ≡ C, then by the induction hypothesis applied to Q, we know that\\n\\nΓ, C′ ⊢C C. Since Γ ⊢C ∃yC′ and y is not free in Γ, C, we conclude that\\n\\nΓ ⊢C C, due to the properties of ⊢C , that coincides with item 2 of the lemma.\\n\\n• If G ≡ C ⇒ G1, then by the induction hypothesis applied to Q, the sequent\\n\\n∆′, D[y/x]; Γ, C′, C |— G1\\n\\nhas a proof of size less than l−1. Therefore, since Γ ⊢C ∃yC′ implies Γ, C ⊢C\\n\\n∃yC′, and y is not free in C, applying (∀L), ∆′, ∀xD; Γ, C |— G1, has a proof\\n\\nof size less or equal than l − 1 so less than l.\\n\\n• If G ≡ ∃wG1, then by applying the induction hypothesis to Q we conclude\\n\\nthat there is C such that Γ, C′ ⊢C ∃zC, where z is not free in ∆′, D[y/x], Γ, C′,\\n\\n∃wG1, and\\n\\n∆′, D[y/x]; Γ, C′, C |— G1[z/w] (†)\\n\\nhas a proof of size less than l− 1. Since y is not free in ∆′, G1[z/w], applying\\n\\nCorollary 4.3 to (†) we obtain that ∆′, D[u/x]; Γ, C′, C, u ≈ y |— G1[z/w],\\n\\nwhere u is a new variable, has a proof of the same size, so by Lemma 4.2,\\n\\n∆′, D[u/x]; Γ, C′ ∧ C, u ≈ y |— G1[z/w] (‡)\\n\\nstill with a proof of size less than l − 1. Now by the properties of the con-\\n\\nstraint entailment, Γ, C′ ∧ C ⊢C ∃u(u ≈ y) (§). Then, since u is not free in\\n\\n∆′, ∀xD, Γ, C′ ∧ C, G1[z/w], we apply (∀L) to (‡) and (§), obtaining that\\n\\n∆′, ∀xD; Γ, C′ ∧ C |— G1[z/w]\\n\\nhas a proof of size less than or equal l − 1. Hence using Lemma 4.4\\n\\n∆′, ∀xD; Γ, ∃y(C′ ∧ C) |— G1[z/w]\\n\\nhas a proof of size less than or equal l − 1, because, by the assumptions,\\n\\ny is not free in ∆′, ∀xD, Γ, G1[z/w]. Therefore we can conclude the result\\n\\nfor this case (item 7), taking ∃y(C′ ∧ C) as auxiliary constraint. In fact,\\n\\nΓ, C′ ⊢C ∃zC implies Γ, C′ ⊢C ∃z(C′ ∧C), since z is not free in Γ, C′. Hence\\n\\nΓ, ∃yC′ ⊢C ∃z∃y(C′∧C), since y is not free in Γ. Finally, Γ ⊢C ∃z∃y(C′∧C),\\n\\nbecause Γ ⊢C ∃yC′.\\n\\n• If G ≡ A, then the induction hypothesis for the sequent Q assures that there\\n\\nare constraints C1, . . . , Cn (n ≥ 0) and a formula ∀x1 . . . ∀xn(G′ ⇒ A′) that\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 35\\n\\nis a variant of a formula in elab(∆′ ∪ {D[y/x]}), where x1, . . . , xn are new\\n\\nvariables, xi not appearing free in C1, . . . , Ci−1, for 1 < i ≤ n, A′ begins with\\n\\nthe same predicate symbol as A, and such that:\\n\\n(i) Γ, C′ ⊢C ∃x1C1; Γ, C′, C1 ⊢C ∃x2C2; . . . ; Γ, C′, C1, . . . , Cn−1 ⊢C ∃xnCn.\\n\\n(ii) Γ, C′, C1, . . . , Cn ⊢C A′ ≈ A.\\n\\n(iii) ∆′, D[y/x]; Γ, C′, C1, . . . , Cn |— G′ has a proof of size less than l − 1, or\\n\\nG′ ≡ ⊤.\\n\\nIn order to establish item 1 of the lemma, we distinguish two cases:\\n\\n(I) ∀x1 . . . ∀xn(G′ ⇒ A′) is a variant of a formula in elab(∆′), or\\n\\n(II) ∀x1 . . . ∀xn(G′ ⇒ A′) is a variant of a formula in elab(D[y/x]).\\n\\n(I). If ∀x1 . . . ', '∀xn(G′ ⇒ A′) is a variant of a formula in elab(∆′), then\\n\\n∀x1 . . . ∀xn(G′ ⇒ A′) is a variant of a formula in elab(∆). Taking the fol-\\n\\nlowing n auxiliary constraints ∃y(C′ ∧C1), . . . ,∃y(C′ ∧C1 ∧ . . .∧Cn), we will\\n\\nprove conditions (a), (b) and (c).\\n\\n• For condition (a) we need to prove:\\n\\nΓ ⊢C ∃x1∃y(C′ ∧ C1) (1)\\n\\nΓ, ∃y(C′ ∧ C1) ⊢C ∃x2∃y(C′ ∧ C1 ∧ C2) (2)\\n...\\n\\n...\\n\\nΓ, ∃y(C′ ∧ C1), . . . ,∃y(C′ ∧ C1 ∧. . .∧ Cn−1) ⊢C\\n\\n∃xn∃y(C′ ∧ C1 ∧. . .∧ Cn) (n)\\n\\nThis can be deduced from condition (i) above, as follows:\\n\\n(1). By (i), Γ, C′ ⊢C ∃x1C1, then Γ, C′ ⊢C C′ ∧ ∃x1C1. Hence\\n\\nΓ, ∃yC′ ⊢C ∃y(C′ ∧ ∃x1C1),\\n\\nsince y is not free in Γ. Therefore\\n\\nΓ, ∃yC′ ⊢C ∃x1∃y(C′ ∧ C1),\\n\\nsince x1 is not free in C′. Now we can conclude (1) because Γ ⊢C ∃yC′.\\n\\n(2). By (i), Γ, C′, C1 ⊢C ∃x2C2, then Γ, C′∧C1 ⊢C C′∧C1∧∃x2C2. Hence\\n\\nΓ, ∃y(C′ ∧ C1) ⊢C ∃y(C′ ∧ C1 ∧ ∃x2C2),\\n\\nsince y is not free in Γ. Therefore\\n\\nΓ, ∃y(C′ ∧ C1) ⊢C ∃x2∃y(C′ ∧ C1 ∧ C2),\\n\\nsince x2 is not free in C′, C1.\\n\\nBy a similar reasoning, we can prove (3) to (n − 1).\\n\\n\\n\\n36 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\n(n). By (i), Γ, C′, C1, . . . , Cn−1 ⊢C ∃xnCn, then Γ, C′ ∧C1 ∧ . . .∧Cn−1 ⊢C\\n\\nC′ ∧ C1 ∧ . . . ∧ Cn−1 ∧ ∃xnCn. Hence\\n\\nΓ, ∃y(C′ ∧ C1 ∧ . . . ∧ Cn−1) ⊢C ∃y(C′ ∧ C1 ∧ . . . ∧ Cn−1 ∧ ∃xnCn),\\n\\nsince y is not free in Γ. Therefore\\n\\nΓ, ∃y(C′ ∧ C1 ∧ . . . ∧ Cn−1) ⊢C ∃xn∃y(C′ ∧ C1 ∧ . . . ∧ Cn−1 ∧ Cn),\\n\\nsince xn is not free in C′, C1, . . . , Cn−1. Then we deduce (n) obviously.\\n\\n• For condition (b) we need:\\n\\nΓ, ∃y(C′ ∧ C1), . . . ,∃y(C′ ∧ C1 ∧ . . . ∧ Cn) ⊢C A′ ≈ A.\\n\\nTo deduce this from (ii), we note that y is not free in ∆′, Γ, A by assumption.\\n\\nMoreover, y is not free in A′, or else it would be free in ∆′. Therefore, (ii)\\n\\nimplies that\\n\\nΓ, ∃y(C′ ∧ C1 ∧ . . . ∧ Cn) ⊢C A′ ≈ A,\\n\\nwhich amounts to what we needed.\\n\\n• Finally, for condition (c) we assume the interesting case where G′ is not ⊤.\\n\\nWe need a proof of size less than l for the sequent\\n\\n∆′, ∀xD; Γ, ∃y(C′ ∧ C1), . . . ,∃y(C′ ∧ C1 ∧ . . . ∧ Cn) |— G′ (†)\\n\\nTo deduce this, we first choose a fresh variable u, and we apply Corollary\\n\\n4.3 to (iii), thus obtaining that\\n\\n∆′, D[u/x]; Γ, C′, C1, . . . , Cn, u ≈ y |— G′\\n\\nhas a proof of size less than l − 1. Since u is new and Γ, C′, C1, . . . , Cn ⊢C\\n\\n∃u(u ≈ y), we can apply (∀L) obtaining that\\n\\n∆′, ∀xD; Γ, C′, C1, . . . , Cn |— G′\\n\\nhas a proof of size less than l. From this, Lemma 4.2 and Lemma 4.4 (note\\n\\nthat y is not free in ∆′, ∀xD, Γ, G′) lead to a proof of size less than l for\\n\\n∆′, ∀xD; Γ, ∃y(C′ ∧ C1 ∧ . . . ∧ Cn) |— G′.\\n\\nAnother application of Lemma 4.2 leads from this to a proof of size less\\n\\nthan l for the sequent (†).\\n\\n(II). If ∀x1 . . . ∀xn(G′ ⇒ A′) is a variant of a formula in elab(D[y/x]), then\\n\\n∀y∀x1 . . .∀xn(G′ ⇒ A′) is a variant of a formula in elab(∀xD), and so it is\\n\\na variant of a formula in elab(∆). Then condition (a) coincides with (i) plus\\n\\nΓ ⊢C ∃yC′, and (b) is equivalent to (ii). Moreover from (iii) (assuming that\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 37\\n\\nG′ is not ⊤) we can deduce that the sequent\\n\\n∆′, D[u/x]; Γ, C′, C1, . . . , Cn, u ≈ y |— G′\\n\\nhas a proof of size less than l − 1, because of Corollary 4.3 (u is chosen as a\\n\\nnew variable). Since Γ, C′, C1, . . . , Cn ⊢C ∃u(u ≈ y), we can apply (∀L) and\\n\\nwe obtain a proof of size less than l for the sequent\\n\\n∆′, ∀xD; Γ, C′, C1, . . . , Cn |— G′.\\n\\nThat is precisely condition (c).\\n\\nProofs of results from Section 4.3\\n\\nLemma 4.7 (Elaboration)\\n\\nFor any ∆, Γ, A and F ∈ elab(∆): if ∆, F ; Γ ⊢IC A, then ∆; Γ ⊢IC A.\\n\\nProof\\n\\nSince F ∈ elab(∆), there will be D ∈ ∆ such that F ∈ elab(D). The proof of the\\n\\nlemma is by case analysis according to the structure of D.\\n\\n• If D ≡ A′, then F ≡ ⊤ ⇒ A′. We prove ∆; Γ ⊢IC A by induction on the size\\n\\nl of the proof of ∆, F ; Γ |— A. If l = 1, the proof consists on the application\\n\\nof (Atom), the form of F implies that it does not take part in this proof.\\n\\nSo there exists A′′ ∈ ∆ such that Γ ⊢C A′′ ≈ A. Therefore ∆; Γ ⊢IC A,\\n\\nby (Atom). Assuming now the result for proofs of size less than l, l > 1, we\\n\\nproceed by case analysis on the last rule applied in the proof of ∆, F ; Γ |— A.\\n\\nNote that it is only necessary to analyze the left-introduction rules, since the\\n\\ngoal is an atomic formula. For (∧L) and (∀L), we note that F ≡ ⊤ ⇒ A′\\n\\ncannot participate on this step of the proof, instead a formula of ∆ has been\\n\\nintroduced. For instance, for (∧L), if D1 ∧D2 is the formula introduced, then\\n\\n∆ is of the form ∆′ ∪ {D1 ∧ D2}, and the last step of the proof is:\\n\\n∆′, D1, D2, F ; Γ |— A\\n\\n∆′, D1 ∧ D2, F ; Γ |—A\\n(∧L).\\n\\nSo ∆′, D1, D2, F ; Γ |—A has a proof of size less that l, and since F ∈ elab(∆′∪\\n\\n{D1, D2}), ∆′, D1, D2; Γ ⊢IC A, by induction hypothesis. The result can be\\n\\nobtained now using the rule (∧L).\\n\\nFor the case (⇒L), if the introduced formula is F (other cases are proved as\\n\\nbefore), then the last step of the proof is:\\n\\n∆; Γ |—⊤ ∆, A′; Γ |—A\\n\\n∆, F ; Γ |—A\\n(⇒L).\\n\\nSince A′ ≡ D and D ∈ ∆, the sequent ∆, A′; Γ |— A can be also written as\\n\\n∆; Γ |— A, and we are done.\\n\\n\\n\\n', '38 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\n• If D ≡ D1 ∧ D2, then F ∈ elab(Di) for i = 1 or 2. ∆, F ; Γ ⊢IC A, by hy-\\n\\npothesis, then it is easy to prove that also ∆, D1, D2, F ; Γ ⊢IC A. Hence,\\n\\napplying structural induction hypothesis to Di, ∆, D1, D2; Γ ⊢IC A. There-\\n\\nfore ∆, D1∧D2; Γ ⊢IC A, in accordance with the rule (∧L). This is equivalent\\n\\nto ∆; Γ ⊢IC A, since D ≡ D1 ∧ D2 and D ∈ ∆.\\n\\n• If D ≡ G1 ⇒ D1, then F ≡ D, so F ∈ ∆ and we have ∆; Γ ⊢IC A directly.\\n\\n• If D ≡ ∀xD1, then F ≡ ∀xF1 and F1 ∈ elab(D1). We proceed by induction\\n\\non the size l of the proof of ∆, F ; Γ |— A. The case l = 1 is trivial because F\\n\\ncannot take part in the proof. Similarly we can reason the inductive step for\\n\\nthe cases (∧L) and (⇒L).The interesting case occurs when (∀L) was the last\\n\\nrule applied and F was the introduced formula. In this case, the last proof\\n\\nstep is of the form:\\n\\n∆, F1[y/x]; Γ, C |— A Γ ⊢C ∃yC\\n\\n∆, F ; Γ |— A\\n(∀L),\\n\\nwhere y is not free in the sequent of the conclusion.\\n\\n∆, D1[y/x], F1[y/x]; Γ, C ⊢IC A can be deduced from ∆, F1[y/x]; Γ, C ⊢IC A.\\n\\nThen ∆, D1[y/x]; Γ, C ⊢IC A, since the lemma holds for D1[y/x] –simpler\\n\\nthan D– and F1[y/x] ∈ elab(D1[y/x]). Therefore ∆, ∀xD1; Γ ⊢IC A, by (∀L),\\n\\nusing the fact that y is not free in ∆, ∀xD1, Γ, A, and that Γ ⊢C ∃yC. We con-\\n\\nclude because D ≡ ∀xD1 and D ∈ ∆.\\n\\nLemma 4.9\\n\\nFor any ∆, Γ, G, if Γ′ is a set of constraints such that Γ′ ⊢C Γ, and ∆; Γ ⊢UC G,\\n\\nthen ∆; Γ′ |— G has a UC-proof of the same size.\\n\\nProof\\n\\nBy induction on the size of the proof of the sequent ∆; Γ |— G, by case analysis on\\n\\nthe last rule applied. Using the definition of the system UC and Lemma 4.2, the\\n\\nonly interesting case is when the last step corresponds to rule (Clause). But the\\n\\nproof in this case is a direct consequence of the induction hypothesis.\\n\\nLemma 4.10\\n\\nFor any ∆, Γ, C, G, if ∆; Γ, C ⊢UC G and x is a variable that does not appear free\\n\\nin ∆, Γ, G, then ∆; Γ, ∃xC |— G has a UC-proof of the same size.\\n\\nProof\\n\\nAs in the previous lemma, and due now to Lemma 4.4, we can focus the proof on\\n\\nthe case (Clause). In this case G ≡ A and the last step of the proof is of the form:\\n\\n∆; Γ, C |— ∃x1 . . . ∃xn((A′ ≈ A) ∧ G′)\\n\\n∆; Γ, C |— A\\n(Clause)\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 39\\n\\nwhere A, A′ begin with the same predicate symbol, and ∀x1 . . . ∀xn(G′ ⇒ A′) is a\\n\\nvariant of a formula of elab(∆), x1, . . . , xn do not appear free in the sequent of the\\n\\nconclusion.\\n\\nSince x is not free in ∆, A, and ∀x1 . . . ∀xn(G′ ⇒ A′) is a variant of a formula of\\n\\nelab(∆), then x is not free in ∃x1 . . . ∃xn((A′ ≈ A) ∧ G′). Note also, that x is not\\n\\nfree in Γ, ∆, by assumption, so applying the induction hypothesis to the sequent\\n\\n∆; Γ, C |— ∃x1 . . . ∃xn((A′ ≈ A) ∧ G′),\\n\\n∆; Γ, ∃xC |— ∃x1 . . . ∃xn((A′ ≈ A) ∧ G′)\\n\\nhas a proof of the same size. Hence, applying (Clause), ∆; Γ, ∃xC |— A has a UC-\\n\\nproof of the same size that ∆; Γ, C |— A.\\n\\nProofs of results from Section 5.1\\n\\nLemma 5.2\\n\\nAssume S ≡ Π[S2G] and S′ ≡ ΠΠ′[S′\\n2G′] are two states w.r.t. a set of variables\\n\\nV , such that S‖—S′. If R′ is a constraint with its free variables in ΠΠ′ or in V , and\\n\\nsuch that R′ ⊢C S′ and for any 〈∆′, C′, G′〉 ∈ G′, ∆′; R′, C′ ⊢UC G′, then Π′R′ ⊢C S\\n\\nand for any 〈∆, C, G〉 ∈ G, ∆; Π′R′, C ⊢UC G.\\n\\nProof\\n\\nWe analyze the different cases, according to the transformation applied.\\n\\nii) Disjunction. Π′ is empty and S ≡ S′ as above. Then let us check only the case\\n\\n〈∆, C, G〉 /∈ G′. This implies G ≡ G1∨G2 and 〈∆, C, G1〉 ∈ G′ or 〈∆, C, G2〉 ∈\\n\\nG′. By hypothesis\\n\\n∆; Π′R′, C ⊢UC G1 or ∆; Π′R′, C ⊢UC G2,\\n\\nsince Π′R′ ≡ R′. Then ∆; Π′R′, C ⊢UC G, because of the rule (∨R).\\n\\niii) Implication with local clause. As before the prefix and the partially calculated\\n\\nanswer constraint do not change. If 〈∆, C, G〉 /∈ G′, then G ≡ D ⇒ G1 and\\n\\n〈∆ ∪ {D}, C, G1〉 ∈ G′. Hence, by hypothesis since Π′R′ ≡ R′, it holds\\n\\n∆, D; Π′R′, C ⊢UC G1\\n\\nfrom which we conclude the result by applying (⇒R).\\n\\niv) Implication with local constraint. As in the preceding cases where there are\\n\\nno changes in S and Π, we check what happens if 〈∆, C, G〉 ∈ G \\\\ G′. In this\\n\\ncase G ≡ C′ ⇒ G1 and 〈∆, C ∧C′, G1〉 ∈ G′. By hypothesis, since Π′R′ ≡ R′,\\n\\nwe have ∆; Π′R′, C ∧ C′ ⊢UC G1 then in accordance with Lemma 4.9\\n\\n∆; Π′R′, C, C′ ⊢UC G1.\\n\\n\\n\\n40 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nNow we conclude ∆; Π′R′, C ⊢UC G, by applying (⇒CR).\\n\\nv) Existential quantification. Π′ ≡ ∃w with w a new variable not in Π nor in V .\\n\\nHence, by item i) of Lemma 5.1, w is not free in the formulas of G, nor in S.\\n\\nTherefore, using the facts R′ ⊢C S′ and S ≡ S′, we can conclude ∃wR′ ⊢C S.\\n\\nNow let 〈∆, C, G〉 ∈ G, if 〈∆, C, G〉 ∈ G′, then ∆; R′, C ⊢UC G, by hypothesis.\\n\\nThen ∆; ∃wR′, C ⊢UC G by Lemma 4.10, because w is not free in ∆, C, G.\\n\\nIf 〈∆, C, G〉 /∈ G′, G ≡ ∃xG1 and 〈∆, C, G1[w/x]〉 ∈ G′. By hypothesis,\\n\\n∆; R′, C ⊢UC G1[w/x]\\n\\nand so also ∆; ∃wR′, R′, C ⊢UC G1[w/x], by Lemma 4.9. Consequently, ap-\\n\\nplying the rule (∃R),\\n\\n∆; ∃wR′, C ⊢UC G\\n\\n', 'since ∃wR′, C ⊢C ∃wR′, and w is new for the sequent of the conclusion.\\n\\nvi) Universal quantification. Π′ ≡ ∀w with w a new variable w.r.t. Π and V , and\\n\\nS ≡ S′. So ∀wR′ ⊢C S holds directly from R′ ⊢C S′.\\n\\nLet 〈∆, C, G〉 ∈ G, if 〈∆, C, G〉 ∈ G′, then ∆; R′, C ⊢UC G, by hypothesis.\\n\\nThen ∆; Π′R′, C ⊢UC G because Π′R′ ⊢C R′ and Lemma 4.9.\\n\\nIf 〈∆, C, G〉 /∈ G′, G ≡ ∀xG1 and 〈∆, C, G1[w/x]〉 ∈ G′. By the hypothesis,\\n\\nsince ∀wR′ ⊢C R′ and Lemma 4.9, we have\\n\\n∆; ∀wR′, C ⊢UC G1[w/x]\\n\\nNow, since w is not in Π nor in V , by item i) of Lemma 5.1, it is not free in\\n\\n∆, C, G, and obviously w is neither free in ∀wR′. Then we conclude\\n\\n∆; ∀wR′, C ⊢UC G\\n\\nby applying (∀R).\\n\\nvii) Constraint. In this case Π′ is empty and ΠS′ ≡ Π(S ∧ (C ⇒ C′)) is C-\\n\\nsatisfiable. Trivially R′ ⊢C S′ implies Π′R′ ⊢C S.\\n\\nNow let 〈∆, C, G〉 ∈ G, the case 〈∆, C, G〉 ∈ G′ is easily proved. If 〈∆, C, G〉 /∈\\n\\nG′, then G ≡ C′. R′ ⊢C C ⇒ C′ because R′ ⊢C S′ and S′ ≡ S ∧ (C ⇒ C′).\\n\\nBy the properties of the constraint entailment, we deduce R′, C ⊢C C′. Then\\n\\napplying the rule (CR),\\n\\n∆; Π′R′, C ⊢UC G,\\n\\nbecause Π′R′ ≡ R′.\\n\\nviii) Clause of the program. Since Π′ is empty and S ≡ S′, we only check the\\n\\ncase 〈∆, C, G〉 ∈ G and 〈∆, C, G〉 /∈ G′. In such case G ≡ A and there is\\n\\n∀x1 . . . ∀xn(G1 ⇒ A′) a variant of a formula of elab(∆) where:\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 41\\n\\n• x1, . . . , xn are new variables not occurring in Π, V , and therefore not free\\n\\nin A, ∆, C and Π′R′.\\n\\n• A and A′ begin with the same predicate symbol.\\n\\n• 〈∆, C, ∃x1 . . . ∃xn((A′ ≈ A) ∧ G1)〉 ∈ G′.\\n\\nBy hypothesis, since Π′R′ ≡ R′,\\n\\n∆; Π′R′, C ⊢UC ∃x1 . . .∃xn((A′ ≈ A) ∧ G1).\\n\\nUsing now the rule (Clause), we conclude ∆; Π′R′, C ⊢UC G.\\n\\nProofs of results from Section 5.2\\n\\nLemma 5.4\\n\\nLet S ≡ Π[S2G] be a non-final state w.r.t. a set of variables V , and let R be a\\n\\nconstraint such that ΠR is C-satisfiable and R ⊢C S. If ∆; R, C ⊢UC G for all\\n\\n〈∆, C, G〉 ∈ G, then we can find a rule transforming S in a state S′ ≡ Π′[S′\\n2G′]\\n\\n(S‖—S′) and a constraint R′ such that:\\n\\n1. ΠR ⊢C Π′R′ and R′ ⊢C S′.\\n\\n2. ∆′; R′, C′ ⊢UC G′ for all 〈∆′, C′, G′〉 ∈ G′. Moreover MG′R′ << MGR.\\n\\nProof\\n\\nLet us choose any 〈∆, C, G〉 ∈ G; we reason by induction on the structure of G,\\n\\nanalyzing cases:\\n\\n• If G has the form G1 ∧ G2, G1 ∨ G2, D ⇒ G1 or C1 ⇒ G1, then we apply\\n\\nrespectively the transformation rules i), ii), iii) or iv) to S. Let S′ be the\\n\\nstate obtained after the transformation, and let R′ ≡ R:\\n\\n1. ΠR ⊢C Π′R′ and R′ ⊢C S′ are obvious by the hypothesis and because\\n\\nΠ′ ≡ Π, S′ ≡ S and R′ ≡ R.\\n\\n2. Let 〈∆′, C′, G′〉 ∈ G′. If 〈∆′, C′, G′〉 ∈ G, then ∆′; R′, C′ ⊢UC G′ trivially\\n\\nsince ∆′; R, C′ ⊢UC G′ by hypothesis, and R′ ≡ R. Moreover τR′ (∆′, C′, G′)=\\n\\nτR(∆′, C′, G′).\\n\\nIf 〈∆′, C′, G′〉 /∈ G and i), for example, was applied, then ∆′ ≡ ∆, C′ ≡\\n\\nC, G ≡ G1 ∧ G2 and G′ ≡ G1 or G′ ≡ G2. By hypothesis ∆; R, C |— G\\n\\nwith a proof of size l, therefore by the definition of UC, since R′ ≡ R,\\n\\n∆; R′, C |— G1 and ∆; R′, C |— G2 have proofs of size less than l. Consequently\\n\\nτR′(∆′, C′, G1) < τR(∆, C, G) and τR′(∆′, C′, G2) < τR(∆, C, G), so, finally\\n\\n∆′; R′, C′ ⊢UC G′ for all 〈∆′, C′, G′〉 ∈ G′ and MG′R′ << MGR. The argu-\\n\\nment for transformations ii), iii) and iv) is similar. Note that, in the case of ii),\\n\\nwe must choose G1 (resp. G2) if the shortest UC-proof of ∆; R, C |— G1 ∨ G2\\n\\ncontains a subproof of ∆;R, C |— G1 (resp. G2).\\n\\n\\n\\n42 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\n• If G has the form ∀xG1, we apply then the transformation rule vi) and obtain\\n\\nS′. Assume R′ ≡ R:\\n\\n1. Trivial since the choice of w assures that ΠR ⊢⊣C Π∀wR ≡ Π′R′; moreover,\\n\\nS′ ≡ S.\\n\\n2. Let 〈∆′, C′, G′〉 ∈ G′, if 〈∆′, C′, G′〉 ∈ G, then we obtain ∆′; R′, C′ ⊢UC G′,\\n\\nbeing τR′(∆′, C′, G′) = τR(∆′, C′, G′).\\n\\nIf 〈∆′, C′, G′〉 /∈ G′, this is the triple coming from the transformation of\\n\\n〈∆, C, G〉, so G′ ≡ G1[w/x], C′ ≡ C and ∆′ ≡ ∆. By hypothesis ∆; R, C|— G\\n\\nhas a proof of size l, then since w does not appear free in ∆, C, R′(≡ R), G1,\\n\\nbecause of the form of the calculus UC, ∆; R′, C |— G1[w/x] has a proof of\\n\\nsize less than l, and for that reason τR′ (∆′, C′, G′) < τR(∆, C, G), and thus\\n\\nwe conclude that 2. is valid.\\n\\n• If G is a constraint C1, we apply the transformation vii) obtaining S′. Assume\\n\\nR′ ≡ R:\\n\\n1. ΠR ⊢C Π′R′ is trivial since Π′ ≡ Π. Furthermore, ∆; R, C ⊢UC C1 by\\n\\nhypothesis, so by the definition of UC, R, C ⊢C C1 and therefore R ⊢C C ⇒ C1.\\n\\nMoreover R ⊢C S, then R′ ⊢C S′, because R′ ≡ R and S′ ≡ S ∧ (C ⇒ C1).\\n\\nNow, from R′ ⊢C S′ and the C-satisfiability of Π′R′ ≡ ΠR, we deduce that\\n\\nΠ′S′ is also C-satisfiable. Therefore the transformation step is allowed.\\n\\n2. G′ ⊂ G, so ∆′; R′, C′ ⊢UC G′ for all 〈∆′, C′, G′〉 ∈ G′ and MG′R′ << MGR.\\n\\n• If G is atomic G ≡ A, by hypothesis ∆; R, C |— A has a proof of size l,\\n\\nthen by reason of the form of UC, if x1, . . . , xn are new variables not free\\n\\nin ∆, R, C neither in A, then there is a variant of a formula from elab(∆),\\n\\n∀x1 . . . ∀xn(G1 ⇒ A′), with A and A′ beginning with the same predicate\\n\\nsymbol, such that ∆; ', 'R, C |— ∃x1 . . . ∃xn((A′ ≈ A) ∧ G1)(†) has a proof of\\n\\nsize less than l. We transform S in S′ by means of the rule viii), using\\n\\n∀x1 . . . ∀xn(G1 ⇒ A′). Assume now R′ ≡ R. Since S ≡ S′ and Π ≡ Π′,\\n\\nthe proof of 1. is immediate.\\n\\n2. Let 〈∆′, C′, G′〉 ∈ G′, if 〈∆′, C′, G′〉 ∈ G, then ∆′; R, C′ ⊢UC G′ by hypoth-\\n\\nesis and therefore ∆′; R′, C′ ⊢UC G′, besides τR′(∆′, C′, G′) = τR(∆′, C′, G′).\\n\\nIf 〈∆′, C′, G′〉 /∈ G, then G′ ≡ ∃x1 . . . ∃xn((A′ ≈ A)∧G1), C′ ≡ C and ∆′ ≡ ∆.\\n\\nAs we have noted in (†), ∆; R′, C′ |— G′ has a proof of size less than l.\\n\\nSo τR′(∆′, C′, G′) < τR(∆, C, G), and 2. is also proved in this case.\\n\\n\\n\\nCLP with Hereditary Harrop Formulas 43\\n\\nReferences\\n\\nAndréka, H. and Németi, I. (1978) The Generalized Completeness of Horn Predicate Logic\\n\\nas a Programming Language, Acta Cybernetica 4, pp. 3–10.\\n\\nClark, K.L. (1978) Negation as Failure. In H. Gallaire and J. Minker (editors), Logic and\\n\\nDatabases (Plenum Press), pp 293–322.\\n\\nComon, H., Haberstrau, M. and Jouannaud, J.P. (1994) Cycle-Syntacticness, and Shal-\\n\\nlow Theories, Information and Computation 111, pp. 154–191.\\n\\nCohen, J. (1990) Constraint Logic Programming Languages, Comm. of the ACM 35(7),\\n\\npp. 52–68.\\n\\nComon, H. (1993) Complete Axiomatizations of Some Quotient Term Algebras, Theoret-\\n\\nical Computer Science 118, pp. 167–191.\\n\\nDarlington, J. and Guo, Y. (1994) Constraint Logic Programming in the Sequent Cal-\\n\\nculus. In F. Pfenning (editor) LPAR’94. LNAI 822, pp. 200–213. Springer-Verlag.\\n\\nDershowitz, N. and Manna, Z. (1979) Proving Termination with Multiset Ordering,\\n\\nComm. of the ACM 22(8), pp. 465–476.\\n\\nHodas, J.S. (1994) Logic Programming in Intuitionistic Linear Logic: Theory, Design and\\n\\nImplementation (Ph.D. Thesis, University of Pennsylvania).\\n\\nJaffar, J. and Lassez, J.L. (1987) Constraint Logic Programming. In Proc. 14-th ACM\\n\\nSymposium on Principles of Programming Languages, pp. 111–119.\\n\\nJaffar, J. and Michaylov, S. (1987) Methodology and Implementation of CLP Systems\\n\\nIn J.L. Lassez (editor), ICLP’87, pp. 196–218. MIT Press.\\n\\nJaffar, J. and Maher, M.J. (1994) Constraint Logic Programming: A Survey, Journal of\\n\\nLogic Programming 19(20), pp. 503–581.\\n\\nJaffar, J., Maher, M.J., Marriott, K. and Stuckey, P. (1996) The Semantics of Constraint\\n\\nLogic Programs (Technical Report TR 96/39, Dept. of Comput. Sci., University of\\n\\nMelbourne).\\n\\nJaffar, J., Michaylov, S., Stuckey, P. and Yap, R. (1992) The CLP(R) Language and\\n\\nSystem, ACM Transactions on Programming Languages 14(3), pp. 339–395.\\n\\nLeach, J., Nieva, S. and Rodŕıguez-Artalejo, M. (1997) Constraint Logic Programming\\n\\nwith Hereditary Harrop Formulas. In J. Ma luszyński (editor), ILPS’97, pp. 307–321.\\n\\nMIT Press.\\n\\nMaher, M. (1987) Logic Semantics for a Class of Committed-Choice Programs In J.L.\\n\\nLassez (editor), ICLP’87, pp. 858–876. MIT Press.\\n\\nMiller, D. (1989) A Logical Analysis of Modules in Logic Programming, Journal of Logic\\n\\nProgramming 6(1,2), pp. 79–108.\\n\\nMiller, D. (1992) Unification under a Mixed Prefix, Journal of Symbolic Computation 14,\\n\\npp. 321–358.\\n\\nMiller, D. and Nadathur, G. (1986) Higher-order Logic Programming In E. Shapiro\\n\\n(editor) ICLP’86 LNCS 225, pp. 448–462. Springer-Verlag.\\n\\nMiller, D., Nadathur, G., Pfenning, F. and Scedrov, A. (1991) Uniform Proofs as a\\n\\n\\n\\n44 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nFoundation for Logic Programming, Annals of Pure and Applied Logic 51(1–2) pp.\\n\\n125–157.\\n\\nMiller, D., Nadathur, G. and Scedrov, A. (1987) Hereditary Harrop Formulas and\\n\\nUniform Proof Systems. In D. Gries (editor), LICS’87, pp. 98–105. IEEE Comp. Soc.\\n\\nPress.\\n\\nNadathur, G. (1993) A Proof Procedure for the Logic of Hereditary Harrop Formulas,\\n\\nJournal of Automated Reasoning 11, pp. 115–145.\\n\\nNadathur, G. and Miller, D. (1988) An Overview of λ-Prolog. In K.A. Bowen and R. A.\\n\\nKowalski (eds.), ICLP’88, pp. 810–827. MIT Press.\\n\\nSaraswat, V. (1992) The Category of Constraint Systems is Cartesian Closed. In LICS’92,\\n\\npp. 341–345. IEEE Comp. Soc. Press.\\n\\nSmolka, G. and Treinen, R. (1994) Records for Logic Programming, Journal of Logic\\n\\nProgramming 18(3), pp. 229–258.\\n\\nVan Emden, M.H. and Kowalski, R.H. (1976) The Semantics of Predicate Logic as a\\n\\nProgramming Language, J. ACM 23(4), pp. 733–742.\\n\\nTarski, A. (1951) A Decision Method for Elementary Algebra and Geometry. University\\n\\nof California Press.\\n\\n\\n\\tIntroduction\\n\\tExamples\\n\\tHereditary Harrop Formulas with Constraints\\n\\tProof Systems\\n\\tThe calculus IC\\n\\tUniform proofs\\n\\tThe calculus UC\\n\\n\\t A Goal Solving Procedure\\n\\tSoundness\\n\\tCompleteness\\n\\n\\tConclusions and Future Work\\n\\tReferences\\n\\n'], 'name': '0404053v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0404/0404053v1.pdf', 'vectorized': None}]}\n",
            "{'@odata.context': \"https://gptkb-3hhfqf2n5qzbc.search.windows.net/indexes('cogsrch-index-csv')/$metadata#docs(*)\", '@odata.count': 48638, '@search.answers': [{'key': 'u2g30x1j', 'text': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP).', 'highlights': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of <em>recombinant SA11 rotavirus core-like particles</em> (CLP) or virus-like particles (VLP).', 'score': 0.9345703125}], 'value': [{'@search.score': 12.707714, '@search.rerankerScore': 2.791743278503418, '@search.captions': [{'text': 'Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody.', 'highlights': ''}], 'id': '5ed5k9tq', 'title': 'Quantification of recombinant core-like particles of bluetongue virus using immunosorbent electron microscopy.', 'chunks': ['Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody. The CLP concentration in purified preparations was determined to be 6.6 x 10(15) particles/l. CLP concentration in lysates of recombinant baculovirus-infected cells was determined at various times post-infection and shown to reach a value of 3 x 10(15) particles/l of culture medium at 96 h post-infection. The results indicated that immunosorbent electron microscopy, aided by an improved particle counting method, is a simple, rapid and accurate technique for the quantification of virus and virus-like particles produced in large scale in vitro systems.'], 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pubmed/10403670/', 'vectorized': None}, {'@search.score': 11.988263, '@search.rerankerScore': 2.548943042755127, '@search.captions': [{'text': 'The chemokine monocyte chemoattractant protein 1/CC chemokine ligand 2 (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases.', 'highlights': 'The<em> chemokine monocyte chemoattractant protein 1/CC</em><em> chemokine ligand 2</em> (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases.'}], 'id': 'm3ibpnfw', 'title': 'Increased susceptibility to septic and endotoxic shock in monocyte chemoattractant protein 1/cc chemokine ligand 2-deficient mice correlates with reduced interleukin 10 and enhanced macrophage migration inhibitory factor production.', 'chunks': ['The chemokine monocyte chemoattractant protein 1/CC chemokine ligand 2 (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases. In the present study, we demonstrate that mcp-1/ccl2-deficient mice are more susceptible to systemic inflammatory response syndrome induced by lipopolysaccharide and to polymicrobial sepsis induced by cecum ligation and puncture (CLP) when compared with wild-type mice. Interestingly, in the CLP model, mcp-1/ccl2-deficient mice efficiently cleared the bacteria despite an impaired recruitment of leukocytes, especially mononuclear cells. The increased lethality rate in these models correlates with an impaired production of interleukin (IL) 10 in vivo. Furthermore, macrophages from mcp-1/ccl2-deficient mice activated with lipopolysaccharide also produced lower amounts of IL-10 and similar tumor necrosis factor compared with wild-type mice. We observed a drastic increase in the amounts of macrophage migration inhibitory factor at 6 and 24 h after CLP in mcp-1/ccl2-deficient mice. These results indicate that endogenous MCP-1/CCL2 positively regulates IL-10 but negatively controls macrophage migration inhibitory factor during peritoneal sepsis, thus suggesting an important immunomodulatory role for MCP-1/CCL2 in controlling the balance between proinflammatory and anti-inflammatory factors in sepsis.'], 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pubmed/17047515/', 'vectorized': None}, {'@search.score': 12.749268, '@search.rerankerScore': 2.5401346683502197, '@search.captions': [{'text': 'In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs.', 'highlights': ''}], 'id': 'vnmg0zid', 'title': 'Length of encapsidated cargo impacts stability and structure of in vitro assembled alphavirus core-like particles', 'chunks': ['In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs. We hypothesized that cargo neutralizes the basic region of the alphavirus capsid protein and if the cargo is long enough, it will also act to scaffold the CP monomers together. Experimentally we found that CLPs encapsidating short 27mer oligonucleotides were less stable than CLPs encapsidating 48mer or 90mer oligonucleotides under different chemical and thermal conditions. Furthermore, cryo-EM studies showed there were structural differences between CLPs assembled with 27mer and 48mer cargo. To mimic the role of the cargo in CLP assembly we made a mutant (4D) where we substituted a cluster of four Lys residues in the CP with four Asp residues. We found that these few amino acid substitutions were enough to initiate CLP assembly in the absence of cargo. The cargo-free 4D CLPs show higher resistance to ionic strength and increased temperature compared to wild-type cargo containing CLPs suggesting their CLP assembly mechanism might also be different.'], 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7103146/', 'vectorized': None}, {'@search.score': 10.760419, '@search.rerankerScore': 2.5137102603912354, '@search.captions': [{'text': 'We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional laparoscopic pyeloplasty (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria.', 'highlights': 'We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional<em> laparoscopic pyeloplasty</em> (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria.'}], 'id': '7xw8tlg3', 'title': 'Laparoendoscopic single site surgery versus conventional laparoscopy for transperitoneal pyeloplasty: A systematic review and meta-analysis.', 'chunks': ['We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional laparoscopic pyeloplasty (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria. The methodological quality of the studies was rated according validated scales. The level of evidence (LE) was reported as described by the Oxford criteria. Preoperative demographic parameters and perioperative outcomes between the two surgical techniques were assessed. A meta-analysis of the included studies was performed. A total of 5 studies were elected for the analysis, including 164 cases, 70 (42.6%) of them being LESS and 94 (57.4%) being CLP. Four studies were observational retrospective comparative studies (LE: 3a-4); one was a prospective randomized controlled trial (LE: 2b). There was no significant difference in age, body mass index, gender, side and presence of the crossing vessel, between the groups. There was no significant difference regarding the operative time (weight mean difference [WMD]: -7.02; 95% confidence interval [CI]: -71.82-57.79; P = 0.83) and length of hospital stay (WMD: 0.04; 95% CI: -0.11-0.20; P = 0.58), whereas the estimated blood loss was statistically lower for LESS (WMD: -16.83; 95% CI: -31.79--1.87; P = 0.03). The postoperative use of analgesic favored the LESS group but without reaching statistical significance (WMD: -7.52; 95% CI: -17.56-2.53; P = 0.14). In conclusion, LESS pyeloplasty offers comparable surgical and functional outcomes to CLP while providing the potential advantages of less blood loss and lower analgesic requirement. Thus, despite being more technically challenging, LESS pyeloplasty can be regarded as a minimally invasive approach for patients seeking fewer incisional scars.'], 'name': 'metadata.csv', 'location': 'https://doi.org/10.4103/0974-7796.156145; https://www.ncbi.nlm.nih.gov/pubmed/26229312/', 'vectorized': None}, {'@search.score': 16.59707, '@search.rerankerScore': 2.457797050476074, '@search.captions': [{'text': 'The Academy of Consultation-Liaison Psychiatry (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient consultation-liaison psychiatry (CLP) training and providing a framework for CLP educators who are interested in developing outpatient CLP rotations within their programs.', 'highlights': 'The Academy of<em> Consultation-Liaison Psychiatry</em> (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient<em> consultation-liaison psychiatry</em> (CLP) training and providing a framework for<em> CLP</em> educators who are interested in developing outpatient<em> CLP</em> rotations within their programs.'}], 'id': 'da6d32x7', 'title': 'The educational value of outpatient CL rotations- a white paper from the ACLP residency education subcommittee', 'chunks': ['Abstract Background and aims As mental health services in outpatient medical clinics expand, psychiatrists must be trained to practice in these settings. The Academy of Consultation-Liaison Psychiatry (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient consultation-liaison psychiatry (CLP) training and providing a framework for CLP educators who are interested in developing outpatient CLP rotations within their programs. Method MEDLINE (via PubMed), Embase and PsycINFO (via OVID), were reviewed each from inception to December 2019, for psychiatric CLP services in ambulatory settings that involved residents or fellows. The CLP education guidelines were reviewed for recommendations relevant to outpatient CLP. We also searched MedEd portal for published curriculums relevant to CLP. The group held 2 conferences to reach consensus about recommendations in setting up outpatient CLP rotations. Results Seventeen articles, three ACLP supported guidelines, and eight online didactic resources were identified as directly reporting on the organization and/or impact of an outpatient CLP rotation. These manuscripts indicated that residents found outpatient CLP rotations effective and relevant to their future careers. However, the literature provided few recommendations for establishing formal outpatient CLP training experiences. Discussion Outpatient CLP rotations offer multiple benefits for trainees, including exposure to specific clinical scenarios and therapeutic interventions applicable only in the outpatient setting, increased continuity of care and the unique experience of providing liaison and education to non-mental health providers. The article outlines recommendations and examples for developing outpatient CLP rotations which CLP educators can incorporate in their programs.'], 'name': 'metadata.csv', 'location': 'https://api.elsevier.com/content/article/pii/S0033318220301420; https://www.sciencedirect.com/science/article/pii/S0033318220301420?v=s5', 'vectorized': None}, {'@search.score': 12.193438, '@search.rerankerScore': 2.2948453426361084, '@search.captions': [{'text': 'Chronic obstructive pulmonary disease (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling.', 'highlights': '<em>Chronic obstructive pulmonary disease</em> (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling.'}], 'id': 'i7ecw3xb', 'title': 'What is the contribution of respiratory viruses and lung proteases to airway remodelling in asthma and chronic obstructive pulmonary disease?', 'chunks': ['It is well known that the lungs of asthmatics show airway wall remodelling and that asthma exacerbations are linked to respiratory infections. There is some evidence that respiratory infections in early childhood may increase the risk of developing asthma later in life. Chronic obstructive pulmonary disease (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling. This review considers the role of matrix metalloproteases and neutrophil elastase in remodelling, and whether the induction of proteases and other mediators during respiratory virus infections may contribute to the development of airway remodelling.'], 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pubmed/16286234/', 'vectorized': None}, {'@search.score': 18.031353, '@search.rerankerScore': 2.262484550476074, '@search.captions': [{'text': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP).', 'highlights': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11<em> rotavirus core-like particles</em> (CLP) or virus-like particles (VLP).'}], 'id': 'u2g30x1j', 'title': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)', 'chunks': ['The isotype antibody responses to bovine IND P(5), G6 and simian SA11 P(2), G3 rotavirus and SA11 rotavirus proteins (VP4, VP6 and VP7) in serum, colostrum and milk were analysed by ELISA in three groups of vaccinated cows and nonvaccinated controls. Pregnant cows were vaccinated intramuscularly and intramammarily with recombinant baculovirus-expressed SA11 rotavirus VLP (triple-layered virus-like particles containing rotavirus VP2, VP4, VP6 and VP7); CLP (double-layered core-like particles containing rotavirus VP2 and VP6); or inactivated SA11 rotavirus, respectively. Rotavirus antigen titers were highest (30–200-fold) in ELISA in the VLP vaccine compared to the inactivated SA11 vaccine. The IgG1, IgG2 and IgM geometric mean antibody titers (GMT) to rotavirus (titers to bovine rotavirus vs SA11 rotavirus did not differ significantly for any isotype or group) and the IgG2 GMT to VP6 in serum at calving in the vaccinated groups were significantly (P <0.05) higher than in the control group. In colostrum, IgG1 and IgA rotavirus antibody titers were significantly elevated for VLP (IgG1 GMT 832225; IgA GMT 16384), CLP (IgG1 GMT 660561; IgA GMT 10321) and SA11 (IgG1 GMT 131072; IgA GMT 1448) vaccinated cows compared to control cows (IgG1 GMT 11585; IgA GMT 45). The IgG1 and IgA GMT to rotavirus were significantly elevated (6–100-fold) in milk of VLP and CLP vaccinated cows compared to SA11 vaccinated or control cows. The isotype antibody responses to VP6 in serum, colostrum and milk paralleled the responses to rotavirus, but titers were ∼2–10-fold lower. Only cows vaccinated with VLP had significantly enhanced serum, colostral and milk antibody titers to rotavirus VP4 and VP7. These results demonstrate that rotavirus antibody titers in serum, colostrum and milk are significantly enhanced by use of non-infectious VLP, CLP and inactivated SA11 rotavirus vaccines, but the VLP or CLP vaccines induced the highest antibody responses, corresponding to their higher rotavirus antigen titers measured by ELISA.'], 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7131174/', 'vectorized': None}, {'@search.score': 12.174453, '@search.rerankerScore': 2.1104471683502197, '@search.captions': [{'text': 'Cold-inducible RNA-binding protein (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys.', 'highlights': 'Cold-inducible<em> RNA-binding protein</em> (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys.'}], 'id': 'ofsjs3nn', 'title': 'A cold-inducible RNA-binding protein (CIRP)-derived peptide attenuates inflammation and organ injury in septic mice', 'chunks': ['Cold-inducible RNA-binding protein (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys. First, we confirmed that C23 dose-dependently inhibited TNF-α release, IκBα degradation, and NF-κB nuclear translocation in macrophages stimulated with CIRP. Next, we observed that male C57BL/6 mice treated with C23 (8 mg/kg BW) at 2 h after cecal ligation and puncture (CLP) had lower serum levels of LDH, ALT, IL-6, TNF-α, and IL-1β (reduced by ≥39%) at 20 h after CLP compared with mice treated with vehicle. C23-treated mice also had improved lung histology, less TUNEL-positive cells, lower serum levels of creatinine (34%) and BUN (26%), and lower kidney expression of NGAL (50%) and KIM-1 (86%). C23-treated mice also had reduced lung and kidney levels of IL-6, TNF-α, and IL-1β. E-selectin and ICAM-1 mRNA was significantly lower in C23-treated mice. The 10-day survival after CLP of vehicle-treated mice was 55%, while that of C23-treated mice was 85%. In summary, C23 decreased systemic, lung, and kidney injury and inflammation, and improved the survival rate after CLP, suggesting that it may be developed as a new treatment for sepsis.'], 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5809586/', 'vectorized': None}, {'@search.score': 13.193248, '@search.rerankerScore': 1.8762637376785278, '@search.captions': [{'text': 'The mainstay of community-acquired pneumonia prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease..\\x00', 'highlights': 'The mainstay of<em> community-acquired pneumonia</em> prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease..\\x00'}], 'id': 'rd3bed48', 'title': 'Community-acquired pneumonia: what is relevant and what is not?', 'chunks': ['PURPOSE OF REVIEW Community-acquired pneumonia is associated with significant morbidity and mortality and is the most common cause of death from infectious diseases in North America. The purpose of this review is to highlight recent advances in epidemiology, risk factors, severity criteria and antibiotic therapeutic regimens used for community-acquired pneumonia management. RECENT FINDINGS All guidelines recommend early and appropriate empiric therapy directed against common typical organisms, such as Streptococcus pneumoniae, and other atypical organisms, but clinicians should be aware of newer emerging pathogens such as community-acquired methicillin-resistant Staphylococcus aureus and Gram-negative pathogens. SUMMARY The optimum outcome in community-acquired pneumonia can be achieved by careful risk stratification using prediction rules together with appropriate antibiotic regimens. The mainstay of community-acquired pneumonia prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease.'], 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pubmed/17414124/', 'vectorized': None}, {'@search.score': 10.3500395, '@search.rerankerScore': 1.8561580181121826, '@search.captions': [{'text': 'The direct costs associated with RSV hospitalization were on average CLP $ 413,529 (US$ 632.1) for Group 1, and CLP $ 744,260 (US$ 1,137.6) for Group 2 (p < 0.05). There was also statistically significant higher cost for Group 2 due to tests and drugs (p < 0.05) and costs per day of hospital stay (p < 0.05).', 'highlights': ''}], 'id': 'eyvywyob', 'title': 'Direct costs of low respiratory infection due to RSV in children under one year.', 'chunks': ['INTRODUCTION Considering the high prevalence of respiratory infections in hospitalized infants with Respiratory Syncytial Virus (RSV), the objective of this study is to determine the direct costs of this infection. PATIENTS AND METHOD Prospective longitudinal study in infants under one year of age hospitalized due to RSV during 2015. The patients were divided into 2 groups, Group 1 pa tients without risk factors and Group 2 patients with risk factors (prematurity, oxygen dependence, bronchopulmonary dysplasia, heart disease, immunocompromised patients), comparing each other variables such as nutritional status, gender, breastfeeding, discharge diagnosis, radiological diagno sis, length of hospital stay, among others. Direct costs for hospitalization were estimated according to the fees of the National Health Fund (FONASA) and the Modality of Institutional Care (MAI). RESULTS The total patients admitted in the period were 260: 234 (90%) in Group 1 and 26 (10%) in Group 2. The average hospital stay for Group 1 was 7.3 days (SD+5.1) with a median of 6 days, and 13.6 days (SD+16.3) for Group 2 with a median of 7 days (p < 0.05). The direct costs associated with RSV hospitalization were on average CLP $ 413,529 (US$ 632.1) for Group 1, and CLP $ 744,260 (US$ 1,137.6) for Group 2 (p < 0.05). There was also statistically significant higher cost for Group 2 due to tests and drugs (p < 0.05) and costs per day of hospital stay (p < 0.05). CONCLUSION These values, known for the first time in the national reality, confirm the high cost of these infections and particularly in risk groups.'], 'name': 'metadata.csv', 'location': 'https://doi.org/10.4067/s0370-41062018005000401; https://www.ncbi.nlm.nih.gov/pubmed/30571819/', 'vectorized': None}]}\n",
            "Number of results: 20\n"
          ]
        }
      ],
      "source": [
        "k = 10 # Number of results per each text_index\n",
        "ordered_results = get_search_results(QUESTION, indexes, k=10, reranker_threshold=1)\n",
        "print(\"Number of results:\",len(ordered_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7714f38a-daaa-4fc5-a95a-dd025d153216",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment the below line if you want to inspect the ordered results\n",
        "# ordered_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da70e7a8-7536-4688-b30c-01ba28e9b9f8",
      "metadata": {},
      "source": [
        "Now we can fill up the vector-based index as users lookup documents using the text-based index. This approach although it requires two searches per user query (one on the text-based indexes and the other one on the vector-based indexes), it is simpler to implement and will be incrementatly faster as user use the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2937ba3b-098d-43f8-8498-3534882a5cc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "embedder = AzureOpenAIEmbeddings(model=\"text-embedding-ada-002\", skip_empty=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f664df30-99c3-4a30-8cb0-42ba3044e5b0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorizing 7 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0508/0508108v1.pdf\n",
            "Vectorizing 5 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0701/0701082v1.pdf\n",
            "Vectorizing 8 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0508/0508106v1.pdf\n",
            "Vectorizing 8 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0011/0011030v1.pdf\n",
            "Vectorizing 14 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0506/0506005v1.pdf\n",
            "Vectorizing 13 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0408/0408056v1.pdf\n",
            "Vectorizing 11 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0310/0310042v1.pdf\n",
            "Vectorizing 8 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0003/0003026v1.pdf\n",
            "Vectorizing 8 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0402/0402019v1.pdf\n",
            "Vectorizing 1 chunks from Document: https://www.ncbi.nlm.nih.gov/pubmed/10403670/\n",
            "Vectorizing 19 chunks from Document: https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0404/0404053v1.pdf\n",
            "Vectorizing 1 chunks from Document: https://www.ncbi.nlm.nih.gov/pubmed/17047515/\n",
            "Vectorizing 1 chunks from Document: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7103146/\n",
            "Vectorizing 1 chunks from Document: https://doi.org/10.4103/0974-7796.156145; https://www.ncbi.nlm.nih.gov/pubmed/26229312/\n",
            "Vectorizing 1 chunks from Document: https://api.elsevier.com/content/article/pii/S0033318220301420; https://www.sciencedirect.com/science/article/pii/S0033318220301420?v=s5\n",
            "Vectorizing 1 chunks from Document: https://www.ncbi.nlm.nih.gov/pubmed/16286234/\n",
            "Vectorizing 1 chunks from Document: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7131174/\n",
            "Vectorizing 1 chunks from Document: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5809586/\n",
            "Vectorizing 1 chunks from Document: https://www.ncbi.nlm.nih.gov/pubmed/17414124/\n",
            "Vectorizing 1 chunks from Document: https://doi.org/10.4067/s0370-41062018005000401; https://www.ncbi.nlm.nih.gov/pubmed/30571819/\n",
            "CPU times: total: 21.4 s\n",
            "Wall time: 1min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for key,value in ordered_results.items():\n",
        "    if value[\"vectorized\"] != True: # If the document has not been vectorized yet\n",
        "        i = 0\n",
        "        print(\"Vectorizing\",len(value[\"chunks\"]),\"chunks from Document:\",value[\"location\"])\n",
        "        for chunk in value[\"chunks\"]: # Iterate over the document's text chunks\n",
        "            try:\n",
        "                upload_payload = {  # Insert the chunk and its vector in the vector-based index\n",
        "                    \"value\": [\n",
        "                        {\n",
        "                            \"id\": key + \"_\" + str(i),\n",
        "                            \"title\": f\"{value['title']}_chunk_{str(i)}\",\n",
        "                            \"chunk\": chunk,\n",
        "                            \"chunkVector\": embedder.embed_query(chunk if chunk!=\"\" else \"-------\"),\n",
        "                            \"name\": value[\"name\"],\n",
        "                            \"location\": value[\"location\"],\n",
        "                            \"@search.action\": \"upload\"\n",
        "                        },\n",
        "                    ]\n",
        "                }\n",
        "\n",
        "                r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + value[\"index\"]+\"-vector\" + \"/docs/index\",\n",
        "                                     data=json.dumps(upload_payload), headers=headers, params=params)\n",
        "                \n",
        "                if r.status_code != 200:\n",
        "                    print(r.status_code)\n",
        "                    print(r.text)\n",
        "                else:\n",
        "                    i = i + 1 # increment chunk number\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(\"Exception:\",e)\n",
        "                print(chunk)\n",
        "                continue\n",
        "\n",
        "        # Update document in text-based index and mark it as \"vectorized\"\n",
        "        upload_payload = {\n",
        "            \"value\": [\n",
        "                {\n",
        "                    \"id\": key,\n",
        "                    \"vectorized\": True,\n",
        "                    \"@search.action\": \"merge\"\n",
        "                },\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + value[\"index\"]+ \"/docs/index\",\n",
        "                                     data=json.dumps(upload_payload), headers=headers, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f490b7fe-eec2-4c96-a2f2-f8ab0a1b2098",
      "metadata": {},
      "source": [
        "**Note**: How the text-based and the vector-based indexes stay in sync?\n",
        "For document changes, the problem is already taken care of, since Azure Engine will update the text-based index automatically if a file has a new version. This puts the vectorized field in None and the next time that the file is searched it will be vectorized again into the vector-based index.\n",
        "\n",
        "However for deletion of files, the problem is half solved. Azure Search engine would delete the documents in the text-based index if the file is deleted on the source, however you will need to code a script that runs on a fixed schedule that looks for deleted ids in the text-based index and deletes the corresponding chunks in the vector-based index."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f67f3a2-0023-4f5a-b52f-3fb071cfd8e1",
      "metadata": {},
      "source": [
        "Now we search on the vector-based indexes and get the top k most similar chunks to our question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "61098bb4-33da-4eb4-94cf-503587337aca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'@odata.context': \"https://gptkb-3hhfqf2n5qzbc.search.windows.net/indexes('cogsrch-index-files-vector')/$metadata#docs(*)\", '@odata.count': 98, '@search.answers': [{'key': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMzEwLzAzMTAwNDJ2MS5wZGY1_2', 'text': 'A CLP(FD) program searches a solution for a set of variables which take values over finite domains and which must verify a set of constraints. The evolution of the domains can be viewed as a sequence of applications of reduction operators attached to the constraints.', 'highlights': 'A CLP(FD) program searches<em> a solution for a set of variables which take values over finite domains and which must verify a set of constraints.</em> The evolution of the domains can be viewed as a sequence of applications of reduction operators attached to the constraints.', 'score': 0.9228515625}], 'value': [{'@search.score': 0.010989011265337467, '@search.rerankerScore': 3.0801165103912354, '@search.captions': [{'text': 'A CLP(C) program is a finite set of rules. A rule has the form H ← c⋄B where H and B are atoms and c is a finite conjunction of primitive constraints such that DC |= ∃c. A query has the form 〈A | d〉 where A is an atom and d is a finite conjunction of primitive constraints. Given an atom A := p(t̃), we write rel(A) to denote the predicate symbol p.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNTA4LzA1MDgxMDZ2MS5wZGY1_2', 'title': 'arXiv:cs/0508106v1  [cs.PL]  24 Aug 2005_chunk_2', 'chunk': 'true if and only if TC |= ∃c. Consequently, as DC and TC correspond on LC ,\\nwe have, for every c ∈ LC , solvC(c) = true if and only if DC |= ∃c.\\n\\nExample 1 (Rlin). The constraint domain Rlin has <, ≤, =, ≥ and > as pred-\\nicate symbols, +, −, ∗, / as function symbols and sequences of digits (possibly\\nwith a decimal point) as constant symbols. Only linear constraints are admitted.\\nThe domain of computation is the structure with reals as domain and where the\\npredicate symbols and the function symbols are interpreted as the usual relations\\nand functions over reals. The theory TRlin\\n\\nis the theory of real closed fields [17].\\nA constraint solver for Rlin always returning either true or false is described\\nin [15].\\n\\nExample 2 (Logic Programming). The constraint domain Term has = as pred-\\nicate symbol and strings of alphanumeric characters as function symbols. The\\ndomain of computation of Term is the set of finite trees (or, equivalently, of finite\\nterms), Tree, while the theory TTerm is Clark’s equality theory [2]. The interpre-\\ntation of a constant is a tree with a single node labeled with the constant. The\\ninterpretation of an n-ary function symbol f is the function fTree : Treen → Tree\\nmapping the trees T1, . . . , Tn to a new tree with root labeled with f and with\\nT1, . . . , Tn as child nodes. A constraint solver always returning either true or\\nfalse is provided by the unification algorithm. CLP(Term) coincides then with\\nlogic programming.\\n\\n4\\n\\n\\n\\n2.4 Operational Semantics\\n\\nThe signature in which all programs and queries under consideration are in-\\ncluded is ΣL := 〈FL, ΠL〉 with FL := FC and ΠL := ΠC ∪ Π ′\\n\\nL where Π ′\\nL, the\\n\\nset of predicate symbols that can be defined in programs, is disjoint from ΠC .\\nWe assume that each predicate symbol p in ΠL has a unique arity denoted by\\narity(p).\\n\\nAn atom has the form p(t̃) where p ∈ Π ′\\nL and t̃ is a sequence of arity(p) ΣL-\\n\\nterms. Throughout this paper, when we write p(t̃), we implicitly assume that t̃\\ncontains arity(p) terms. A CLP(C) program is a finite set of rules. A rule has the\\nform H ← c⋄B where H and B are atoms and c is a finite conjunction of primitive\\nconstraints such that DC |= ∃c. A query has the form 〈A | d〉 where A is an atom\\nand d is a finite conjunction of primitive constraints. Given an atom A := p(t̃),\\nwe write rel(A) to denote the predicate symbol p. Given a query S := 〈A | d〉, we\\nwrite rel(S) to denote the predicate symbol rel(A). The set of variables occurring\\nin some syntactic objects O1, . . . , On is denoted Var(O1, . . . , On).\\n\\nThe examples of this paper make use of the language CLP(Rlin) and the\\nlanguage CLP(Term). In program and query examples, variables begin with an\\nupper-case letter, [Head |Tail ] denotes a list with head Head and tail Tail , and\\n[ ] denotes an empty list.\\n\\nWe consider the following operational semantics given in terms of derivations\\nfrom queries to queries. Let 〈p(ũ) | d〉 be a query and r := p(s̃) ← c ⋄ q(t̃) be a\\nrule. Let r′ := p(s̃′)← c′ ⋄ q(t̃′) be a variant of r variable disjoint with 〈p(ũ) | d〉\\nsuch that solvC(s̃′ = ũ∧c′∧d) = true. Then, 〈p(ũ) | d〉=⇒\\n\\nr\\n〈q(t̃′) | s̃′ = ũ ∧ c′ ∧ d〉\\n\\nis a derivation step of 〈p(ũ) | d〉 with respect to r with r′ as its input rule. We\\n\\nwrite S\\n+\\n\\n=⇒\\nP\\n\\nS′ to summarize a finite number (> 0) of derivation steps from S to\\n\\nS′ where each input rule is a variant of a rule from program P . Let S0 be a query.\\nA sequence of derivation steps S0 =⇒\\n\\nr1\\n\\nS1 =⇒\\nr2\\n\\n· · · of maximal length is called a\\n\\nderivation of P ∪ {S0} if r1, r2, . . . are rules from P and if the standardization\\napart condition holds, i.e. each input rule used is variable disjoint from the initial\\nquery S0 and from the input rules used at earlier steps. We say S0 loops with\\nrespect to P if there exists an infinite derivation of P ∪ {S0}.\\n\\n3 Loop Inference with Constraints\\n\\nIn the logic programming framework, the subsumption test provides a simple\\nway to infer looping queries: if, in a logic program P , there is a rule p(s̃)← p(t̃)\\nsuch that p(t̃) is more general than p(s̃), then the query p(s̃) loops with respect\\nto P . In this section, we extend this result to the constraint logic programming\\nframework.\\n\\n3.1 A “More General Than” Relation\\n\\nA query can be viewed as a finite description of a possibly infinite set of atoms,\\nthe arguments of which are values from DC .\\n\\n5\\n\\n\\n\\nExample 3. Suppose that C = Rlin .\\n\\n– The query 〈p(2 ∗X) |X ≥ −1〉 describes those atoms p(x) where x is a real\\nand the term 2 ∗X can be made equal to x while the constraint X ≥ −1 is\\nsatisfied.\\n\\n– The query 〈q(X, Y ) |Y ≤ X + 2〉 describes those atoms q(x, y) where x and\\ny are reals and X and Y can be made equal to x and y respectively while\\nthe constraint Y ≤ X + 2 is satisfied.\\n\\nIn order to capture this intuition, we introduce the following definition.\\n\\nDefinition 1 (Set Described by a Query). The set of atoms that is described\\nby a query S := 〈p(t̃) | d〉 is denoted by Set(S) and is defined as: Set(S) =\\n{p(v(t̃)) | DC |=v d}.\\n\\n', 'name': '0508106v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0508/0508106v1.pdf'}, {'@search.score': 0.025987006723880768, '@search.rerankerScore': 2.8434436321258545, '@search.captions': [{'text': 'A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1 Constraint Logic Programming  Constraint logic programming (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers).', 'highlights': 'A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1<em> Constraint Logic Programming  Constraint logic programming</em> (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers).'}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMDExLzAwMTEwMzB2MS5wZGY1_1', 'title': 'arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000_chunk_1', 'chunk': 'This paper is an extension and revision of [17] which\\nfocuses more on the formal relations between the declarative specifications of\\nthe problems on the different systems.\\n\\nOne more problem which uses aggregate functions is included in the present\\npaper. So is an additional experiment for finding all solutions of the n-queens\\nproblem. Finally, some comments from the authors of the different systems were\\ntaken into account.\\n\\n2 Formalisms and Systems\\n\\nA constraint satisfaction problem (CSP) is usually defined as a finite set of con-\\n\\nstraint variables X = {X1, . . . , Xn} (the variables of the CSP), a finite domain\\nDi of possible values for each variable Xi, and a finite set of constraint relations\\n\\n\\n\\nR where each r ∈ R is a constraint between a subset of the set X of variables. A\\nsolution is an instantiation of the variables of X which satisfies all the constraints\\nin R.\\n\\n2.1 Constraint Logic Programming\\n\\nConstraint logic programming (CLP) [7] is an extension of logic programming\\nwhere some of the predicate and function symbols have a fixed interpretation over\\nsome subdomain (e.g. finite trees or real numbers). Special purpose constraint\\nsolvers are integrated with a logic programming system for efficient reasoning on\\nthese symbols. This results in a very expressive language which can efficiently\\nsolve problems in many domains.\\n\\nVan Hentenryck [20] pioneered the work on finite domain constraint logic\\nprogramming, CLP(FD), by introducing domain declarations for the logic vari-\\nables and integrating consistency techniques as part of the SLD proof procedure.\\nA CLP(FD) system supports standard arithmetic relations (=, 6=, <) and func-\\ntions (+,−, ∗) on the natural numbers. A typical formulation of the n-queens\\nproblem is as follows:\\n\\nqueens(N, L)←\\nlength(L, N),\\ndomain(L, 1, N),\\nconstrain all(L),\\nlabeling(L).\\n\\nconstrain all([]).\\nconstrain all([X |Xs])←\\n\\nconstrain between(X, Xs, 1)\\nconstrain all(Xs).\\n\\nconstrain between(X, [], N).\\nconstrain between(X, [Y |Y s], N)←\\n\\nsafe(X, Y, N),\\nN1 is N + 1,\\nconstrain between(X, Y s, N1).\\n\\nsafe(X1, X2, D)←\\nX1 6= X2, abs(X1 −X2) 6= D.\\n\\nExecuting the query queens(n, L) first creates a list L with n variables where\\nthe ith variable gives the column position of the queen on row i. Then the\\nconstraints expressed with the safe/3 predicate are added by using two nested\\nrecursive predicates. Such procedural code for setting up constraints and the\\nencoding of the solution in a large data structure results in a rather procedural\\nstyle which is typical for the CLP approach.\\n\\n2.2 First Order Logic: Model Generation\\n\\nThe most elegant solution for the n-queens problem is using many sorted first\\norder logic and first order model generation. Systems like FINDER and SEM\\n\\n\\n\\n[24] are examples. One can introduce functions (with the sorts of their domain\\nand range) and predicates (with the sorts of their domains and the sort bool as\\nrange). In addition, functions can be restricted to be injective, bijective, . . . This\\nallows to express the n-queens problem very concisely as:\\n\\nD = {1..n}\\n\\npos : D → D (bijection)\\n\\nabs(pos(X1)− pos(X2)) 6= X2 −X1 ← X1 < X2.\\n\\nThe first line declares D as a sort with interpretation consisting of the set of\\nintegers 1 to n. The following line introduces the function pos/1 as a bijection\\nfrom D to D. Hence, the range of the function is a permutation of its domain.\\nThis function represents the column positions of the queens. The only remaining\\nconstraint is that queens have to be on different diagonals. This is expressed by\\nthe formula on the third line using the predefined functions abs/1 and −/2. Due\\nto symmetry, one need only to verify the constraint for pairs of queens X1, X2\\n\\nsuch that X1 < X2.\\n\\nSolutions are given by the interpretation of the pos/1 function in the models\\nof this theory. In principle, this approach is applicable on any CSP problem by\\nrepresenting the CSP variables by logical constants. However, in most cases, CSP\\nvariables are just an encoding of some attribute of a set of first order objects,\\nsuch as the position of a queen or the color of a node in a graph. In such cases,\\nthere is no need to introduce the CSP variable. The attribute can be represented\\ndirectly as a function or predicate on these objects (e.g. pos).\\n\\nAs the domains of all sorts are finite, SEM first computes the grounding\\nof the theory and then uses backtracking combined with various inference and\\nsimplification rules to guide the search for models [24].\\n\\n2.3 Stable Logic Programming\\n\\nIn [14], Niemelä proposes logic programming with the stable model semantics [6]\\nas a constraint logic programming paradigm. The underlying idea is to represent\\na problem as a set of rules, each rule being the declarative expression of a piece\\nof knowledge about the problem domain and such that the stable models of the\\nwhole program are constrained to be solutions of the problem.\\n\\nThe smodels system [15] is an efficient implementation of the stable model\\nsemantics. ', 'name': '0011030v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0011/0011030v1.pdf'}, {'@search.score': 0.012048192322254181, '@search.rerankerScore': 2.819699764251709, '@search.captions': [{'text': 'CLP(FD) languages have been suc-  cessfully used for solving a variety of industrial and academic problems. However,  in some constraint problems, where domain elements need to be acquired, it may  not be wise to perform the acquisition of the whole domains of variables before the  beginning of the constraint propagation process.', 'highlights': '<em>CLP(FD)</em> languages have been suc-  cessfully used for solving a variety of industrial and academic problems. However,  in some constraint problems, where domain elements need to be acquired, it may  not be wise to perform the acquisition of the whole domains of variables before the  beginning of the constraint propagation process.'}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNDA4LzA0MDgwNTZ2MS5wZGY1_0', 'title': 'None_chunk_0', 'chunk': '\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n04\\n\\n08\\n05\\n\\n6v\\n1 \\n\\n [\\ncs\\n\\n.L\\nO\\n\\n] \\n 2\\n\\n4 \\nA\\n\\nug\\n 2\\n\\n00\\n4\\n\\nTo appear in Theory and Practice of Logic Programming (TPLP) 1\\n\\nA CHR-based Implementation\\n\\nof Known Arc-Consistency\\n\\nMARCO ALBERTI, MARCO GAVANELLI, EVELINA LAMMA\\n\\nDipartimento di Ingegneria, Università degli Studi di Ferrara\\n\\nPAOLA MELLO, MICHELA MILANO\\n\\nDipartimento di Elettronica, Informatica e Sistemistica, Università degli Studi di Bologna\\n\\nsubmitted 31 August 2002; revised 13 November 2003, 30 June 2004; accepted 9 August 2004\\n\\nAbstract\\n\\nIn classical CLP(FD) systems, domains of variables are completely known at the beginning\\nof the constraint propagation process. However, in systems interacting with an external\\nenvironment, acquiring the whole domains of variables before the beginning of constraint\\npropagation may cause waste of computation time, or even obsolescence of the acquired\\ndata at the time of use.\\n\\nFor such cases, the Interactive Constraint Satisfaction Problem (ICSP) model has been\\nproposed (Cucchiara et al. 1999a) as an extension of the CSP model, to make it possible\\nto start constraint propagation even when domains are not fully known, performing ac-\\nquisition of domain elements only when necessary, and without the need for restarting the\\npropagation after every acquisition.\\n\\nIn this paper, we show how a solver for the two sorted CLP language, defined in previous\\nwork (Gavanelli et al. 2004) to express ICSPs, has been implemented in the Constraint\\nHandling Rules (CHR) language, a declarative language particularly suitable for high level\\nimplementation of constraint solvers.\\n\\n1 Introduction\\n\\nConstraint Logic Programming on Finite Domains (CLP(FD)) represents one of the\\n\\nmost successful implementations of declarative languages. By means of constraints,\\n\\nthe user can give the specifications of a combinatorial problem and possibly solve\\n\\nit, exploiting efficient propagation algorithms. CLP(FD) languages have been suc-\\n\\ncessfully used for solving a variety of industrial and academic problems. However,\\n\\nin some constraint problems, where domain elements need to be acquired, it may\\n\\nnot be wise to perform the acquisition of the whole domains of variables before the\\n\\nbeginning of the constraint propagation process. For instance, in configuration prob-\\n\\nlems (Mailharro 1998; ILOG 1999) domain elements represent components, which\\n\\nhave to be synthesized before being used. The set of components is not known\\n\\nbeforehand, and sometimes even the size of the set cannot be estimated. Often,\\n\\na minimization of the set of components is required, thus the constraint solver\\n\\nproduces a new component only when it is strictly necessary.\\n\\nIn systems that need to interact with an external environment, domain elements\\n\\nhttp://arXiv.org/abs/cs/0408056v1\\n\\n\\n2 M.Alberti et al.\\n\\ncan be produced by an acquisition system that retrieves information about the outer\\n\\nworld. An example is given by Faltings and Macho-Gonzalez (2003) where Internet\\n\\napplications are faced and obviously not all the information can be computed before\\n\\nstarting the constraint satisfaction process. As another example, consider a visual\\n\\nsearch system (Cucchiara et al. 1999b) where domain elements are basic visual fea-\\n\\ntures (like segments, points, or surface patches) extracted from the image. In a\\n\\nclassical CLP(FD) computation, all domain values must be known when defining\\n\\nthe variables, so all the possible visual features would have to be extracted before\\n\\nstarting the visual search process, even if only a small subset of them will be actu-\\n\\nally used. The synthesis of visual features is usually very time consuming, because\\n\\nthe information encoded with signals must be converted into symbolic form. Thus,\\n\\nthe extraction of domain elements that will not be used can result in a significant\\n\\nwaste of computation time. Also, in systems that interact with an evolving environ-\\n\\nment, full acquisition of all the domain elements is not wise (Barruffi et al. 1999). In\\n\\nfact, if all the possible information is acquired beforehand, some of the information\\n\\nmight be obsolete at the end of the acquisition.\\n\\nFor all these reasons, a new model called Interactive Constraint Satisfaction\\n\\nProblem (ICSP) has been proposed (Cucchiara et al. 1999a) as an extension of the\\n\\nwidely used Constraint Satisfaction Problem (CSP) model. In an ICSP, domains\\n\\nconsist of a known part, containing the available elements, plus a variable that\\n\\nsemantically represents a set of values that could be added to the domain in the\\n\\nfuture. In a sense, in an ICSP, domains can be considered as streams of information\\n\\nfrom one system to the constraint solver. Constraint propagation can be performed\\n\\neven when the domains are not completely known, and domain values can be re-\\n\\nquested from an acquisition system during constraint propagation; in other words,\\n\\nconstraint propagation and value acquisition interact (thus Interactive in the name\\n\\n', 'name': '0408056v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0408/0408056v1.pdf'}, {'@search.score': 0.012820512987673283, '@search.rerankerScore': 2.635876178741455, '@search.captions': [{'text': 'The CLP consistency techniques seem to be much less sensitive to the domains size, and this carries over to the abductive systems which reduce the problem to a CLP problem and then use the CLP solver to search for the solution.  6This strategy is sometimes abbreviated to ffc.    0  20  40  60  80  100  120  0 10 20 30 40 50 60  T im  e  (s  ec .)', 'highlights': 'The<em> CLP</em> consistency techniques seem to be much less sensitive to the domains size, and this carries over to the abductive systems which reduce the problem to a<em> CLP</em> problem and then use the<em> CLP</em> solver to search for the solution.  6This strategy is sometimes abbreviated to ffc.    0  20  40  60  80  100  120  0 10 20 30 40 50 60  T im  e  (s  ec .)'}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMDAzLzAwMDMwMjZ2MS5wZGY1_5', 'title': 'arXiv:cs/0003026v1  [cs.LO]  8 Mar 2000_chunk_5', 'chunk': 'interpretation of the open predicates. It is proven in\\n(Cadoli & Palopoli 1998) that the data complexity of\\ndeciding whether a query is not entailed by the pro-\\ngram is NP-complete which means that one can express\\nany CSP in this formalism. However, as the language\\ndoes not contain negation, one can not use directly the\\nmethodology discussed above for representing CSPs.\\n\\nIn (Cadoli et al. 1999) is defined the language np-\\n\\nspec which is an extension of datalog\\nCIRC and allows\\n\\na more natural representation of problems. The main\\ndifference is that it supports special meta-declarations,\\ncalled tailoring predicates, restricting the domain and\\nthe interpretation of the open predicates. The most\\nsimple one is of the form Subset(domain/n, pred)\\nwhich defines pred/n to be an open predicate and\\nits interpretation should be a subset of the interpre-\\ntation of the predicate domain/n. Another declara-\\ntion is Partition(domain/n, pred, m) which states that\\nthe predicate pred/n should be partitioned in m sets\\nwhich is, in fact, equivalent to a function with domain\\ndomain/n and a range 0..m− 1. The two other tailor-\\ning predicates are Permutation(domain/n, pred) and\\nIntFunc(domain/n, pred, min..max) which express re-\\nspectively that pred/n is a bijection from domain/n\\nto 0..domain/n − 1 and pred/n is a function with a\\nrange min..max. Another extension of np-spec is the\\nsupport of a predefined arithmetic functions and pred-\\nicates.\\n\\nThe formulation of the graph coloring problem in the\\nnp-spec language is given below. The input of the\\nprogram consists of facts node/1 and edge/2 describing\\nthe graph.\\n\\nPartition(node/1, color, 4).\\n\\n⇐ edge(V1, V2), color(V1, C1), color(V2, C2).\\n\\nExperiments\\n\\nThe Systems\\n\\nThe finite domain CLP package is the one provided with\\nSICStus version 3.7. Given the reputation of SICS-\\ntus and of finite domain CLP, one can assume it offers\\nstate of the art technology for CSP solving and it is a\\ngood yardstick to judge the performance of other sys-\\ntems. The abductive system ACLP (Kakas, Michael,\\n& Mourlas 2000) is a meta interpreter written in Pro-\\nlog, runs on Eclipse version 4.2 and makes use of its fi-\\nnite domain package. The abductive system SLDNFAC\\n(Denecker & Van Nuffelen 1999) is also a meta inter-\\npreter written in Prolog but runs on SICStus version\\n3.7 and makes use of the SICStus finite domain pack-\\nage. The model generator SEM (Zhang & Zhang 1995)\\nversion 1.7 is a fine tuned package written in C. smodels\\n(Niemelä & Simons 1996) version 2.25, the system for\\ncomputing stable models is implemented in C++ and\\nthe associated program used grounding is lparse version\\n0.99.48. All experiments have been done on the same\\nhardware, namely Pentium II.\\n\\nAll systems based on a finite domain constraint solver\\nused a labeling strategy which first selects variables\\nwith the smallest domain and then the ones which par-\\nticipate in the highest number of constraints6.\\n\\nN-Queens\\n\\nFigure 6 gives the running times for the different sys-\\ntems and figure 7 gives the number of backtracks. The\\ntwo abductive systems (ACLP and SLDNFAC) do not\\nintroduce any extra choice points compared to CLP and\\nhence are not plotted in figure 7. Not surprisingly, CLP\\ngives the best results. SLDNFAC is second best and,\\nalthough meta-interpretation overhead increases with\\nproblem size, deteriorates very slowly. SEM is third\\nbut runs out of memory for large problems (it needs\\nabout 120MB for 27 queens). This is probably caused\\nby a not very good techniques for grounding the prob-\\nlem and exploring the search space. The times given\\nfor SEM do not include time spend by the operating\\nsystem in managing the memory which becomes con-\\nsiderable for the larger instances of the problem. ACLP\\nperforms substantially worse than SLDNFAC and de-\\ngrades more quickly for the larger problems. It can\\nlikely be attributed to the more experimental nature\\nof the implementation. smodels performs very poorly\\non this problem, in particular when compared with its\\nperformance on the graph coloring problem. As can be\\nseen from figure 7 the main reason seems to be the large\\nnumber of backtracks it does.\\n\\nThe CLP consistency techniques seem to be much\\nless sensitive to the domains size, and this carries over\\nto the abductive systems which reduce the problem to\\na CLP problem and then use the CLP solver to search\\nfor the solution.\\n\\n6This strategy is sometimes abbreviated to ffc.\\n\\n\\n\\n0\\n\\n20\\n\\n40\\n\\n60\\n\\n80\\n\\n100\\n\\n120\\n\\n0 10 20 30 40 50 60\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nQueens\\n\\nN-Queens\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFigure 6: N-Queens: Running times\\n\\n0\\n\\n100\\n\\n200\\n\\n300\\n\\n400\\n\\n500\\n\\n600\\n\\n700\\n\\n800\\n\\n0 10 20 30 40 50 60\\n\\nB\\nac\\n\\nkt\\nra\\n\\nck\\ns\\n\\nQueens\\n\\nN-Queens\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFigure 7: N-Queens: Number of backtracks.\\n\\n\\n\\n0.01\\n\\n0.1\\n\\n1\\n\\n10\\n\\n100\\n\\n1000\\n\\n10000\\n\\n100000\\n\\n10 100 1000 10000 100000\\n\\nT\\nim\\n\\ne \\n(s\\n\\nec\\n.)\\n\\nEdges\\n\\nGraph Coloring\\n\\nACLP\\nSLDNFAC\\n\\nSEM\\nCLP\\n\\nsmodels\\n\\nFigure 8: Graph Coloring\\n\\nGraph Coloring\\n\\nWe used a graph generator program which is\\n', 'name': '0003026v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0003/0003026v1.pdf'}, {'@search.score': 0.016129031777381897, '@search.rerankerScore': 2.610217571258545, '@search.captions': [{'text': 'A CLP(FD) program searches a solution for a set of variables which take values over finite domains and which must verify a set of constraints. The evolution of the domains can be viewed as a sequence of applications of reduction operators attached to the constraints.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMzEwLzAzMTAwNDJ2MS5wZGY1_2', 'title': '()_chunk_2', 'chunk': 'Section 4 outlines the trace analysis step. In particular,\\nit briefly presents the connection to a trace analyzer and lists some interesting graphical views for\\nCLP(FD). Section 5 discusses the low-level implementation of tracers. Section 6 sketches the valida-\\ntion of the efficient tracer against the prototype implementation.\\n\\n2 Formal specification of a trace model\\n\\nThe first step of our methodology is to specify a trace model, namely what information about pro-\\ngram executions should be given. In our sequential language context, a trace is a sequence of events.\\nAn event represents an interesting execution step, it can be seen as an execution breakpoint to which\\ninformation is attached.\\n\\nMost specifications of trace models are informal, when they exist at all. However, an informal\\nspecification is prone to misinterpretation by both developers and users. Indeed, in order to denote\\nthe events of interest, one has first to be able to denote events, and this is not easy in an informal way.\\n\\nIn the following, we describe two ways that have been tried to provide a formal specification of\\ntrace model, firstly an existing operational semantics has been instrumented and secondly an abstract\\noperational semantics has been specified. We then give some details of the second experiment.\\n\\nFifth Int. Workshop on Automated and Algorithmic Debugging\\n\\n\\n\\n174 M. DUCASSÉ ET AL.\\n\\nx y z x y z x y z x y zx y z x y z\\n\\n1\\n\\n3\\n2\\n\\nred\\nx red\\n\\ny\\nred\\n\\ny\\ny > z red\\n\\nz\\ny > z red\\n\\nx\\nx > yx > yx > y\\n\\nFigure 1: Application of reductions to the system {x > y; y > z}.\\n\\n2.1 Instrumenting an existing operational semantics\\n\\nSome programming languages have precise operational semantics which rigorously specify the com-\\nputation steps. Hence the computation events are clearly denoted. In such a case, it is relatively easy\\nto formally specify a trace model as shown by Jahier et al. with the Prolog tracer retro-specifica-\\ntion [JDR01]. There were already numerous operational semantics available for Prolog. The contin-\\nuation passing semantics of Nicholson and Foo [NF89] was used. Then instrumentations inside the\\noperational semantics were specified. Only 2 rules of one line each had to be instrumented in order\\nto get the “standard” trace of Prolog. The instrumentation itself is slightly tricky but it can be under-\\nstood without ambiguity when examining a formal specification of 10 lines. The detailed description\\nof this experiment is out of the scope of this article. Indeed, the explanations of operational semantics\\nrequires a couple of pages, understanding them requires a good knowledge of Prolog and this article\\nis not aiming at Prolog specialists.\\n\\n2.2 Specifying an abstract operational semantics\\n\\nAn operational semantics is not always available, for example we are not aware of any for the C lan-\\nguage. In such a case, starting the design of the tracer by designing a complete operational semantics\\nis certainly an overkill. An operational semantics specifies in detail the execution of a program. From\\nan operational semantics one can derive an implementation of a compiler. In order to design a tracer,\\nless information is usually needed than to implement a compiler. In that case, an abstract operational\\nsemantics is sufficient. The information given in an abstract operational semantics is correct but not\\ncomplete. It tells tracer developers what information should be provided to users and it tells users\\nhow to interpret this trace information. In the case of CLP(FD) there was no operational semantics\\nthat we could use to specify a tracer and we designed an abstract operational semantics as a set of\\nstate transition rules. .\\n\\n2.3 Informal presentation of domain reduction\\n\\nBefore we give examples of a formal specification of events we have to informally explain how vari-\\nable domains are reduced. This is an essential mechanism of constraint propagation in the case of\\nfinite domains. A CLP(FD) program searches a solution for a set of variables which take values\\nover finite domains and which must verify a set of constraints. The evolution of the domains can\\nbe viewed as a sequence of applications of reduction operators attached to the constraints. Each op-\\nerator can be applied several times until the computation reaches a fix-point [FLT00]. This fix-point\\nis the set of final domain states. An example of computation with reduction operators is shown in\\nFigure 1. There are three variables x, y and z and two constraints, x > y and y > z. A set of possi-\\nble values is associated to each variable. This set is called the domain of the variable. The domain\\nreduction consists in elementary steps that remove inconsistent values from those domains. At the\\nbeginning, the domain of x, Dx, the domain of y, Dy , and the domain of z, Dz , are all equal to {1, 2, 3}.\\nThis is represented by three columns of white squares. Considering the first constraint, it appears that\\nx cannot take the value “1”, because otherwise there would be no value for y such that x > y; ', 'name': '0310042v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0310/0310042v1.pdf'}, {'@search.score': 0.012500000186264515, '@search.rerankerScore': 2.588388442993164, '@search.captions': [{'text': 'The CLP, ACLP and SLDNFAC systems are based on the same finite domain constraint solver, so their convergence is not unex- pected. Indeed, the abductive system generates a constraint problem which is equivalent to the problem generated by the CLP program and no backtracking occurs in the abductive system. Hence, its overhead becomes ignorable.', 'highlights': 'The<em> CLP,</em> ACLP and SLDNFAC systems are based on the same finite domain constraint solver, so their convergence is not unex- pected. Indeed, the abductive system generates a constraint problem which is equivalent to the problem generated by the<em> CLP</em> program and no backtracking occurs in the abductive system. Hence, its overhead becomes ignorable.'}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMDExLzAwMTEwMzB2MS5wZGY1_4', 'title': 'arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000_chunk_4', 'chunk': 'This is confirmed by the much better performance of the\\nsystem in computing all solutions.\\n\\nFigure 3 gives the running times for finding all solutions. The y-axis is plot-\\nted on a logarithmic scale. The CLP, ACLP and SLDNFAC systems are based\\non the same finite domain constraint solver, so their convergence is not unex-\\npected. Indeed, the abductive system generates a constraint problem which is\\nequivalent to the problem generated by the CLP program and no backtracking\\noccurs in the abductive system. Hence, its overhead becomes ignorable. Also\\nthe SEM system converges to the same performance as CLP (but runs out of\\nmemory for big problems). In this experiment, the smodels system performs\\nmuch better but is still the slowest system. A likely reason for this is that the\\nnumber of propositional variables in the n-queens problem grows quadratically\\nwith the problem size, in contrast with the graph coloring problem where the\\nnumber of variables grows only linearly (because of a constant number of colors).\\nConsequently, the grounding grows faster for this problem. The CLP consistency\\ntechniques seem to be much less sensitive to the domain size, and this carries\\nover to the abductive systems which reduce the problem to a CLP problem and\\nthen use the CLP solver to search for the solution.\\n\\n3.4 A Real World Problem\\n\\nA Belgian electricity company has a number of power plants divided in geo-\\ngraphic areas. Each power plant has a number of power generating units, each of\\nwhich must receive a given number (usually 1 or 2) of preventive maintenances\\nwith a fixed duration in the course of one year. The computational problem is to\\nschedule these maintenances according to some constraints and optimality crite-\\nria. Some of the constraints are: some time slots are prohibited for maintenance\\nfor some units; for each power plant, there is an upper limit on the total number\\nof units in maintenance per week for reasons of availability of personnel; some\\nof the maintenances are fixed in advance, . . . The objective of the problem is to\\nfind a schedule that maximizes the minimal weekly reserve, which is the sum\\nof the capacity of all units not in maintenance minus the expected weekly peak\\nload.\\n\\nThis is a rather difficult problem in several aspects. Firstly, the specification\\nuses aggregate expressions like cardinality and sum (e.g. for each area, there is\\nan upper limit to the total capacity for units in maintenance per week). Only\\nCLP, smodels and SLDNFAC support some form of aggregates and only these\\nsystems were used in our experiment. Also, the search space is very large, as\\nthere are 56 maintenances to be scheduled in 52 weeks which makes about 5652\\n\\ncombinations3. The company provided a set of constraints for which the optimal\\nsolution was known to have a minimal week reserve of 2100 (100%). The three\\nsystems found correct schedules but none was able to find this optimal solution.\\n\\n3 The maintenances with duration of more than one week cannot be scheduled in week\\n52, hence this number is only an upper approximation.\\n\\n\\n\\nThis application was first considered in a context of a master’s thesis [18] and\\nthen reported in [4], where a first attempt was done for integrating the SLDNFA\\nproof procedure with the CLP system ROPE [23, 22]. This early system needed\\n24 hours to reduce the problem to a constraint store. Later on, in [22] several\\ndifferent direct encodings in CLP of the problem were presented and compared.\\nRecently, [21] discussed an extension of the SLDNFAC system with aggregate\\nfunctions and this problem was used as a benchmark.\\n\\nThe first version of the smodels system did not support aggregate expres-\\nsions. A more recent version of the system added a limited support for rules\\nwith a body consisting of a single cardinality or sum constraint [16] and allowed\\nus to specify the problem. However, these aggregate constraints cannot be used\\nfor computing the sum or the cardinality of a set of atoms and we were not\\nable to express the optimization function. By setting increasing lower bounds on\\nthe reserve capacity, branch and bound can be simulated manually. It should be\\nnoted that, because of the very large size of the problem, the specification of the\\nproblem in the smodels system had to be redesigned with special care in order\\nto produce a ground program not exceeding the limits of the system.\\n\\nTable 1 summarizes the results of executing the problem with the different\\nsystems. The first row “Setup” gives the time used for pre-processing the problem\\nspecification. For the abductive systems, this is the time for reducing the high-\\nlevel specification to a set of constraints. For the smodels system this is the\\ntime for grounding the program. The rest of the rows give the times used by the\\nconstraint solver to find a solution with the given quality. The results for CLP\\nare taken from [22] for a standard encoding of the problem4 and the program\\nwas run under SICStus Prolog.\\n\\nReserve CLP SLDNFACsmodels\\n\\nSetup 45 36.4\\n\\n', 'name': '0011030v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0011/0011030v1.pdf'}, {'@search.score': 0.012987012974917889, '@search.rerankerScore': 2.506816864013672, '@search.captions': [{'text': 'We say that a CLP(C) program P is terminating if every derivation start- ing from any ground state via any selection rule is finite, under the operational semantics defined above. To characterize this notion of termination, we use the notion of level mapping. A level mapping for a constraint domain C is a function | · | : BC  P → R.', 'highlights': 'We say that a<em> CLP(C)</em> program P is terminating if every derivation start- ing from any ground state via any selection rule is finite, under the operational semantics defined above. To characterize this notion of termination, we use the notion of level mapping. A level mapping for a constraint domain C is a function | · | : BC  P → R.'}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNzAxLzA3MDEwODJ2MS5wZGY1_1', 'title': 'None_chunk_1', 'chunk': 'Note that ground instances do\\nnot contain any constraint.\\n\\nWe now discuss the operational semantics of CLP-programs we consider in this paper.\\nA state of computation is a pair 〈A1, . . . ,An‖c〉. We further assume that one of the atoms in\\nA1, . . . ,An, say Ai, is selected for resolution by a selection rule. The operational semantics\\ncan be expressed by means of the following rewriting rules:\\n\\n\\n\\nRecurrence with affine level mappings is P-time decidable for CLP(R) 3\\n\\n• 〈A1, . . . ,An‖c〉 rewrites to 〈�‖false〉 if there exists a fresh rule A′i← c′,B1, . . . ,Bm in\\nP such that c∧ (Ai = A′i)∧ c′ is unsatisfiable;\\n• 〈A1, . . . ,An‖c〉 rewrites to 〈A1, . . . ,Ai−1,B1, . . . ,Bm,Ai+1, . . . ,An||c∧Ai = A′i ∧ c′〉 if\\n\\nthere exists a fresh rule A′i← c′,B1, . . . ,Bm in P such that c∧ (Ai = A′i)∧c′ is satisfi-\\nable.\\n\\nA derivation from a state S0 is a finite or infinite sequence of states S0,S1, . . . ,Sn, . . . such\\nthat each Si can be rewritten as Si+1. A ground state is a state 〈A1, . . . ,An‖true〉 where each\\nAi belongs to BC\\n\\nP . We say that a CLP(C) program P is terminating if every derivation start-\\ning from any ground state via any selection rule is finite, under the operational semantics\\ndefined above.\\n\\nTo characterize this notion of termination, we use the notion of level mapping. A level\\nmapping for a constraint domain C is a function | · | : BC\\n\\nP → R. We adapt the idea of recur-\\nrence, originally introduced in (Bezem 1993), to CLP:\\n\\nDefinition 1\\nLet P be a flat CLP(C) program, and | · | : C-base→ R be a level mapping. P is called\\nrecurrent with respect to | · | if there exists a real number ε > 0 such that, for every A←\\nB1, . . . ,Bn ∈ groundC(P), |A| ∈ R+, and |Bi| ∈ R+, |A| ≥ |Bi|+ ε for all i, 1 ≤ i ≤ n. We\\nsay that P is recurrent if there exists a level-mapping such that P is recurrent with respect\\nto it.\\n\\nObserve that rules of the form p(x̃)← c are not taken into account by the definition\\nabove. Moreover, without loss of generality, we may fix ε to 1: if P is recurrent in this\\nnarrow sense, P is trivially recurrent with respect to Definition 1. Conversely, since ε > 0,\\nwe can safely multiply the values of the level mapping by 1/ε.\\n\\nTheorem 1\\n(Bezem 1993) P is recurrent if and only if P is terminating.\\n\\n3 Alm-recurrent programs\\n\\nLet us consider programs that can be analyzed by means of affine level mappings.\\n\\nDefinition 2\\nA level mapping | · | is called affine if for any n-ary predicate symbol p ∈ ΠP, there exist\\nreal numbers µp,i, 0≤ i≤ n, such that for any atom p(e1, . . . ,en) ∈ BC\\n\\nP :\\n\\n|p(e1, . . . ,en)|= µp,0 +\\nn\\n\\n∑\\ni=1\\n\\nµp,iei\\n\\nSo for a given atom p(ẽ), its affine level mapping is a linear combination of ẽ shifted by\\na constant. We can define the class of programs we are interested in:\\n\\nDefinition 3\\nLet P be a flat CLP(C) program. We say that P is alm-recurrent if there exists an affine\\nlevel mapping | · | such that P is recurrent with respect to it.\\n\\n\\n\\n4 Fred Mesnard and Alexander Serebrenik\\n\\nExample 2\\nThe CLP(Q) program P from Example 1 is alm-recurrent with respect to |p(x)|= 73− x.\\n\\nClearly, if P is alm-recurrent, then P is recurrent thus terminating. Let us show that alm-\\nrecurrence can be efficiently decided. We start with proving this result for binary programs.\\n\\nTheorem 2\\nAlm-recurrence of a binary constraint logic program P over Q,Q+,R and R+ is decidable\\nin polynomial time with respect to the size of P.\\n\\nProof\\nThe proof is constructive: we provide a decision procedure for alm-recurrence of binary\\nconstraint logic programs over Q,Q+,R and R+. The decision procedure extends the al-\\ngorithm proposed in (Sohn and Van Gelder 1991) for termination of Prolog programs (ab-\\nstracted as CLP(N) programs) to binary CLP(C) where C is Q,Q+,R or R+. The algo-\\nrithm tries to find an affine level mapping showing that P is alm-recurrent by examining\\neach user-defined predicate symbol p of a binary CLP program P in turn (the precise order\\ndoes not matter). For every rule r, say p(x̃p)← c,q(x̃q), we test the satisfiability of c. For\\nthe domains we consider, it can be done in polynomial time (Khachiyan 1979). If c is not\\nsatisfiable, we disregard this rule. Otherwise, let np and nq be the arities of p and q. For the\\nrule r, recurrence is equivalent to:\\n\\nC |= c→ [|p(x̃p)| ≥ 1 + |q(x̃q)| ∧ |q(x̃q)| ≥ 0] (1)\\n\\nNote that the condition c→ |p(x̃p)| ≥ 0 can be omitted as it is implied by (1). Formula (1)\\nis logically equivalent to C |= c→ |p(x̃p)| ≥ 1+ |q(x̃q)| and C |= c→ |q(x̃q)| ≥ 0. Let x̃p be\\n(xp,1, . . . ,xp,np), x̃q be (xq,1, . . . ,xq,nq) and let µp,0, . . . ,µp,np ,µq,0, . . . ,µq,nq ∈R be such that\\nfor any atom p(e1, . . . ,enp)∈ BC\\n\\nP and any atom q(e1, . . . ,enq)∈BC\\nP : |p(e1, . . . ,enp)|= µp,0 +\\n\\n∑np\\ni=1 µp,iei and |q(e1, . . . ,enq)| = µq,0 + ∑\\n\\nnq\\ni=1 µq,iei. Hence, c should imply (µp,0− µq,0)+\\n\\n∑np\\ni=1 µp,ixp,i + ∑\\n\\nnq\\ni=1(−µq,i)xq,i ≥ 1 and µq,0 + ∑\\n\\nnq\\ni=1 µq,ixq,i ≥ 0. For the sake of uniformity,\\n\\nwe rewrite the second inequality as µq,0 + ∑np\\ni=1 0xp,i + ∑\\n\\nnq\\ni=1 µq,ixq,i ≥ 0. ', 'name': '0701082v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0701/0701082v1.pdf'}, {'@search.score': 0.02416052483022213, '@search.rerankerScore': 2.5052847862243652, '@search.captions': [{'text': 'Not surprisingly, CLP is the fastest system. smod- els is second best on this problem. We assume it is in part because of the very concise formulation.', 'highlights': 'Not surprisingly,<em> CLP</em> is the fastest system. smod-<em> els</em> is second best on this problem. We assume it is in part because of the very concise formulation.'}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wMDAzLzAwMDMwMjZ2MS5wZGY1_6', 'title': 'arXiv:cs/0003026v1  [cs.LO]  8 Mar 2000_chunk_6', 'chunk': 'available from address http://web.cs.ualberta.ca/\\n~joe/Coloring/Generators/generate.html. We did\\nour experiments with planar undirected graphs which\\nare known to be 4-colorable. The graphs were generated\\nusing a 20% probability of assigning arcs. This results\\nin dense graphs with a stable behavior. For this prob-\\nlem, the domain of the solution variables (the number\\nof colors) remained the same and we have modified only\\nthe parameter of the problem (the number of vertices)\\nand consequently the number of constraints (arcs). Fig-\\nure 8 gives the results of solving the problem with the\\ndifferent systems. Both axes are plotted in a logarith-\\nmic scale. On the x-axis we have put the number of\\narcs (constraints) instead of the number of vertices.\\n\\nNot surprisingly, CLP is the fastest system. smod-\\nels is second best on this problem. We assume it is in\\npart because of the very concise formulation. Using the\\nso called technique of rules with exceptions (Niemelä\\n1999), the two rules needed to describe the space of\\ncandidate solutions also encode the constraint that the\\ncolor is a function of the vertex. Hence there is only\\none other rule, namely the constraint that two adja-\\ncent vertices must have a different color. The differ-\\nence with CLP is almost two orders of magnitude for\\nthe largest problems. SLDNFAC is slightly worse than\\nsmodels. Although meta-interpretation overhead tends\\nto increase with problems size, the difference with smod-\\nels grows very slowly. The model generator SEM de-\\nteriorates much faster and runs out of memory for the\\n\\nlarger problems. The fact that it grounds the whole the-\\nory is a likely explanation. The difference with smod-\\nels supports the claim that smodels has better tech-\\nniques for grounding. ACLP performs substantially\\nworse than SLDNFA and also deteriorates faster.\\n\\nConclusion\\n\\nThe examples which we have considered in this paper\\nare by no ways representative. However we think that\\nthey still show some interesting features and limitations\\nof the considered systems.\\n\\nConsistency algorithms are a very efficient way for\\nsolving CSP. Constraint logic programming allows this\\ntechniques to be integrated in a natural and clear way\\nto logic programs. However, as argued parameterized\\nCSPs can not be represented in a declarative way as\\nCLP(FD) programs. Using abduction or stable mod-\\nels as the basis for logic programming allows the prob-\\nlems to be represented in a more declarative way and\\nthe recent integration of abduction with CLP allows\\nthe same consistency techniques to be used for solving\\nthe problems. At the moment, such systems are imple-\\nmented as meta-interpreters on top of Prolog and they\\nessentially reduce a problem to the same set of con-\\nstraints (in many cases without backtracking) which\\nwould be produced by the corresponding constraint\\nlogic program. Our experiments suggest that the over-\\nhead of an abductive system is small and acceptable.\\nMoreover they can also solve other classes of problems\\nwhich require non-monotonic reasoning like planning\\nproblems. We also showed that there is a very close\\n\\n\\n\\nrelation between the semantics and the problem rep-\\nresentation of abduction and logic programming with\\nstable model semantics. The only difference is in the\\nreasoning techniques - abduction is usually done by\\na top-down proof procedure, while a stable model is\\nusually computed by a bottom-up procedure. How-\\never, the techniques used to compute a stable model\\nof a program do not seem to be so well suited for\\nsolving CSPs. One reason could be that they work\\non a ground propositional programs which tend to be\\nlarge and grow fast as the parameter of the problem in-\\ncreases. This suggests that an interesting area for fur-\\nther research would be a framework for computing sta-\\nble models of constraint logic programs with the help of\\nconstraint solving techniques. Some work has already\\nbeen done in this direction (Dix & Stolzenburg 1998;\\nEiter, Lu, & Subrahmanian 1997).\\n\\nWe argued earlier in the paper that the most nat-\\nural way for representing CSPs is with functions with\\nopen interpretation. Hence it would be interesting to\\nconsider extensions of the CLP scheme which directly\\nsupport such form of reasoning. Some work in this\\narea is done in (Bruynooghe, Pelov, & Denecker 1999;\\nHickey 1993).\\n\\nAcknowledgments.\\n\\nWe want to thank the members of the DTAI group\\nat K.U.Leuven and anonymous referees for their use-\\nful comments. This research is supported by the GOA\\nproject LP+. The third author is supported by FWO-\\nVlaanderen.\\n\\nReferences\\n\\nBruynooghe, M.; Pelov, N.; and Denecker, M. 1999.\\nTowards a more declarative language for solving fi-\\nnite domain problems. In Apt, K.; Kakas, A.; Mon-\\nfroy, E.; and Rossi, F., eds., Proceedings of the\\nERCIM/COMPULOG Workshop on Constraints. Pa-\\nphos, Cyprus: University of Cyprus.\\n\\nBruynooghe, M. 1991. Intelligent backtracking revis-\\nited. In Lassez, J.-L., and Plotkin, G., eds., Computa-\\ntional Logic - Essays in Honor of Alan Robinson. MIT\\nPress. ', 'name': '0003026v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0003/0003026v1.pdf'}, {'@search.score': 0.012345679104328156, '@search.rerankerScore': 2.3689491748809814, '@search.captions': [{'text': 'A CLP framework for computing structural  test data. In First International Conference on Computational Logic, pages 399– 413. Springer, 2000. 10. A. Gotlieb, T. Denmat, and B. Botella. Goal-oriented test data generation for programs with pointer variables. In Proceedings of the International Computer  .\\x00', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNTA4LzA1MDgxMDh2MS5wZGY1_5', 'title': 'None_chunk_5', 'chunk': 'The second guarded-constraint of the\\nw operator instantiated for the foo program is :\\n\\n¬Nk > 0 −→ [Rk, Nk, Sk] = [RET,N2, S2]\\n\\n\\n\\n13\\n\\nWhen k = MAX INT , the guard is entailed because of constraint 10.\\nConsequently, the constraint\\n\\nRET = RMAX INT (11)\\n\\nis set up. It makes the constraint store unsatisfiable, and this is detected\\nby the constraint solver. As a consequence, the third invariant is proved\\nto be true.\\n\\n6 Discussion\\n\\nThe previous section presented three examples of validation of likely in-\\nvariants by constraint solving. Two likely invariants were disproved by\\nthe exhibition of a counter-example. The last one was proved to be an\\ninvariant.\\n\\nA point that we have not developed yet is the case where the resolution\\ndoes not terminate or is too long. There are two main reasons why these\\ncases can happen. The first reason is due to the loops. Indeed, as the model\\nwe use describes the operational semantics of a program, if the original\\nprogram does not terminate, then the resolution will not terminate.\\n\\nThe second reason is a problem of propagation in the constraint sys-\\ntem. As presented in section 4, the operators ite and w are defined via\\nguarded-constraints. Consequently, if the entailment of none of the guards\\ncan be deduced from the current store of constraints, then the resolution\\nof the constraint system suspends. The problem is that our system is very\\nspecific and usual methods of entailment-checking are inefficient in this\\ncontext : domains of variables are very large, constraint store is dynamic\\nand constraints used can be non-linear.\\n\\nThe consequence of this lack of propagation is that, in bad cases,\\nalmost all the possible values of input variables will have to be enumer-\\nated to prove or disprove likely invariants. In such a case, our approach\\nbecomes a generate-and-test method, which is intractable when the do-\\nmains of input variables are large. Future work will consist in improving\\nthe propagation inside our specific constraint system.\\n\\n7 Conclusion\\n\\nIn this paper, we have presented an approach to verify the correctness of\\nlikely invariants using constraint solving. We have illustrated its principles\\non a toy example.\\n\\n\\n\\n14\\n\\nThe originality of this method is that some likely invariants are dis-\\nproved and others are proved. This differs from other methods that\\nare dedicated to only one of these capabilities. Methods using under-\\napproximations can only disprove likely invariants whereas methods us-\\ning over-approximation can only prove likely invariants. We are not using\\nany approximation, it allows us to prove and disprove but prevents us\\nto guarantee termination and good performances. Consequently, the key\\npoint of our approach is to have a good propagation inside the constraint\\nsystem in order to reduce as much as possible the number of cases where\\nwe cannot conclude.\\n\\nAcknowledgments We thank the anonymous referees for their helpful com-\\nments.\\n\\nReferences\\n\\n1. B. Botella, A. Gotlieb, and C. Michel. Symbolic execution of floating-point com-\\nputations. Software Testing, Verification and Reliability Journal, 2005.\\n\\n2. L. Burdy, Y. Cheon, D. R. Cok, M. D. Ernst, J. R. Kiniry, G. T. Leavens, K. R.\\nLeino, and E. Poll. An overview of JML tools and applications. International\\n\\nJournal on Software Tools for Technology Transfer, 7(3):212–232, 2005.\\n3. P. Cousot and R. Cousot. Abstract interpretation : A unified lattice model for static\\n\\nanalysis of programs by construction or approximation of fixpoints. In Proceedings\\n\\nof Symposium on Principles of Programming Languages, pages 238–252. ACM,\\n1977.\\n\\n4. P. Cousot and N. Halbwachs. Automatic discovery of linear restraints among\\nvariables of a program. In Proceedings of Symposium on Principles of Programming\\n\\nLanguages, pages 84–96. ACM, 1978.\\n5. R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. Efficiently\\n\\ncomputing static single assignment form and the control dependence graph. ACM\\n\\nTransactions on Programming Languages and Systems, 13(4):451–490, 1991.\\n6. M. D. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin. Dynamically discovering\\n\\nlikely program invariants to support program evolution. IEEE Transactions on\\n\\nSoftware Engineering, 27(2):99–123, 2001.\\n7. M. D. Ernst, A. Czeisler, W. G. Griswold, and D. Notkin. Quickly detecting\\n\\nrelevant program invariants. In Proceedings of the International Conference on\\n\\nSoftware Engineering, pages 449–458. IEEE, 2000.\\n8. A. Gotlieb, B. Botella, and M. Rueher. Automatic test data generation using\\n\\nconstraint solving techniques. In Proceedings of the International Symposium on\\n\\nSoftware Testing and Analysis, pages 53–62. ACM, 1998.\\n9. A. Gotlieb, B. Botella, and M. Rueher. A CLP framework for computing structural\\n\\ntest data. In First International Conference on Computational Logic, pages 399–\\n413. Springer, 2000.\\n\\n10. A. Gotlieb, T. Denmat, and B. Botella. Goal-oriented test data generation for\\nprograms with pointer variables. In Proceedings of the International Computer\\n\\n', 'name': '0508108v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0508/0508108v1.pdf'}, {'@search.score': 0.026810109615325928, '@search.rerankerScore': 2.3463542461395264, '@search.captions': [{'text': 'Sistemas Informáticos y Programación  Av. Complutense s/n, Universidad Complutense de Madrid,  E-28040 Madrid, Spain  (e-mail: {leach,nieva,mario}@sip.ucm.es)  Abstract  Constraint Logic Programming (CLP) and Hereditary Harrop Formulas (HH )are two well  known ways to enhance the expressivity of Horn clauses.', 'highlights': ''}], 'id': 'aHR0cHM6Ly9kYXRhc2V0c2dwdHNtYXJ0c2VhcmNoLmJsb2IuY29yZS53aW5kb3dzLm5ldC9hcnhpdmNzL3BkZi8wNDA0LzA0MDQwNTN2MS5wZGY1_0', 'title': 'None_chunk_0', 'chunk': '\\nar\\nX\\n\\niv\\n:c\\n\\ns/\\n04\\n\\n04\\n05\\n\\n3v\\n1 \\n\\n [\\ncs\\n\\n.P\\nL\\n\\n] \\n 2\\n\\n6 \\nA\\n\\npr\\n 2\\n\\n00\\n4\\n\\nUnder consideration for publication in Theory and Practice of Logic Programming 1\\n\\nConstraint Logic Programming with\\n\\nHereditary Harrop Formulas\\n\\nJavier Leach, Susana Nieva, Mario Rodŕıguez-Artalejo ∗\\n\\nDpto. Sistemas Informáticos y Programación\\n\\nAv. Complutense s/n, Universidad Complutense de Madrid,\\n\\nE-28040 Madrid, Spain\\n\\n(e-mail: {leach,nieva,mario}@sip.ucm.es)\\n\\nAbstract\\n\\nConstraint Logic Programming (CLP) and Hereditary Harrop Formulas (HH )are two well\\n\\nknown ways to enhance the expressivity of Horn clauses. In this paper, we present a novel\\n\\ncombination of these two approaches. We show how to enrich the syntax and proof theory\\n\\nof HH with the help of a given constraint system, in such a way that the key property of HH\\n\\nas a logic programming language (namely, the existence of uniform proofs) is preserved.\\n\\nWe also present a procedure for goal solving, showing its soundness and completeness for\\n\\ncomputing answer constraints. As a consequence of this result, we obtain a new strong\\n\\ncompleteness theorem for CLP that avoids the need to build disjunctions of computed\\n\\nanswers, as well as a more abstract formulation of a known completeness theorem for HH.\\n\\nkeywords: constraint systems, hereditary Harrop formulas, uniform proofs, goal solving.\\n\\n1 Introduction\\n\\nTraditionally, the logic of Horn clauses has been considered as the basis for logic\\n\\nprogramming (Van Emden and Kowalski, 1976). In spite of its Turing completeness\\n\\n(Andréka and Németi, 1978), the lack of expressivity of Horn clauses for program-\\n\\nming purposes is widely acknowledged. During the last decade, different extensions\\n\\nof Horn clauses have been proposed, with the aim of increasing expressivity with-\\n\\nout sacrificing the declarative character of pure logic programming. Among such\\n\\nextensions, two important approaches are Constraint Logic Programming (CLP)\\n\\nand Hereditary Harrop Formulas (HH ).\\n\\n∗ This is a substantially revised and extended version of\\n\\n(Leach, Nieva and Rodŕıguez-Artalejo, 1997). The authors have been partially supported\\n\\nby the Spanish National Project TIC 98-0445-C03-02 TREND and the Esprit BRA Working\\n\\nGroup EP-22457 CCLII.\\n\\nhttp://arXiv.org/abs/cs/0404053v1\\n\\n\\n2 J.Leach, S.Nieva, M.Rodŕıguez-Artalejo\\n\\nThe CLP scheme (Jaffar and Lassez, 1987) goes beyond the limitations of the\\n\\nHerbrand universe by providing the ability to program with Horn clauses over\\n\\ndifferent computation domains, whose logical behaviour is given by constraint sys-\\n\\ntems. CLP languages keep all the good semantic properties of pure logic program-\\n\\nming, including soundness and completeness results (Jaffar et al., 1996). Their im-\\n\\nplementation relies on the combination of SLD resolution with dedicated algorithms\\n\\nfor constraint entailment, solving and simplification. Therefore, efficient and yet\\n\\ndeclarative programs can be written to solve complex combinatorial problems. See\\n\\n(Jaffar and Maher, 1994) for a survey of the foundations, implementation issues\\n\\nand applications of CLP languages.\\n\\nOn the other hand, the HH approach (Miller, Nadathur and Scedrov, 1987) over-\\n\\ncomes the inability of Horn clauses to provide a logical basis for several constructions\\n\\ncommonly found in modern programming languages, such as scoping, abstraction\\n\\nand modularity. This is achieved by extending Horn clauses to a richer fragment of\\n\\nintuitionistic logic that allows us to use disjunctions, implications and quantifiers in\\n\\ngoals. In fact, HH is a typical example of an abstract logic programming language, in\\n\\nthe sense of (Miller et al., 1991). Abstract logic programming languages are charac-\\n\\nterized by the fact that the declarative meaning of a program, given by provability\\n\\nin a deduction system, can be interpreted operationally as goal-oriented search for\\n\\nsolutions. Technically, the existence of uniform proofs for all provable goal formu-\\n\\nlas permits the search interpretation of provability. The implementation of pro-\\n\\ngramming languages based on HH, such as λ-Prolog (Miller and Nadathur, 1986;\\n\\nNadathur and Miller, 1988), requires the resolution of the problem of unifying terms\\n\\noccurring under the scope of arbitrary quantifier prefixes. Correct unification al-\\n\\ngorithms for such problems have been studied in (Miller, 1992; Nadathur, 1993).\\n\\nMoreover, (Nadathur, 1993) shows in detail the soundness and completeness of a\\n\\ngoal solving procedure for the first-order HH language.\\n\\nThe aim of this paper is to present a framework for the combination of the CLP\\n\\nand HH approaches, that incorporates the benefits of expressivity and efficiency\\n\\nthat HH and CLP bring to logic programming, respectively. We will enrich the\\n\\nsyntax of first-order HH with constraints coming from a given constraint system.\\n\\nThe resulting language is such that all constructions and results are valid for any\\n\\nconstraint system C, therefore we can speak of a scheme HH(X) with instances\\n\\nHH(C), as in CLP. ', 'name': '0404053v1.pdf', 'location': 'https://datasetsgptsmartsearch.blob.core.windows.net/arxivcs/pdf/0404/0404053v1.pdf'}]}\n",
            "{'@odata.context': \"https://gptkb-3hhfqf2n5qzbc.search.windows.net/indexes('cogsrch-index-csv-vector')/$metadata#docs(*)\", '@odata.count': 10, '@search.answers': [{'key': 'u2g30x1j_0', 'text': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)_chunk_0.', 'highlights': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant<em> SA11 rotavirus core-like particles</em> (CLP) or virus-like particles (VLP)_chunk_0.', 'score': 0.87939453125}], 'value': [{'@search.score': 0.031054403632879257, '@search.rerankerScore': 2.8763787746429443, '@search.captions': [{'text': 'Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody.', 'highlights': ''}], 'id': '5ed5k9tq_0', 'title': 'Quantification of recombinant core-like particles of bluetongue virus using immunosorbent electron microscopy._chunk_0', 'chunk': 'Immunosorbent electron microscopy was used to quantify recombinant baculovirus-generated bluetongue virus (BTV) core-like particles (CLP) in either purified preparations or lysates of recombinant baculovirus-infected cells. The capture antibody was an anti-BTV VP7 monoclonal antibody. The CLP concentration in purified preparations was determined to be 6.6 x 10(15) particles/l. CLP concentration in lysates of recombinant baculovirus-infected cells was determined at various times post-infection and shown to reach a value of 3 x 10(15) particles/l of culture medium at 96 h post-infection. The results indicated that immunosorbent electron microscopy, aided by an improved particle counting method, is a simple, rapid and accurate technique for the quantification of virus and virus-like particles produced in large scale in vitro systems.', 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pubmed/10403670/'}, {'@search.score': 0.030886195600032806, '@search.rerankerScore': 2.548943042755127, '@search.captions': [{'text': 'The chemokine monocyte chemoattractant protein 1/CC chemokine ligand 2 (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases.', 'highlights': 'The<em> chemokine monocyte chemoattractant protein 1/CC</em><em> chemokine ligand 2</em> (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases.'}], 'id': 'm3ibpnfw_0', 'title': 'Increased susceptibility to septic and endotoxic shock in monocyte chemoattractant protein 1/cc chemokine ligand 2-deficient mice correlates with reduced interleukin 10 and enhanced macrophage migration inhibitory factor production._chunk_0', 'chunk': 'The chemokine monocyte chemoattractant protein 1/CC chemokine ligand 2 (MCP-1/CCL2) is a potent chemoattractant of mononuclear cells and a regulatory mediator involved in a variety of inflammatory diseases. In the present study, we demonstrate that mcp-1/ccl2-deficient mice are more susceptible to systemic inflammatory response syndrome induced by lipopolysaccharide and to polymicrobial sepsis induced by cecum ligation and puncture (CLP) when compared with wild-type mice. Interestingly, in the CLP model, mcp-1/ccl2-deficient mice efficiently cleared the bacteria despite an impaired recruitment of leukocytes, especially mononuclear cells. The increased lethality rate in these models correlates with an impaired production of interleukin (IL) 10 in vivo. Furthermore, macrophages from mcp-1/ccl2-deficient mice activated with lipopolysaccharide also produced lower amounts of IL-10 and similar tumor necrosis factor compared with wild-type mice. We observed a drastic increase in the amounts of macrophage migration inhibitory factor at 6 and 24 h after CLP in mcp-1/ccl2-deficient mice. These results indicate that endogenous MCP-1/CCL2 positively regulates IL-10 but negatively controls macrophage migration inhibitory factor during peritoneal sepsis, thus suggesting an important immunomodulatory role for MCP-1/CCL2 in controlling the balance between proinflammatory and anti-inflammatory factors in sepsis.', 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pubmed/17047515/'}, {'@search.score': 0.03009049780666828, '@search.rerankerScore': 2.5137102603912354, '@search.captions': [{'text': 'We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional laparoscopic pyeloplasty (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria.', 'highlights': 'We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional<em> laparoscopic pyeloplasty</em> (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria.'}], 'id': '7xw8tlg3_0', 'title': 'Laparoendoscopic single site surgery versus conventional laparoscopy for transperitoneal pyeloplasty: A systematic review and meta-analysis._chunk_0', 'chunk': 'We aimed to review studies comparing the outcomes of the laparoendoscopic single site (LESS) pyeloplasty with those of conventional laparoscopic pyeloplasty (CLP). A systematic review of the literature was performed according to the PRISMA (preferred reporting items for systematic reviews and meta-analysis) criteria. The methodological quality of the studies was rated according validated scales. The level of evidence (LE) was reported as described by the Oxford criteria. Preoperative demographic parameters and perioperative outcomes between the two surgical techniques were assessed. A meta-analysis of the included studies was performed. A total of 5 studies were elected for the analysis, including 164 cases, 70 (42.6%) of them being LESS and 94 (57.4%) being CLP. Four studies were observational retrospective comparative studies (LE: 3a-4); one was a prospective randomized controlled trial (LE: 2b). There was no significant difference in age, body mass index, gender, side and presence of the crossing vessel, between the groups. There was no significant difference regarding the operative time (weight mean difference [WMD]: -7.02; 95% confidence interval [CI]: -71.82-57.79; P = 0.83) and length of hospital stay (WMD: 0.04; 95% CI: -0.11-0.20; P = 0.58), whereas the estimated blood loss was statistically lower for LESS (WMD: -16.83; 95% CI: -31.79--1.87; P = 0.03). The postoperative use of analgesic favored the LESS group but without reaching statistical significance (WMD: -7.52; 95% CI: -17.56-2.53; P = 0.14). In conclusion, LESS pyeloplasty offers comparable surgical and functional outcomes to CLP while providing the potential advantages of less blood loss and lower analgesic requirement. Thus, despite being more technically challenging, LESS pyeloplasty can be regarded as a minimally invasive approach for patients seeking fewer incisional scars.', 'name': 'metadata.csv', 'location': 'https://doi.org/10.4103/0974-7796.156145; https://www.ncbi.nlm.nih.gov/pubmed/26229312/'}, {'@search.score': 0.03125763311982155, '@search.rerankerScore': 2.4367339611053467, '@search.captions': [{'text': 'In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs.', 'highlights': ''}], 'id': 'vnmg0zid_0', 'title': 'Length of encapsidated cargo impacts stability and structure of in vitro assembled alphavirus core-like particles_chunk_0', 'chunk': 'In vitro assembly of alphavirus nucleocapsid cores, called core-like particles (CLPs), requires a polyanionic cargo. There are no sequence or structure requirements to encapsidate single-stranded nucleic acid cargo. In this work, we wanted to determine how the length of the cargo impacts the stability and structure of the assembled CLPs. We hypothesized that cargo neutralizes the basic region of the alphavirus capsid protein and if the cargo is long enough, it will also act to scaffold the CP monomers together. Experimentally we found that CLPs encapsidating short 27mer oligonucleotides were less stable than CLPs encapsidating 48mer or 90mer oligonucleotides under different chemical and thermal conditions. Furthermore, cryo-EM studies showed there were structural differences between CLPs assembled with 27mer and 48mer cargo. To mimic the role of the cargo in CLP assembly we made a mutant (4D) where we substituted a cluster of four Lys residues in the CP with four Asp residues. We found that these few amino acid substitutions were enough to initiate CLP assembly in the absence of cargo. The cargo-free 4D CLPs show higher resistance to ionic strength and increased temperature compared to wild-type cargo containing CLPs suggesting their CLP assembly mechanism might also be different.', 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7103146/'}, {'@search.score': 0.03306011110544205, '@search.rerankerScore': 2.4336702823638916, '@search.captions': [{'text': 'The Academy of Consultation-Liaison Psychiatry (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient consultation-liaison psychiatry (CLP) training and providing a framework for CLP educators who are interested in developing outpatient CLP rotations within their programs.', 'highlights': 'The Academy of<em> Consultation-Liaison Psychiatry</em> (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient<em> consultation-liaison psychiatry</em> (CLP) training and providing a framework for<em> CLP</em> educators who are interested in developing outpatient<em> CLP</em> rotations within their programs.'}], 'id': 'da6d32x7_0', 'title': 'The educational value of outpatient CL rotations- a white paper from the ACLP residency education subcommittee_chunk_0', 'chunk': 'Abstract Background and aims As mental health services in outpatient medical clinics expand, psychiatrists must be trained to practice in these settings. The Academy of Consultation-Liaison Psychiatry (ACLP) residency education subcommittee convened a writing group with the goal of summarizing the current evidence about outpatient consultation-liaison psychiatry (CLP) training and providing a framework for CLP educators who are interested in developing outpatient CLP rotations within their programs. Method MEDLINE (via PubMed), Embase and PsycINFO (via OVID), were reviewed each from inception to December 2019, for psychiatric CLP services in ambulatory settings that involved residents or fellows. The CLP education guidelines were reviewed for recommendations relevant to outpatient CLP. We also searched MedEd portal for published curriculums relevant to CLP. The group held 2 conferences to reach consensus about recommendations in setting up outpatient CLP rotations. Results Seventeen articles, three ACLP supported guidelines, and eight online didactic resources were identified as directly reporting on the organization and/or impact of an outpatient CLP rotation. These manuscripts indicated that residents found outpatient CLP rotations effective and relevant to their future careers. However, the literature provided few recommendations for establishing formal outpatient CLP training experiences. Discussion Outpatient CLP rotations offer multiple benefits for trainees, including exposure to specific clinical scenarios and therapeutic interventions applicable only in the outpatient setting, increased continuity of care and the unique experience of providing liaison and education to non-mental health providers. The article outlines recommendations and examples for developing outpatient CLP rotations which CLP educators can incorporate in their programs.', 'name': 'metadata.csv', 'location': 'https://api.elsevier.com/content/article/pii/S0033318220301420; https://www.sciencedirect.com/science/article/pii/S0033318220301420?v=s5'}, {'@search.score': 0.031054403632879257, '@search.rerankerScore': 2.3356311321258545, '@search.captions': [{'text': 'Chronic obstructive pulmonary disease (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling.', 'highlights': '<em>Chronic obstructive pulmonary disease</em> (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling.'}], 'id': 'i7ecw3xb_0', 'title': 'What is the contribution of respiratory viruses and lung proteases to airway remodelling in asthma and chronic obstructive pulmonary disease?_chunk_0', 'chunk': 'It is well known that the lungs of asthmatics show airway wall remodelling and that asthma exacerbations are linked to respiratory infections. There is some evidence that respiratory infections in early childhood may increase the risk of developing asthma later in life. Chronic obstructive pulmonary disease (COPD), by definition, involves structural changes to the airways. However, very little is known about what role virus infections play in the development of this remodelling. This review considers the role of matrix metalloproteases and neutrophil elastase in remodelling, and whether the induction of proteases and other mediators during respiratory virus infections may contribute to the development of airway remodelling.', 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pubmed/16286234/'}, {'@search.score': 0.0314980149269104, '@search.rerankerScore': 2.1104471683502197, '@search.captions': [{'text': 'Cold-inducible RNA-binding protein (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys.', 'highlights': 'Cold-inducible<em> RNA-binding protein</em> (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys.'}], 'id': 'ofsjs3nn_0', 'title': 'A cold-inducible RNA-binding protein (CIRP)-derived peptide attenuates inflammation and organ injury in septic mice_chunk_0', 'chunk': 'Cold-inducible RNA-binding protein (CIRP) is a novel sepsis inflammatory mediator and C23 is a putative CIRP competitive inhibitor. Therefore, we hypothesized that C23 can ameliorate sepsis-associated injury to the lungs and kidneys. First, we confirmed that C23 dose-dependently inhibited TNF-α release, IκBα degradation, and NF-κB nuclear translocation in macrophages stimulated with CIRP. Next, we observed that male C57BL/6 mice treated with C23 (8 mg/kg BW) at 2 h after cecal ligation and puncture (CLP) had lower serum levels of LDH, ALT, IL-6, TNF-α, and IL-1β (reduced by ≥39%) at 20 h after CLP compared with mice treated with vehicle. C23-treated mice also had improved lung histology, less TUNEL-positive cells, lower serum levels of creatinine (34%) and BUN (26%), and lower kidney expression of NGAL (50%) and KIM-1 (86%). C23-treated mice also had reduced lung and kidney levels of IL-6, TNF-α, and IL-1β. E-selectin and ICAM-1 mRNA was significantly lower in C23-treated mice. The 10-day survival after CLP of vehicle-treated mice was 55%, while that of C23-treated mice was 85%. In summary, C23 decreased systemic, lung, and kidney injury and inflammation, and improved the survival rate after CLP, suggesting that it may be developed as a new treatment for sepsis.', 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5809586/'}, {'@search.score': 0.03077651560306549, '@search.rerankerScore': 2.0615952014923096, '@search.captions': [{'text': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)_chunk_0.', 'highlights': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus<em> core-like particles</em> (CLP) or virus-like particles (VLP)_chunk_0.'}], 'id': 'u2g30x1j_0', 'title': 'Isotype-specific antibody responses to rotavirus and virus proteins in cows inoculated with subunit vaccines composed of recombinant SA11 rotavirus core-like particles (CLP) or virus-like particles (VLP)_chunk_0', 'chunk': 'The isotype antibody responses to bovine IND P(5), G6 and simian SA11 P(2), G3 rotavirus and SA11 rotavirus proteins (VP4, VP6 and VP7) in serum, colostrum and milk were analysed by ELISA in three groups of vaccinated cows and nonvaccinated controls. Pregnant cows were vaccinated intramuscularly and intramammarily with recombinant baculovirus-expressed SA11 rotavirus VLP (triple-layered virus-like particles containing rotavirus VP2, VP4, VP6 and VP7); CLP (double-layered core-like particles containing rotavirus VP2 and VP6); or inactivated SA11 rotavirus, respectively. Rotavirus antigen titers were highest (30–200-fold) in ELISA in the VLP vaccine compared to the inactivated SA11 vaccine. The IgG1, IgG2 and IgM geometric mean antibody titers (GMT) to rotavirus (titers to bovine rotavirus vs SA11 rotavirus did not differ significantly for any isotype or group) and the IgG2 GMT to VP6 in serum at calving in the vaccinated groups were significantly (P <0.05) higher than in the control group. In colostrum, IgG1 and IgA rotavirus antibody titers were significantly elevated for VLP (IgG1 GMT 832225; IgA GMT 16384), CLP (IgG1 GMT 660561; IgA GMT 10321) and SA11 (IgG1 GMT 131072; IgA GMT 1448) vaccinated cows compared to control cows (IgG1 GMT 11585; IgA GMT 45). The IgG1 and IgA GMT to rotavirus were significantly elevated (6–100-fold) in milk of VLP and CLP vaccinated cows compared to SA11 vaccinated or control cows. The isotype antibody responses to VP6 in serum, colostrum and milk paralleled the responses to rotavirus, but titers were ∼2–10-fold lower. Only cows vaccinated with VLP had significantly enhanced serum, colostral and milk antibody titers to rotavirus VP4 and VP7. These results demonstrate that rotavirus antibody titers in serum, colostrum and milk are significantly enhanced by use of non-infectious VLP, CLP and inactivated SA11 rotavirus vaccines, but the VLP or CLP vaccines induced the highest antibody responses, corresponding to their higher rotavirus antigen titers measured by ELISA.', 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7131174/'}, {'@search.score': 0.029857397079467773, '@search.rerankerScore': 1.8161381483078003, '@search.captions': [{'text': 'The direct costs associated with RSV hospitalization were on average CLP $ 413,529 (US$ 632.1) for Group 1, and CLP $ 744,260 (US$ 1,137.6) for Group 2 (p < 0.05). There was also statistically significant higher cost for Group 2 due to tests and drugs (p < 0.05) and costs per day of hospital stay (p < 0.05).', 'highlights': ''}], 'id': 'eyvywyob_0', 'title': 'Direct costs of low respiratory infection due to RSV in children under one year._chunk_0', 'chunk': 'INTRODUCTION Considering the high prevalence of respiratory infections in hospitalized infants with Respiratory Syncytial Virus (RSV), the objective of this study is to determine the direct costs of this infection. PATIENTS AND METHOD Prospective longitudinal study in infants under one year of age hospitalized due to RSV during 2015. The patients were divided into 2 groups, Group 1 pa tients without risk factors and Group 2 patients with risk factors (prematurity, oxygen dependence, bronchopulmonary dysplasia, heart disease, immunocompromised patients), comparing each other variables such as nutritional status, gender, breastfeeding, discharge diagnosis, radiological diagno sis, length of hospital stay, among others. Direct costs for hospitalization were estimated according to the fees of the National Health Fund (FONASA) and the Modality of Institutional Care (MAI). RESULTS The total patients admitted in the period were 260: 234 (90%) in Group 1 and 26 (10%) in Group 2. The average hospital stay for Group 1 was 7.3 days (SD+5.1) with a median of 6 days, and 13.6 days (SD+16.3) for Group 2 with a median of 7 days (p < 0.05). The direct costs associated with RSV hospitalization were on average CLP $ 413,529 (US$ 632.1) for Group 1, and CLP $ 744,260 (US$ 1,137.6) for Group 2 (p < 0.05). There was also statistically significant higher cost for Group 2 due to tests and drugs (p < 0.05) and costs per day of hospital stay (p < 0.05). CONCLUSION These values, known for the first time in the national reality, confirm the high cost of these infections and particularly in risk groups.', 'name': 'metadata.csv', 'location': 'https://doi.org/10.4067/s0370-41062018005000401; https://www.ncbi.nlm.nih.gov/pubmed/30571819/'}, {'@search.score': 0.031159421429038048, '@search.rerankerScore': 1.6583563089370728, '@search.captions': [{'text': 'The mainstay of community-acquired pneumonia prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease..\\x00', 'highlights': 'The mainstay of<em> community-acquired pneumonia</em> prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease..\\x00'}], 'id': 'rd3bed48_0', 'title': 'Community-acquired pneumonia: what is relevant and what is not?_chunk_0', 'chunk': 'PURPOSE OF REVIEW Community-acquired pneumonia is associated with significant morbidity and mortality and is the most common cause of death from infectious diseases in North America. The purpose of this review is to highlight recent advances in epidemiology, risk factors, severity criteria and antibiotic therapeutic regimens used for community-acquired pneumonia management. RECENT FINDINGS All guidelines recommend early and appropriate empiric therapy directed against common typical organisms, such as Streptococcus pneumoniae, and other atypical organisms, but clinicians should be aware of newer emerging pathogens such as community-acquired methicillin-resistant Staphylococcus aureus and Gram-negative pathogens. SUMMARY The optimum outcome in community-acquired pneumonia can be achieved by careful risk stratification using prediction rules together with appropriate antibiotic regimens. The mainstay of community-acquired pneumonia prevention is influenza and pneumococcal immunization. Promotion of smoking cessation will also help curtail the incidence of pneumococcal disease.', 'name': 'metadata.csv', 'location': 'https://www.ncbi.nlm.nih.gov/pubmed/17414124/'}]}\n",
            "Number of results: 3\n"
          ]
        }
      ],
      "source": [
        "vector_indexes = [index+\"-vector\" for index in indexes]\n",
        "\n",
        "k = 10\n",
        "similarity_k = 3\n",
        "ordered_results = get_search_results(QUESTION, vector_indexes,\n",
        "                                        k=k, # Number of results per vector index\n",
        "                                        reranker_threshold=1,\n",
        "                                        vector_search=True, \n",
        "                                        similarity_k=similarity_k,\n",
        "                                        query_vector = embedder.embed_query(QUESTION)\n",
        "                                        )\n",
        "print(\"Number of results:\",len(ordered_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a98a974-0633-499f-a8f0-29bf6242e737",
      "metadata": {},
      "source": [
        "For vector search is not recommended to give more than k=5 chunks (of max 5000 characters each) to the LLM as context. Otherwise you can have issues later with the token limit trying to have a conversation with memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7dfb9e39-2542-469d-8f64-4c0c26d79535",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of chunks: 3\n"
          ]
        }
      ],
      "source": [
        "top_docs = []\n",
        "for key,value in ordered_results.items():\n",
        "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
        "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location}))\n",
        "        \n",
        "print(\"Number of chunks:\",len(top_docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "880885fe-16bd-44bb-9556-7cb3d4989993",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System prompt token count: 1669\n",
            "Max Completion Token count: 1000\n",
            "Combined docs (context) token count: 945\n",
            "--------\n",
            "Requested token count: 3614\n",
            "Token limit for gpt-4-32k : 32768\n",
            "Chain Type selected: stuff\n"
          ]
        }
      ],
      "source": [
        "# Calculate number of tokens of our docs\n",
        "if(len(top_docs)>0):\n",
        "    tokens_limit = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
        "    prompt_tokens = num_tokens_from_string(COMBINE_PROMPT_TEMPLATE) # this is a custom function we created in common/utils.py\n",
        "    context_tokens = num_tokens_from_docs(top_docs) # this is a custom function we created in common/utils.py\n",
        "    \n",
        "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
        "    \n",
        "    chain_type = \"map_reduce\" if requested_tokens > 0.9 * tokens_limit else \"stuff\"  \n",
        "    \n",
        "    print(\"System prompt token count:\",prompt_tokens)\n",
        "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
        "    print(\"Combined docs (context) token count:\",context_tokens)\n",
        "    print(\"--------\")\n",
        "    print(\"Requested token count:\",requested_tokens)\n",
        "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
        "    print(\"Chain Type selected:\", chain_type)\n",
        "        \n",
        "else:\n",
        "    print(\"NO RESULTS FROM AZURE SEARCH\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e232424-c7ba-4153-b23b-fb1fa2ebc64b",
      "metadata": {},
      "source": [
        "Now we will use our Utility Chain from LangChain `qa_with_sources`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "511273b3-256d-4e60-be72-ccd4a74cb885",
      "metadata": {},
      "outputs": [],
      "source": [
        "if chain_type == \"stuff\":\n",
        "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
        "                                       prompt=COMBINE_PROMPT)\n",
        "elif chain_type == \"map_reduce\":\n",
        "    chain = load_qa_with_sources_chain(llm, chain_type=chain_type, \n",
        "                                       question_prompt=COMBINE_QUESTION_PROMPT,\n",
        "                                       combine_prompt=COMBINE_PROMPT,\n",
        "                                       return_intermediate_steps=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b99a0c19-d48c-41e9-8d6c-6d9f13d29da3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 17.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Try with other language as well\n",
        "response = chain({\"input_documents\": top_docs, \"question\": QUESTION, \"language\": \"English\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "37f7fa67-f67b-402e-89e3-266d5d6d21d8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "CLP can refer to Consultation-Liaison Psychiatry, a field of psychiatry that involves providing psychiatric services in outpatient medical clinics<sup><a href=\"https://api.elsevier.com/content/article/pii/S0033318220301420; https://www.sciencedirect.com/science/article/pii/S0033318220301420?v=s5\" target=\"_blank\">[1]</a></sup>. It can also refer to Cecal Ligation and Puncture, a method used in medical research, particularly in studies related to sepsis<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5809586/\" target=\"_blank\">[2]</a></sup>. Additionally, in the context of virology, CLP stands for Core-Like Particles, which are assembled in vitro in the study of alphaviruses<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7103146/\" target=\"_blank\">[3]</a></sup>. The specific meaning of CLP would depend on the context in which it is used."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(response['output_text']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e27c75-bfd9-4304-b2fd-c8e30bcc0558",
      "metadata": {},
      "source": [
        "**Please Note**: There are some instances where, despite the answer's high accuracy and quality, the references are not done according to the instructions provided in the COMBINE_PROMPT. This behavior is anticipated when dealing with GPT-3.5 models. We will provide a more detailed explanation of this phenomenon towards the conclusion of Notebook 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11345374-6420-4b36-b061-795d2a804c85",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment if you want to inspect the results from map_reduce chain type, each top similar chunk summary (k=4 by default)\n",
        "\n",
        "# if chain_type == \"map_reduce\":\n",
        "#     for step in response['intermediate_steps']:\n",
        "#         display(HTML(\"<b>Chunk Summary:</b> \" + step))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
      "metadata": {},
      "source": [
        "# Summary\n",
        "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
        "- Utilizing Azure Cognitive Search, we conduct a multi-index text-based search that identifies the top documents from each index.\n",
        "- Utilizing Azure Cognitive Search's vector search, we extract the most relevant chunks of information.\n",
        "- Subsequently, Azure OpenAI utilizes these extracted chunks as context, comprehends the content, and employs it to deliver optimal answers.\n",
        "- Best of two worlds!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc6e2fe-1c34-4952-99ad-14940f022379",
      "metadata": {},
      "source": [
        "# NEXT\n",
        "In the next notebook, we are going to see how we can treat complex and large documents separately, also using Vector Search"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
