{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Internet and Websites Search using Bing API - Bing Chat Clone"
      ],
      "metadata": {},
      "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we'll delve into the ways in which you can **boost your GPT Smart Search Engine with web search functionalities**, utilizing both Langchain and the Azure Bing Search API service.\n",
        "\n",
        "As previously discussed in our other notebooks, **harnessing agents and tools is an effective approach**. We aim to leverage the capabilities of OpenAI's large language models (LLM), such as GPT-4 and its successors, to perform the heavy lifting of reasoning and researching on our behalf.\n",
        "\n",
        "There are numerous instances where it is necessary for our Smart Search Engine to have internet access. For instance, we may wish to **enrich an answer with information available on the web**, or **provide users with up-to-date and recent information**, or **finding information on an specific public website**. Regardless of the scenario, we require our engine to base its responses on search results.\n",
        "\n",
        "By the conclusion of this notebook, you'll have a solid understanding of the Bing Search API basics, including **how to create a Web Search Agent using the Bing Search API**, and how these tools can strengthen your chatbot. Additionally, you'll learn about **Callback Handlers, their use, and their significance in bot applications**."
      ],
      "metadata": {},
      "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, os\n",
        "from typing import Dict, List\n",
        "from pydantic import BaseModel, Extra, root_validator\n",
        "\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.utilities import BingSearchAPIWrapper\n",
        "\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts import BING_PROMPT_PREFIX\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string.replace(\"$\",\"USD \")))\n",
        "\n",
        "# GPT-4 models are necessary for this feature. GPT-35-turbo will make mistakes multiple times on following system prompt instructions.\n",
        "MODEL_DEPLOYMENT_NAME = os.environ[ \"AZURE_OPENAI_GPT4_DEPLOYMENT\" ]"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1697562098682
        }
      },
      "id": "c1fb79a3-4856-4721-988c-112813690a90"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_GPT4_ENDPOINT\"]\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_GPT4_KEY\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1697562101474
        }
      },
      "id": "258a6e99-2d4f-4147-b8ee-c64c85296181"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Callback Handlers"
      ],
      "metadata": {},
      "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This following explanation comes directly from the Langchain documentation about Callbacks ([HERE](https://python.langchain.com/docs/modules/callbacks/)):\n",
        "\n",
        "**Callbacks**:<br>\n",
        "LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. This is useful for logging, monitoring, streaming, and other tasks. You can subscribe to these events by using the callbacks argument available throughout the API. This argument is list of handler objects.\n",
        "\n",
        "**Callback handlers**:<br>\n",
        "CallbackHandlers are objects that implement the CallbackHandler interface, which has a method for each event that can be subscribed to. The CallbackManager will call the appropriate method on each handler when the event is triggered.\n",
        "\n",
        "--------------------\n",
        "We will incorporate a handler for the callbacks, enabling us to observe the response as it streams and to gain insights into the Agent's reasoning process. This will prove incredibly valuable when we aim to stream the bot's responses to users and keep them informed about the ongoing process as they await the answer.\n",
        "\n",
        "Our custom handler is on the folder `common/callbacks.py`. Go and take a look at it."
      ],
      "metadata": {},
      "id": "003327ac-2851-48ef-8a6b-2d8c2004bb2e"
    },
    {
      "cell_type": "code",
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "# Now we declare our LLM object with the callback handler \n",
        "llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0, max_tokens=1000)\n",
        "\n",
        "# or uncomment the below line if you want to see the responses being streamed\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0, max_tokens=1000, streaming=True, callback_manager=cb_manager)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1697562105395
        }
      },
      "id": "9d3daf03-77e2-466e-a255-2f06bee3561b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a custom tool - Bing Search API tool"
      ],
      "metadata": {},
      "id": "11da70c2-60b6-47fb-94f1-aa11291fa40c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langhain has already a pre-created tool called BingSearchAPIWrapper ([HERE](https://github.com/hwchase17/langchain/blob/master/langchain/utilities/bing_search.py)), however we are going to make it a bit better by using the results function instead of the run function, that way we not only have the text results, but also the title and link(source) of each snippet."
      ],
      "metadata": {},
      "id": "4dc30c9d-605d-4ada-9358-f926aeed2e48"
    },
    {
      "cell_type": "code",
      "source": [
        "class MyBingSearch(BaseTool):\n",
        "    \"\"\"Tool for a Bing Search Wrapper\"\"\"\n",
        "    \n",
        "    name = \"@bing\"\n",
        "    description = \"useful when the questions includes the term: @bing.\\n\"\n",
        "\n",
        "    k: int = 5\n",
        "    \n",
        "    def _run(self, query: str) -> str:\n",
        "        bing = BingSearchAPIWrapper(k=self.k)\n",
        "        return bing.results(query,num_results=self.k)\n",
        "            \n",
        "    async def _arun(self, query: str) -> str:\n",
        "        \"\"\"Use the tool asynchronously.\"\"\"\n",
        "        raise NotImplementedError(\"This Tool does not support async\")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1697562108204
        }
      },
      "id": "d3d155ae-16eb-458a-b2ed-5aa9a9b84ed8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we create our REACT agent that uses our custom tool and our custom prompt `BING_PROMPT_PREFIX`"
      ],
      "metadata": {},
      "id": "0a3d6569-0c61-4b1c-9263-431304577551"
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [MyBingSearch(k=5)]\n",
        "agent_executor = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
        "                         agent_kwargs={'prefix':BING_PROMPT_PREFIX}, callback_manager=cb_manager, )"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1697562110567
        }
      },
      "id": "2c6cf721-76bb-47b6-aeeb-9ff4ff92b1f4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try some of the below questions, or others that you might like"
      ],
      "metadata": {},
      "id": "7232260e-e972-4288-b0b5-0b605e584528"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"Create a list with the main facts on What is happening with the oil supply in the world right now?\"\n",
        "# QUESTION = \"How much is 50 USD in Euros and is it enough for an average hotel in Madrid?\"\n",
        "# QUESTION = \"My son needs to build a pinewood car for a pinewood derbi, how do I build such a car?\"\n",
        "# QUESTION = \"Who won the 2023 superbowl and who was the MVP?\"\n",
        "# QUESTION = \"can I travel to Hawaii, Maui from Dallas, TX for 7 days with $7000 on the month of September, what are the best days to travel?\"\n",
        "\n",
        "\n",
        "# This complex question below needs gpt-4-32k (0613 version) in order to ensure a good answer. \n",
        "# ---------------\n",
        "# QUESTION = \"\"\"\n",
        "# compare the number of job opennings (provide the exact number), the average salary within 15 miles of Dallas, TX, for these ocupations:\n",
        "\n",
        "# - ADN Registerd Nurse \n",
        "# - Occupational therapist assistant\n",
        "# - Dental Hygienist\n",
        "# - Graphic Designer\n",
        "# - Real Estate Agent\n",
        "\n",
        "\n",
        "# Create a table with your findings. Place the sources on each cell.\n",
        "# \"\"\""
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1697562113107
        }
      },
      "id": "fa949cea-c9aa-4529-a75f-61084ffffd7e"
    },
    {
      "cell_type": "code",
      "source": [
        "#As LLMs responses are never the same, we do a for loop in case the answer cannot be parsed according to our prompt instructions\n",
        "for i in range(2):\n",
        "    try:\n",
        "        response = agent_executor.run(QUESTION) \n",
        "        break\n",
        "    except Exception as e:\n",
        "        response = str(e)\n",
        "        continue"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The user is asking for current information about the global oil supply. I will need to perform a web search to gather the most recent data and facts on this topic.\nAction: @bing\nAction Input: What is happening with the oil supply in the world right now?The user is asking for current information about the global oil supply. I will need to perform a web search to gather the most recent data and facts on this topic.\nAction: @bing\nAction Input: What is happening with the oil supply in the world right now?\nThe user is asking for current information about the global oil supply. I will need to perform a web search to gather the most recent data and facts on this topic.\nAction: @bing\nAction Input: What is happening with the oil supply in the world right now?The user is asking for current information about the global oil supply. I will need to perform a web search to gather the most recent data and facts on this topic.\nAction: @bing\nAction Input: What is happening with the oil supply in the world right now?\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1697562122049
        }
      },
      "id": "ca910f71-60fb-4758-b4a9-757e37eb421f"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(response)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "401 Client Error: Access Denied for url: https://api.bing.microsoft.com/v7.0/search?q=What+is+happening+with+the+oil+supply+in+the+world+right+now%3F&count=5&textDecorations=True&textFormat=HTML"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1697562126727
        }
      },
      "id": "25a410b2-9950-43f5-8f14-b333bdc24ff2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QnA to specific websites\n",
        "\n",
        "There are several use cases where we want the smart bot to answer questions about a specific company's public website. There are two approaches we can take:\n",
        "\n",
        "1. Create a crawler script that runs regularly, finds every page on the website, and pushes the documents to Azure Cognitive Search.\n",
        "2. Since Bing has likely already indexed the public website, we can utilize Bing search targeted specifically to that site, rather than attempting to index the site ourselves and duplicate the work already done by Bing's crawler.\n",
        "\n",
        "Below are some sample questions related to specific sites. Take a look:"
      ],
      "metadata": {},
      "id": "e9ba3e35-8021-4262-8494-d1aee3862f7e"
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION = \"information on how to kill wasps in homedepot.com\"\n",
        "# QUESTION = \"in target.com, find how what's the price of a Nesspresso coffee machine and of a Keurig coffee machine\"\n",
        "QUESTION = \"in microsoft.com, find out what is the latests news on quantum computing\"\n",
        "# QUESTION = \"give me on a list the main points on the latest investor report from mondelezinternational.com\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "e925ee4a-d295-4815-9e8c-bd6999f48892"
    },
    {
      "cell_type": "code",
      "source": [
        "#As LLMs responses are never the same, we do a for loop in case the answer cannot be parsed according to our prompt instructions\n",
        "for i in range(3):\n",
        "    try:\n",
        "        response = agent_executor.run(QUESTION) \n",
        "        break\n",
        "    except Exception as e:\n",
        "        response = str(e)\n",
        "        continue"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "099830a1-b81d-4698-a458-e84ccf3989cc"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(response)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "89e67095-277d-45b6-84aa-acef0eb6cf5f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you want to take a look at the custom bing search prompt (This is where the magic happens: a great system promp + GPT-4)\n",
        "# printmd(agent_executor.agent.llm_chain.prompt.template)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "9782fafa-9453-46be-b9d7-b33088f61ac8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {},
      "id": "56cbc405-26e2-471e-9626-2a0df07f5ddc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we learned about Callback Handlers and how to stream the response from the LLM. We also learn how to create a Bing Chat clone using a clever prompt with specific search and formatting instructions.\n",
        "\n",
        "The outcome is an agent capable of conducting intelligent web searches and performing research on our behalf. This agent provides us with answers to our questions along with appropriate URL citations and links!"
      ],
      "metadata": {},
      "id": "7381ea5f-7269-4e1f-8b0c-1e2c04bd84c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "\n",
        "The Next Notebook will guide you on how we stick everything together. How do we use the features of all notebooks and create a brain agent that can respond to any request accordingly."
      ],
      "metadata": {},
      "id": "02073623-91b4-40d6-8eaf-cb6d9c6a7a9a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}