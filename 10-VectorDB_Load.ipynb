{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading data into the Vector Database, Weaviate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Prerequites:\n",
        "\n",
        "1. Weaviate Running on AKS\n",
        "    This notebook assumes you have a Weaviate instance running. https://weaviate.io/developers/weaviate/installation\n",
        "2. Azure openAI endpoint\n",
        "    Have a commercial Azure openAI endpoint provisioned, you need 2 deployments both an embedding model and a LLM deployed. https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal\n",
        "\n",
        "This demo takes research pdfs from blob storage, loads and splits it, and writes them to weaviate given an embedding model.\n",
        "\n",
        "Below are a list of necessary packages:\n",
        "- weviate-client is for connecting to weaviate from python. \n",
        "- tiktoken is a dependancy for OpenAIEmbeddings.\n",
        "- openai is for connecting to your AOAI instance.\n",
        "- langchain is a language model integration framework. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install weaviate-client\n",
        "%pip install tiktoken\n",
        "%pip install openai[datalib]\n",
        "%pip install langchain\n",
        "%pip install pymupdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and split Data archive pdfs from blob storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook uses this dataset as an example. Your dataset can be used instead. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BLOB_CONNECTION_STRING=\"DefaultEndpointsProtocol=https;AccountName=demodatasetsp;AccountKey=QVFgIKPiWB+8f0mH+F7fidVLG7wq1S3WhtAqXOWaMWtr6fZ4frhVgmUzgBSdkmw4VsjoEAo7C2Hn+ASt2Cc5HA==;EndpointSuffix=core.windows.net\"\n",
        "BLOB_SAS_TOKEN=\"?sv=2022-11-02&ss=bf&srt=sco&sp=rltfx&se=2024-10-02T01:02:07Z&st=2023-08-03T17:02:07Z&spr=https&sig=gLxStXFSY6X29OPpPDpBEhoQDdtJNDrMVExNYJ%2BhmBQ%3D\"\n",
        "BLOB_CONTAINER_NAME = \"arxivcs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install unstructured\n",
        "%pip install \"unstructured[pdf]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#loads pdfs from arxivcs storage container.\n",
        "\n",
        "from langchain.document_loaders import AzureBlobStorageContainerLoader\n",
        "\n",
        "loader = AzureBlobStorageContainerLoader(\n",
        "    conn_str=BLOB_CONNECTION_STRING,\n",
        "    container=BLOB_CONTAINER_NAME,\n",
        "    prefix=\"000\"\n",
        "    )\n",
        "    \n",
        "docs = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting our embedding parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    deployment=\"YOUR_DEPLOYMENT\",\n",
        "    model=\"YOUR_EMBEDDING_MODEL\",\n",
        "    openai_api_base=\"YOUR_URL\",\n",
        "    openai_api_type=\"azure\",\n",
        "    openai_api_key=\"YOUR_KEY\",\n",
        "    chunk_size = 16\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Write to authenticated Weaviate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Note: To use internal IP of the VM hosting docker instance compute instance has to be in same vnet. \n",
        "Example: https://10.0.0.4:8080\n",
        "\n",
        "For an AKS cluster navigate to the resource->services and ingresses->click on your weaviate service-> use the endpoint which will look like the example above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1690829564389
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Weaviate\n",
        "import weaviate\n",
        "\n",
        "WEAVIATE_URL = \"YOUR_URL\" #example: http://10.244.3.20:8080\"\n",
        "WEAVIATE_API_KEY = \"YOUR_KEY\"\n",
        "\n",
        "client = weaviate.Client(url=WEAVIATE_URL, auth_client_secret=weaviate.AuthApiKey(WEAVIATE_API_KEY))\n",
        "vectorstore = Weaviate.from_documents(docs, embeddings, client=client, by_text=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify documents were loaded the format will be: \n",
        "\n",
        "Document(\n",
        "        page_content=\"Content\",\n",
        "        metadata={\"metadata\"},\n",
        "    ),\n",
        "    \n",
        "You can query on either the page content or the metadata.\n",
        "\n",
        "The following is just an example query using similarity, queries can be done in a variety of ways such as relevance, variety or limit the number of retrieved docs. https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"What do you know about quantum Mechanics\"\n",
        "vectorstore_output = vectorstore.similarity_search(query)\n",
        "vectorstore_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If needed, uncomment the final cell to clear the loaded data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#client.schema.delete_all()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
